{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# General setting"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-05T21:24:35.223718Z","iopub.status.busy":"2023-05-05T21:24:35.223255Z","iopub.status.idle":"2023-05-05T21:24:35.247958Z","shell.execute_reply":"2023-05-05T21:24:35.246553Z","shell.execute_reply.started":"2023-05-05T21:24:35.223682Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","# started at https://www.kaggle.com/renataghisloti\n","# %-m pip install --upgrade pip\n","# %pip install pandas \n","# %pip install seaborn\n","# %pip install matplotlib\n","# %pip install xgboost\n","# %pip install lightgbm\n","# %pip install sklearn\n","# %pip install \"tensorflow<2.11\"\n","# %pip install catboost\n","import time\n","import numpy as np # yLinear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","import sklearn\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from copy import deepcopy\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import random\n","import os\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor\n","from sklearn.svm import SVC, SVR\n","from sklearn.neural_network import MLPClassifier, MLPRegressor\n","from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n","from catboost import CatBoostClassifier, CatBoostRegressor\n","from sklearn.model_selection import train_test_split\n","import xgboost as xg\n","import lightgbm as lgb\n","from sklearn.metrics import log_loss\n","# #https://www.tensorflow.org/install\n","# # Requires the latest pip\n","# # !-m pip install --upgrade pip\n","# # Current stable release for CPU and GPU\n","# # !pip install tensorflow\n","# #Testing if tensorflow is installed\n","import tensorflow as tf \n","from tensorflow import keras \n","# print('tf.__version__: ', tf.__version__)\n","# print('__version__: ', keras.__version__)\n","from sklearn.base import BaseEstimator, TransformerMixin\n","\n","random.seed(42)\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","isInKaggle = not os.environ['PATH'].startswith('c:')#It is local if True ;)\n","\n","DATA_ROOT = \"/kaggle/input/icr-identify-age-related-conditions/\" if isInKaggle else \"C:/Users/praf6/OneDrive - Universidade Federal do Cariri - UFCA/Drive/UFCA/Ensino/CRAN R_aulas/kaggleFiles/data/ageRelatedConditions/\"\n","PREPROCESSED_DATA_ROOT = \"/kaggle/input/preprocessed/\" if isInKaggle else \"C:/Users/praf6/OneDrive - Universidade Federal do Cariri - UFCA/Drive/UFCA/Ensino/CRAN R_aulas/kaggleFiles/data/ageRelatedConditions/\"\n","RESULTS_ROOT = '/kaggle/working/' if isInKaggle else \"C:/Users/praf6/OneDrive - Universidade Federal do Cariri - UFCA/Drive/UFCA/Ensino/CRAN R_aulas/kaggleFiles/results/ageRelatedConditions/\"\n","\n","# Input train files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# for dirname, _, filenames in os.walk(DATA_ROOT):\n","#     for filename in filenames:\n","        # print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","\n","# u1 = 0; u2 = 1; \n","u = 'Class'\n","initialModelsObjs = {}; errorModelsObjs = {}"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:35.251152Z","iopub.status.busy":"2023-05-05T21:24:35.250587Z","iopub.status.idle":"2023-05-05T21:24:35.265085Z","shell.execute_reply":"2023-05-05T21:24:35.263512Z","shell.execute_reply.started":"2023-05-05T21:24:35.251106Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.__version__:  2.10.1\n","Num GPUs Available:  1\n"]},{"data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 11048519229905195581\n"," xla_global_id: -1,\n"," name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 1734816564\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 8326164378183510517\n"," physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n"," xla_global_id: 416903419]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#from https://www.tensorflow.org/install/pip?hl=pt-br#windows-native\n","# %conda install -c conda-forge cudatoolkit=11.8.0\n","#....\n","# # %pip install --upgrade pip\n","print('tf.__version__: ', tf.__version__)\n","# %pip install tensorflow-gpu\n","from tensorflow.python.client import device_lib\n","\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","device_lib.list_local_devices()"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2023-05-05T21:24:35.267511Z","iopub.status.busy":"2023-05-05T21:24:35.266982Z","iopub.status.idle":"2023-05-05T21:24:35.278916Z","shell.execute_reply":"2023-05-05T21:24:35.277640Z","shell.execute_reply.started":"2023-05-05T21:24:35.267461Z"},"trusted":true},"outputs":[],"source":["#constants\n","CombMVMaxLogLoss_dif_vt = .1\n","# isToModel = True\n","outlierProbability = None#.5; #None for not using outlier-variables\n","dataSubsetsProps = [.25, .50, .75, .25] #proportion of patients to each modeling phase and test phase;\n","isWithOptimization = False; \n","isWithPCA = False; \n","TfBatchSize = 35 if isInKaggle else 35; \n","TfVerbose = False if isInKaggle else False;\n","TfEpochs = 5000 if isInKaggle else 5000; \n","TfPatience = 10\n","nImportantFeatures = 56;#there are 56 predictor variables;\n","nPcaComponents = np.min([20, nImportantFeatures])# there are 56 predictor variables;\n","myCv = 5 if not isInKaggle else 50;\n","openMinimalTreshold = -1 #only values greater than openMinimalTreshold are considered in the modeling; \n","optMethod = 'GridSearchCV'#'BayesSearchCV'\n","PRED_PREFIX = ''#'pe'#'pr'"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:35.282886Z","iopub.status.busy":"2023-05-05T21:24:35.282041Z","iopub.status.idle":"2023-05-05T21:24:35.338984Z","shell.execute_reply":"2023-05-05T21:24:35.337120Z","shell.execute_reply.started":"2023-05-05T21:24:35.282846Z"},"trusted":true},"outputs":[],"source":["# Models Architecture Compilation\n","import joblib\n","MODELS_ROOT = \"/kaggle/input/\"+PRED_PREFIX + \\\n","    'models3/' if isInKaggle else \"C:/Users/praf6/OneDrive - Universidade Federal do Cariri - UFCA/Drive/UFCA/Ensino/CRAN R_aulas/kaggleFiles/results/ageRelatedConditions/\"+PRED_PREFIX\n","def foldersVerification(ROOT):\n","    def computeFolder(root, folder):\n","        path = root + folder\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","        return path\n","    ROOT_ = computeFolder(ROOT, 'Models/')\n","    ROOT_ = computeFolder(ROOT_, 'withPCA/' if isWithPCA else 'withoutPCA/')\n","    ROOT_ = computeFolder(\n","        ROOT_, 'withOptimization/' if isWithOptimization else 'withoutOptimization/')\n","    return ROOT_\n","MODELS_ROOT = foldersVerification(MODELS_ROOT)\n","PERFORMANCE_ROOT = foldersVerification(RESULTS_ROOT+'Wperformance/')\n","def getModelName(yModel, eModel=None, targetVar=\"\"):\n","    type_yModel = type(yModel)\n","    yModelNm = yModel if type_yModel == str else 'y'+type_yModel.__name__\n","    formalism = yModelNm.replace('Classifier', '').replace('Classification', '').replace(\n","        'Regressor', '').replace('Regression', '')  # .replace('yy', 'y')\n","    if eModel is not None:\n","        type_eModel = type(eModel)\n","        eModelNm = eModel if type_eModel == str else type_eModel.__name__\n","        # replace('Classifier', '').replace('Classification', '')\n","        formalism += '_e' + \\\n","            eModelNm.replace('Regressor', '').replace('Regression', '')\n","    # if targetVar != \"\": formalism += ('_'+targetVar)\n","    return formalism\n","class MyEstimator(BaseEstimator, TransformerMixin):\n","    def __init__(self, targetVar=None, saveExtension='.sav', model=None,\n","                 xVarsNms=None):\n","        self.targetVar = targetVar\n","        self.model = model\n","        self.xVarsNms = xVarsNms\n","        self.saveExtension = saveExtension\n","        self.xVarsNms = xVarsNms\n","    def loadModel(self, path):\n","        try:\n","            # the usual function for sklearn models\n","            self.model = joblib.load(path)\n","        except:\n","            fileNm = path.split('/')\n","            fileNm = fileNm[len(fileNm)-1]\n","            path2 = foldersVerification(RESULTS_ROOT)+fileNm\n","            # the usual function for sklearn models\n","            self.model = joblib.load(path2)\n","\n","        return self.model\n","    def saveModel(self, path):\n","        try:\n","            # the usual function for sklearn models\n","            joblib.dump(self.model, path)\n","        except:\n","            fileNm = path.split('/')\n","            fileNm = fileNm[len(fileNm)-1]\n","            path2 = foldersVerification(RESULTS_ROOT)+fileNm\n","            joblib.dump(self.model, path2)\n","        return self\n","    def fit(self, X, y, modelName=None):\n","        if isWithOptimization:\n","            self.model.fit(X, y)\n","        else:\n","            modelNm = modelName if modelName is not None else getModelName(\n","                self, targetVar=self.targetVar)\n","            path = MODELS_ROOT+modelNm+self.saveExtension\n","            start = time.time()\n","            try:\n","                self.model = self.loadModel(path)\n","                print('==**** load_model', modelNm, '****==')\n","            except:\n","                print('==**** fit', modelNm, '****==')\n","                # X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, shuffle=False)\n","                # eval_set = [(X_validation, y_validation)]\n","                # , eval_metric=\"binary:logistic\", eval_set=eval_set, early_stopping_rounds=10,\n","                self.model.fit(X, y)\n","                self.saveModel(path)\n","            print('>>> elapsed time:', str(time.time() - start), 'seconds!')\n","        return self\n","class MyClassifier(MyEstimator):\n","    def predict(self, X):\n","        # the usual function for sklearn classiifers\n","        ret = self.model.predict_proba(X)[:, 1]\n","        # if not isWithOptimization:\n","        # ret = ret[:,1]#[v[1] for v in ret0]\n","        # ret = list(np.concatenate(ret, axis=0 ))\n","        return ret  # .tolist()\n","    # def transform(self, X):\n","    #     return self\n","class MyRegressor(MyEstimator):\n","    def predict(self, X):\n","        # the usual function for sklearn regressors\n","        ret = self.model.predict(X)\n","        # if not isWithOptimization:\n","        # ret = ret[:,1]#[v[1] for v in ret0]\n","        # ret = list(np.concatenate(ret, axis=0 ))\n","        return ret.tolist()\n","class MyTfANN (MyEstimator):\n","    def __init__(self, targetVar, phase, hidden_layer_sizes=(2, 2, 2),\n","                 hidden_layer_dropout_rates=(.2, .2, .2),\n","                 hidden_layer_activations=('relu', 'relu', 'relu'),\n","                 learningRate=3e-3,\n","                 inpute_layer_dropout_rate=.2,\n","                 hidden_layer_functions=[keras.layers.Dense],\n","                 outputActivationFunction='linear',  # 'sigmoid'\n","                 loss='rmse',\n","                 batch_size=1):\n","        self.targetVar = targetVar\n","        self.phase = phase\n","        self.hidden_layer_sizes = hidden_layer_sizes\n","        self.learningRate = learningRate\n","        self.inpute_layer_dropout_rate = inpute_layer_dropout_rate\n","        self.hidden_layer_activations = hidden_layer_activations\n","        self.hidden_layer_functions = hidden_layer_functions\n","        self.outputActivationFunction = outputActivationFunction\n","        self.loss = loss\n","        self.batch_size = batch_size\n","        # Model architecture\n","        self.model = self.getTfAnnModelStructure(\n","            hidden_layer_sizes=hidden_layer_sizes,\n","            hidden_layer_dropout_rates=hidden_layer_dropout_rates,\n","            hidden_layer_activations=hidden_layer_activations,\n","            learningRate=learningRate,\n","            inpute_layer_dropout_rate=inpute_layer_dropout_rate,\n","            hidden_layer_functions=hidden_layer_functions,\n","            outputActivationFunction=outputActivationFunction,\n","            loss=loss)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.keras', xVarsNms=None)\n","    def getTfAnnModelStructure(self, targetVar=None, hidden_layer_sizes=(2, 2, 2),\n","                               hidden_layer_dropout_rates=(.2, .2, .2),\n","                               hidden_layer_activations=(\n","                                   'relu', 'relu', 'relu'),\n","                               learningRate=3e-3,\n","                               inpute_layer_dropout_rate=.2,\n","                               hidden_layer_functions=[keras.layers.Dense],\n","                               outputActivationFunction='linear',  # 'sigmoid'\n","                               loss='rmse'):  # 'log_loss'\n","        # Model architecture\n","        tfAnn_reg = keras.models.Sequential(name=\"TF_ANN\")\n","        multi = 1 if outlierProbability is None else 3  # due to the two outliers columns\n","        u = targetVar\n","        input_shape = None\n","        if str(hidden_layer_functions[0]) == \"<class 'keras.layers.core.dense.Dense'>\":\n","            input_shape = (nPcaComponents*multi,\n","                           ) if isWithPCA else (nImportantFeatures*multi,)\n","        elif str(hidden_layer_functions[0]) == \"<class 'keras.layers.rnn.lstm.LSTM'>\":\n","            # (1, nPcaComponents*multi, ) if isWithPCA else (1, nImportantFeatures*multi, )#to evolve ;)\n","            input_shape = [None, 1]\n","        tfAnn_reg.add(keras.layers.InputLayer(\n","            name=\"input_layer\", input_shape=input_shape))\n","        if inpute_layer_dropout_rate > 0:\n","            tfAnn_reg.add(keras.layers.Dropout(\n","                inpute_layer_dropout_rate))  # dropout\n","        nHiddenLayers = len(hidden_layer_sizes)\n","        nDropouts = len(hidden_layer_dropout_rates)\n","        nActivations = len(hidden_layer_activations)\n","        n_hidden_layer_functions = len(hidden_layer_functions)\n","        if nHiddenLayers > 1 and nDropouts == 1:\n","            hidden_layer_dropout_rates = tuple(\n","                [hidden_layer_dropout_rates[0]]*nHiddenLayers)\n","        if nHiddenLayers > 1 and nActivations == 1:\n","            hidden_layer_activations = tuple(\n","                [hidden_layer_activations[0]]*nHiddenLayers)\n","        if nHiddenLayers > 1 and n_hidden_layer_functions == 1:\n","            hidden_layer_functions = tuple(\n","                [hidden_layer_functions[0]]*nHiddenLayers)\n","        for i in range(nHiddenLayers):\n","            if str(hidden_layer_functions[i]) == \"<class 'keras.layers.core.dense.Dense'>\":\n","                tfAnn_reg.add(hidden_layer_functions[i](name=(\"hidden_layer_\" + str(i)),\n","                                                        units=hidden_layer_sizes[i],\n","                                                        activation=hidden_layer_activations[i]))  # hidden layer # i\n","                if hidden_layer_dropout_rates[i] > 0:\n","                    tfAnn_reg.add(keras.layers.Dropout(\n","                        hidden_layer_dropout_rates[i]))\n","            elif str(hidden_layer_functions[i]) == \"<class 'keras.layers.rnn.lstm.LSTM'>\":\n","                return_sequences = True if i < (nHiddenLayers-1) else False\n","                tfAnn_reg.add(hidden_layer_functions[i](name=(\"hidden_layer_\" + str(i)),\n","                                                        units=hidden_layer_sizes[i],\n","                                                        recurrent_dropout=hidden_layer_dropout_rates[i],\n","                                                        return_sequences=return_sequences))  # hidden layer # i\n","\n","        # outputActivationFunction = 'sigmoid' if type=='Classifier' else 'linear'\n","        tfAnn_reg.add(keras.layers.Dense(name=\"output_layer\", units=1,\n","                      activation=outputActivationFunction))  # output layer 'linear' 'softmax'\n","        optimizer = keras.optimizers.SGD(learning_rate=learningRate)\n","        tfAnn_reg.compile(loss=loss, optimizer=optimizer,\n","                          metrics='mae')\n","        return (tfAnn_reg)\n","    def loadModel(self, path):\n","        try:\n","            # the usual function for keras models\n","            self.model = keras.models.load_model(path)\n","        except:\n","            fileNm = path.split('/')\n","            fileNm = fileNm[len(fileNm)-1]\n","            path2 = foldersVerification(RESULTS_ROOT)+fileNm\n","            self.model = keras.models.load_model(path2)\n","        return self.model\n","    def saveModel(self, path):\n","        try:\n","            self.model.save(path)  # the usual function for keras models\n","        except:\n","            fileNm = path.split('/')\n","            fileNm = fileNm[len(fileNm)-1]\n","            path2 = foldersVerification(RESULTS_ROOT)+fileNm\n","            self.model.save(path2)\n","        return self\n","    def fit(self, X, y, modelName=None):\n","        if isWithOptimization:\n","            self.model.fit(X, y)\n","        else:\n","            # self.targetVar + '_' + self.phase + '_' + type(self).__name__.replace('Classifier', '')\n","            modelNm = modelName if modelName is not None else getModelName(\n","                self, targetVar=self.targetVar)\n","            path = MODELS_ROOT+modelNm+self.saveExtension\n","            start = time.time()\n","            try:\n","                self.model = self.loadModel(path)\n","                print('==**** load_model', modelNm, '****==')\n","            except:\n","                print('==****', modelNm, '****==')\n","                early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                                  patience=TfPatience,\n","                                                                  restore_best_weights=True)\n","\n","                # reshape input to be [samples, time steps, features]\n","                # np.reshape(X, (X.shape[0], 1, X.shape[1]))#to evolve with this... ;)\n","                rX = X\n","                history = self.model.fit(rX, y, epochs=TfEpochs,\n","                                         batch_size=self.batch_size,\n","                                         validation_split=.2,\n","                                         verbose=TfVerbose, callbacks=[early_stopping_cb])\n","                epochsLastIndex = len(history.epoch)-1\n","                LogLoss_t = np.round(\n","                    (history.history['loss'][epochsLastIndex]), 3)\n","                LogLoss_v = np.round(\n","                    (history.history['val_loss'][epochsLastIndex]), 3)\n","                MAE_t = np.round(history.history['mae'][epochsLastIndex], 3)\n","                MAE_v = np.round(\n","                    history.history['val_mae'][epochsLastIndex], 3)\n","                LogLoss_v_t = LogLoss_v - LogLoss_t\n","                MAE_v_t = MAE_v - MAE_t\n","                df = pd.DataFrame({'convergenceEpoch': history.epoch[epochsLastIndex],\n","                                   'MSE_t': LogLoss_t, 'MSE_v': LogLoss_v, 'MSE_v_t': LogLoss_v_t,\n","                                   'MAE_t': MAE_t, 'MAE_v': MAE_v, 'MAE_v_t': MAE_v_t}, index=[0])\n","                display(df)\n","                self.saveModel(path)\n","            print('>>> elapsed time:', str(time.time() - start), 'seconds!')\n","        return self\n","    def predict(self, X):\n","        ret = self.model.predict(X, verbose=False)\n","        ret = list(np.concatenate(ret, axis=0))\n","        return ret\n","class MyXGB (MyEstimator):\n","    def __init__(self, targetVar=None, colsample_bytree=1, eta=0.3, max_depth=6, n_estimators=100,\n","                 objective='reg:squarederror', seed=0, subsample=1, gamma=0, model=None,\n","                 eval_metric = 'rmse',\n","                 learning_rate = 0.413327571405248,\n","                booster = 'gbtree',\n","                reg_lambda = 0.0000263894617720096,\n","                alpha = 0.000463768723479341,\n","                min_child_weight = 9,\n","                grow_policy = 'depthwise',\n","                n_jobs = -1,\n","                verbosity = 0):#logloss \n","        self.targetVar = targetVar\n","        self.colsample_bytree = colsample_bytree\n","        self.eta = eta\n","        self.max_depth = max_depth\n","        self.n_estimators = n_estimators\n","        self.subsample = subsample\n","        self.objective = objective\n","        self.seed = seed\n","        self.model = model\n","        self.gamma = gamma\n","        self.eval_metric = eval_metric\n","        self.learning_rate = learning_rate\n","        self.booster = booster\n","        self.reg_lambda = reg_lambda\n","        self.alpha = alpha\n","        self.min_child_weight = min_child_weight\n","        self.grow_policy = grow_policy\n","        self.n_jobs = n_jobs\n","        self.verbosity = verbosity\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.txt', xVarsNms=None)\n","\n","    def loadModel(self, path):\n","        try:\n","            self.model.load_model(path)\n","        except:\n","            fileNm = path.split('/')\n","            fileNm = fileNm[len(fileNm)-1]\n","            path2 = foldersVerification(RESULTS_ROOT)+fileNm\n","            self.model.load_model(path2)\n","        return self.model\n","\n","    def saveModel(self, path):\n","        try:\n","            self.model.save_model(path)\n","        except:\n","            fileNm = path.split('/')\n","            fileNm = fileNm[len(fileNm)-1]\n","            path2 = foldersVerification(RESULTS_ROOT)+fileNm\n","            self.model.save_model(path2)\n","        return self\n","\n","    def fit(self, X, y, modelName=None):\n","        if isWithOptimization:\n","            self.model.fit(X, y)\n","        else:\n","            # self.targetVar + '_' + self.phase + '_' + type(self).__name__.replace('Classifier', '')\n","            modelNm = modelName if modelName is not None else getModelName(\n","                self, targetVar=self.targetVar)\n","            path = MODELS_ROOT+modelNm+self.saveExtension\n","            start = time.time()\n","            try:\n","                self.model = self.loadModel(path)\n","                print('==**** load_model', modelNm, '****==')\n","            except:\n","                print('==**** fit_model', modelNm, '****==')\n","                X_train, X_validation, y_train, y_validation = train_test_split(\n","                    X, y, test_size=0.2, shuffle=False)\n","                eval_set = [(X_validation, y_validation)]\n","                self.model.fit(X_train, y_train,\n","                                  eval_metric=self.eval_metric,\n","                               eval_set=eval_set,\n","                               early_stopping_rounds=10,\n","                               verbose=False)\n","                self.saveModel(path)\n","            print('>>> elapsed time:', str(time.time() - start), 'seconds!')\n","        return self\n","class MyLGBM (MyEstimator):\n","    def __init__(self, targetVar=None, min_split_gain=0,\n","                 learning_rate=0.1,\n","                 min_child_samples=20,\n","                 max_depth=-1,\n","                 n_estimators=100,\n","                 random_state=0,\n","                 num_leaves=31,\n","                 model=None,\n","                 eval_metric='rmse'):  # \"binary:logistic\"\n","        self.targetVar = targetVar\n","        self.min_split_gain = min_split_gain\n","        self.learning_rate = learning_rate\n","        self.min_child_samples = min_child_samples\n","        self.max_depth = max_depth\n","        self.n_estimators = n_estimators\n","        self.random_state = random_state\n","        self.num_leaves = num_leaves\n","        self.model = model\n","        self.eval_metric = eval_metric\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.txt', xVarsNms=None)\n","\n","    def loadModel(self, path):\n","        try:\n","            self.model = lgb.Booster(model_file=path)\n","        except:\n","            fileNm = path.split('/')\n","            fileNm = fileNm[len(fileNm)-1]\n","            path2 = foldersVerification(RESULTS_ROOT)+fileNm\n","            self.model = lgb.Booster(model_file=path2)\n","        return self.model\n","\n","    def saveModel(self, path):\n","        try:\n","            self.model.booster_.save_model(path)\n","        except:\n","            fileNm = path.split('/')\n","            fileNm = fileNm[len(fileNm)-1]\n","            path2 = foldersVerification(RESULTS_ROOT)+fileNm\n","            self.model.booster_.save_model(path2)\n","        return self\n","\n","    def fit(self, X, y, modelName=None):\n","        if isWithOptimization:\n","            self.model.fit(X, y)\n","        else:\n","            # self.targetVar + '_' + self.phase + '_' + type(self).__name__.replace('Classifier', '')\n","            modelNm = modelName if modelName is not None else getModelName(\n","                self, targetVar=self.targetVar)\n","            # if(modelNm == 'yMyXGB_eMyLGBM'):\n","            #     g=1\n","            path = MODELS_ROOT+modelNm+self.saveExtension\n","            start = time.time()\n","            try:\n","                self.model = self.loadModel(path)\n","                print('==**** load_model', modelNm, '****==')\n","            except:\n","                print('==**** fit', modelNm, '****==')\n","                X_train, X_validation, y_train, y_validation = train_test_split(\n","                    X, y, test_size=0.2, shuffle=False)\n","                eval_set = [(X_validation, y_validation)]\n","                \n","                self.model.fit(X_train, y_train, eval_metric=self.eval_metric, eval_set=eval_set, early_stopping_rounds=10,\n","                               verbose=False)\n","                self.saveModel(path)\n","            print('>>> elapsed time:', str(time.time() - start), 'seconds!')\n","        return self\n","\n","# classifiers\n","class MyLogisticRegression (MyClassifier, LogisticRegression):\n","    def __init__(self, targetVar=None, tol=0.0001,\n","                 C=1, fit_intercept=True, intercept_scaling=1,\n","                 max_iter=100, verbose=False, random_state=0):\n","        self.targetVar = targetVar\n","        self.tol = tol\n","        self.C = C\n","        self.fit_intercept = fit_intercept\n","        self.intercept_scaling = intercept_scaling\n","        self.max_iter = max_iter\n","        self.verbose = verbose\n","        self.random_state = random_state\n","\n","        self.model = LogisticRegression(tol=self.tol,\n","                                        C=self.C,\n","                                        fit_intercept=self.fit_intercept,\n","                                        intercept_scaling=self.intercept_scaling,\n","                                        max_iter=self.max_iter,\n","                                        verbose=self.verbose,\n","                                        random_state=self.random_state)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MySVC (MyClassifier, SVC):\n","    def __init__(self, targetVar=None,\n","                 C=1,\n","                 #  ,\n","                 coef0=0,\n","                 degree=3,\n","                 gamma='scale',\n","                 kernel='rbf',\n","                 tol=1e-3):\n","        self.targetVar = targetVar\n","        self.C = C\n","        self.coef0 = coef0\n","        self.degree = degree\n","        self.gamma = gamma\n","        self.kernel = kernel\n","        self.tol = tol\n","\n","        self.model = SVC(probability=True,\n","                         C=self.C,\n","                         coef0=self.coef0,\n","                         degree=self.degree,\n","                         gamma=self.gamma,\n","                         kernel=self.kernel,\n","                         tol=self.tol,\n","                         verbose=False)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MyDecisionTreeClassifier (MyClassifier, DecisionTreeClassifier):\n","    def __init__(self, targetVar=None,\n","                 ccp_alpha=0,\n","                 max_depth=None,\n","                 min_samples_leaf=1,\n","                 min_samples_split=2,\n","                 splitter='best'):\n","        self.targetVar = targetVar\n","        self.ccp_alpha = ccp_alpha\n","        self.max_depth = max_depth\n","        self.min_samples_leaf = min_samples_leaf\n","        self.min_samples_split = min_samples_split\n","        self.splitter = splitter\n","\n","        self.model = DecisionTreeClassifier(\n","            ccp_alpha=self.ccp_alpha,\n","            max_depth=self.max_depth,\n","            min_samples_leaf=self.min_samples_leaf,\n","            min_samples_split=self.min_samples_split,\n","            splitter=self.splitter,\n","            random_state=0)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MyRandomForestClassifier (MyClassifier, RandomForestClassifier):\n","    def __init__(self, targetVar=None,\n","                 n_estimators=100,\n","                 ccp_alpha=0,\n","                 max_depth=None,\n","                 min_samples_leaf=1,\n","                 min_samples_split=2):\n","        self.targetVar = targetVar\n","        self.n_estimators = n_estimators\n","        self.ccp_alpha = ccp_alpha\n","        self.max_depth = max_depth\n","        self.min_samples_leaf = min_samples_leaf\n","        self.min_samples_split = min_samples_split\n","\n","        self.model = RandomForestClassifier(\n","            ccp_alpha=self.ccp_alpha,\n","            max_depth=self.max_depth,\n","            min_samples_leaf=self.min_samples_leaf,\n","            min_samples_split=self.min_samples_split,\n","            random_state=0)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MyHistGBClassifier (MyClassifier, HistGradientBoostingClassifier):\n","    def __init__(self, targetVar=None, \n","                 loss=\"log_loss\",\n","                learning_rate = 0.1,\n","                max_iter = 100,\n","                max_leaf_nodes = 31,\n","                max_depth = None,\n","                min_samples_leaf = 20,\n","                l2_regularization = 0,\n","                max_bins = 255,\n","                categorical_features = None,\n","                monotonic_cst = None,\n","                interaction_cst = None,\n","                warm_start = False,\n","                early_stopping= \"auto\",\n","                scoring = \"loss\",\n","                validation_fraction = 0.1,\n","                n_iter_no_change = 10,\n","                tol = 1e-7,\n","                verbose = 0,\n","                random_state = 0,\n","                class_weight = None):\n","\n","        self.model = HistGradientBoostingClassifier(loss=loss,\n","                    learning_rate=learning_rate,\n","                    max_iter=max_iter,\n","                    max_leaf_nodes=max_leaf_nodes,\n","                    max_depth=max_depth,\n","                    min_samples_leaf=min_samples_leaf,\n","                    l2_regularization=l2_regularization,\n","                    max_bins=max_bins,\n","                    categorical_features=categorical_features,\n","                    monotonic_cst=monotonic_cst,\n","                    interaction_cst=interaction_cst,\n","                    warm_start=warm_start,\n","                    early_stopping=early_stopping,\n","                    scoring=scoring,\n","                    validation_fraction=validation_fraction,\n","                    n_iter_no_change=n_iter_no_change,\n","                    tol=tol,\n","                    verbose=verbose,\n","                    random_state=random_state,\n","                    class_weight=class_weight)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MyMLPClassifier (MyClassifier, MLPClassifier):\n","    def __init__(self, targetVar=None,\n","                 random_state=0,\n","                 activation='relu',\n","                 early_stopping=True,  # False,\n","                 validation_fraction=.2,  # 0.1,\n","                 n_iter_no_change=TfPatience,  # 10,\n","                 batch_size=TfBatchSize,  # \"auto\",\n","                 hidden_layer_sizes=(100,),\n","                 verbose=False, max_iter=200):\n","        self.targetVar = targetVar\n","        self.random_state = random_state\n","        self.activation = activation\n","        self.hidden_layer_sizes = hidden_layer_sizes\n","        self.batch_size = batch_size\n","        self.early_stopping = early_stopping\n","        self.validation_fraction = validation_fraction\n","        self.n_iter_no_change = n_iter_no_change\n","        self.verbose = verbose\n","        self.max_iter = max_iter\n","        self.model = MLPClassifier(random_state=self.random_state,\n","                                   activation=self.activation,\n","                                   hidden_layer_sizes=self.hidden_layer_sizes,\n","                                   batch_size=self.batch_size,\n","                                   n_iter_no_change=self.n_iter_no_change,\n","                                   validation_fraction=self.validation_fraction,\n","                                   early_stopping=self.early_stopping,\n","                                   verbose=self.verbose, max_iter=self.max_iter\n","                                   )\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MyTfRNNClassifier (MyTfANN):\n","    def __init__(self, targetVar, phase, hidden_layer_sizes=(2, 2, 2),\n","                 hidden_layer_dropout_rates=(.2, .2, .2),\n","                 hidden_layer_activations=('relu', 'relu', 'relu'),\n","                 learningRate=3e-3,\n","                 inpute_layer_dropout_rate=.2):\n","        MyTfANN.__init__(self=self, targetVar=targetVar,\n","                         phase=phase,\n","                         hidden_layer_sizes=hidden_layer_sizes,\n","                         hidden_layer_dropout_rates=hidden_layer_dropout_rates,\n","                         hidden_layer_activations=hidden_layer_activations,\n","                         learningRate=learningRate,\n","                         inpute_layer_dropout_rate=inpute_layer_dropout_rate,\n","                         hidden_layer_functions=[keras.layers.LSTM],\n","                         outputActivationFunction='sigmoid',\n","                         loss='mse',\n","                         batch_size=1)\n","class MyTfMLPClassifier (MyTfANN):\n","    def __init__(self, targetVar, phase, hidden_layer_sizes=(2, 2, 2),\n","                 hidden_layer_dropout_rates=(.2, .2, .2),\n","                 hidden_layer_activations=('relu', 'relu', 'relu'),\n","                 learningRate=3e-3,\n","                 inpute_layer_dropout_rate=.2):\n","        MyTfANN.__init__(self=self, targetVar=targetVar,\n","                         phase=phase,\n","                         hidden_layer_sizes=hidden_layer_sizes,\n","                         hidden_layer_dropout_rates=hidden_layer_dropout_rates,\n","                         hidden_layer_activations=hidden_layer_activations,\n","                         learningRate=learningRate,\n","                         inpute_layer_dropout_rate=inpute_layer_dropout_rate,\n","                         hidden_layer_functions=[keras.layers.Dense],\n","                         outputActivationFunction='sigmoid',\n","                         loss='mse',\n","                         batch_size=TfBatchSize)\n","class MyXGBClassifier (MyClassifier, MyXGB):\n","    def __init__(self, targetVar=None, colsample_bytree=1, eta=0.3, max_depth=6, n_estimators=100,\n","                 objective='reg:squarederror', seed=0, subsample=1, gamma=0, learning_rate = 0.3,\n","                booster = 'gbtree',\n","                reg_lambda = 1,\n","                alpha = 0,\n","                min_child_weight = 1,\n","                grow_policy = 'depthwise',\n","                n_jobs = -1,\n","                verbosity = 0):\n","        self.model = xg.XGBClassifier(colsample_bytree=colsample_bytree,\n","                                      eta=eta, max_depth=max_depth,\n","                                      n_estimators=n_estimators, subsample=subsample,\n","                                      objective=objective, seed=seed, gamma=gamma,\n","                        booster = booster,\n","                        reg_lambda = reg_lambda,\n","                        alpha = alpha,\n","                        min_child_weight = min_child_weight,\n","                        grow_policy = grow_policy,\n","                        n_jobs = n_jobs,\n","                        verbosity = verbosity)\n","        MyXGB.__init__(self, targetVar=targetVar,\n","                       colsample_bytree=colsample_bytree,\n","                       eta=eta, max_depth=max_depth, n_estimators=n_estimators,\n","                       objective=objective, seed=seed, subsample=subsample, gamma=gamma,\n","                       model=self.model, learning_rate = learning_rate,\n","                        booster = booster,\n","                        reg_lambda = reg_lambda,\n","                        alpha = alpha,\n","                        min_child_weight = min_child_weight,\n","                        grow_policy = grow_policy,\n","                        n_jobs = n_jobs,\n","                        verbosity = verbosity,\n","                        )\n","\n","    def loadModel(self, path):\n","        try:\n","            self.model.load_model(path)\n","        except:\n","            fileNm = path.split('/')\n","            fileNm = fileNm[len(fileNm)-1]\n","            path2 = foldersVerification(RESULTS_ROOT)+fileNm\n","            self.model.load_model(path2)\n","        return self.model\n","class MyLGBMClassifier (MyClassifier, MyLGBM):\n","    def __init__(self, targetVar=None, min_split_gain=0,\n","                 learning_rate=0.1,\n","                 min_child_samples=20,\n","                 max_depth=-1,\n","                 n_estimators=100,\n","                 random_state=0,\n","                 num_leaves=31):\n","\n","        self.model = lgb.LGBMClassifier(min_split_gain=min_split_gain,\n","                                        learning_rate=learning_rate,\n","                                        min_child_samples=min_child_samples,\n","                                        max_depth=max_depth,\n","                                        n_estimators=n_estimators,\n","                                        random_state=random_state,\n","                                        num_leaves=num_leaves)\n","\n","        MyLGBM.__init__(self, targetVar=targetVar, min_split_gain=min_split_gain,\n","                        learning_rate=learning_rate,\n","                        min_child_samples=min_child_samples,\n","                        max_depth=max_depth,\n","                        n_estimators=n_estimators,\n","                        random_state=random_state,\n","                        num_leaves=num_leaves,\n","                        model=self.model, eval_metric=\"binary:logistic\")\n","\n","    def predict(self, X):\n","        try:\n","            ret = self.model.predict_proba(X)[:, 1]  # , verbose=False)\n","        except:\n","            ret = self.model.predict(X)\n","        # ret = list(np.concatenate(ret, axis=0 ))\n","        # ret = ret[:, 1]\n","        return ret.tolist()\n","class MyCatBClassifier (MyClassifier, CatBoostClassifier):\n","    def __init__(self, targetVar=None, \n","                iterations = None,\n","                learning_rate = None,\n","                depth = None,\n","                l2_leaf_reg = None,\n","                model_size_reg = None,\n","                rsm = None,\n","                loss_function = None,\n","                border_count = None,\n","                feature_border_type = None,\n","                per_float_feature_quantization = None,\n","                input_borders = None,\n","                output_borders = None,\n","                fold_permutation_block = None,\n","                od_pval = None,\n","                od_wait = None,\n","                od_type = None,\n","                nan_mode = None,\n","                counter_calc_method = None,\n","                leaf_estimation_iterations = None,\n","                leaf_estimation_method = None,\n","                thread_count = None,\n","                random_seed = None,\n","                use_best_model = None,\n","                verbose = None,\n","                logging_level = None,\n","                metric_period = None,\n","                ctr_leaf_count_limit = None,\n","                store_all_simple_ctr = None,\n","                max_ctr_complexity = None,\n","                has_time = None,\n","                allow_const_label = None,\n","                classes_count = None,\n","                class_weights = None,\n","                auto_class_weights = None,\n","                one_hot_max_size = None,\n","                random_strength = None,\n","                name = None,\n","                ignored_features = None,\n","                train_dir = None,\n","                custom_loss = None,\n","                custom_metric = None,\n","                eval_metric = None,\n","                bagging_temperature = None,\n","                save_snapshot = None,\n","                snapshot_file = None,\n","                snapshot_interval = None,\n","                fold_len_multiplier = None,\n","                used_ram_limit = None,\n","                gpu_ram_part = None,\n","                allow_writing_files = None,\n","                final_ctr_computation_mode = None,\n","                approx_on_full_history = None,\n","                boosting_type = None,\n","                simple_ctr = None,\n","                combinations_ctr = None,\n","                per_feature_ctr = None,\n","                task_type = None,\n","                device_config = None,\n","                devices = None,\n","                bootstrap_type = None,\n","                subsample = None,\n","                sampling_unit = None,\n","                dev_score_calc_obj_block_size = None,\n","                max_depth = None,\n","                n_estimators = None,\n","                num_boost_round = None,\n","                num_trees = None,\n","                colsample_bylevel = None,\n","                random_state = None,\n","                reg_lambda = None,\n","                objective = None,\n","                eta = None,\n","                max_bin = None,\n","                scale_pos_weight = None,\n","                gpu_cat_features_storage = None,\n","                data_partition = None,\n","                metadata = None,\n","                early_stopping_rounds = None,\n","                cat_features = None,\n","                grow_policy = None,\n","                min_data_in_leaf = None,\n","                min_child_samples = None,\n","                max_leaves = None,\n","                num_leaves = None,\n","                score_function = None,\n","                leaf_estimation_backtracking = None,\n","                ctr_history_unit = None,\n","                monotone_constraints = None,\n","                feature_weights = None,\n","                penalties_coefficient = None,\n","                first_feature_use_penalties = None,\n","                model_shrink_rate = None,\n","                model_shrink_mode = None,\n","                langevin = None,\n","                diffusion_temperature = None,\n","                posterior_sampling = None,\n","                boost_from_average = None,\n","                text_features = None,\n","                tokenizers = None,\n","                dictionaries = None,\n","                feature_calcers = None,\n","                text_processing = None,\n","                fixed_binary_splits = None):\n","\n","        self.model = CatBoostClassifier(iterations = iterations,\n","                         learning_rate = learning_rate,\n","                         depth = depth,\n","                         l2_leaf_reg = l2_leaf_reg,\n","                         model_size_reg = model_size_reg,\n","                         rsm = rsm,\n","                         loss_function = loss_function,\n","                         border_count = border_count,\n","                         feature_border_type = feature_border_type,\n","                         per_float_feature_quantization = per_float_feature_quantization,\n","                         input_borders = input_borders,\n","                         output_borders = output_borders,\n","                         fold_permutation_block = fold_permutation_block,\n","                         od_pval = od_pval,\n","                         od_wait = od_wait,\n","                         od_type = od_type,\n","                         nan_mode = nan_mode,\n","                         counter_calc_method = counter_calc_method,\n","                         leaf_estimation_iterations = leaf_estimation_iterations,\n","                         leaf_estimation_method = leaf_estimation_method,\n","                         thread_count = thread_count,\n","                         random_seed = random_seed,\n","                         use_best_model = use_best_model,\n","                         verbose = verbose,\n","                         logging_level = logging_level,\n","                         metric_period = metric_period,\n","                         ctr_leaf_count_limit = ctr_leaf_count_limit,\n","                         store_all_simple_ctr = store_all_simple_ctr,\n","                         max_ctr_complexity = max_ctr_complexity,\n","                         has_time = has_time,\n","                         allow_const_label = allow_const_label,\n","                         classes_count = classes_count,\n","                         class_weights = class_weights,\n","                         auto_class_weights = auto_class_weights,\n","                         one_hot_max_size = one_hot_max_size,\n","                         random_strength = random_strength,\n","                         name = name,\n","                         ignored_features = ignored_features,\n","                         train_dir = train_dir,\n","                         custom_loss = custom_loss,\n","                         custom_metric = custom_metric,\n","                         eval_metric = eval_metric,\n","                         bagging_temperature = bagging_temperature,\n","                         save_snapshot = save_snapshot,\n","                         snapshot_file = snapshot_file,\n","                         snapshot_interval = snapshot_interval,\n","                         fold_len_multiplier = fold_len_multiplier,\n","                         used_ram_limit = used_ram_limit,\n","                         gpu_ram_part = gpu_ram_part,\n","                         allow_writing_files = allow_writing_files,\n","                         final_ctr_computation_mode = final_ctr_computation_mode,\n","                         approx_on_full_history = approx_on_full_history,\n","                         boosting_type = boosting_type,\n","                         simple_ctr = simple_ctr,\n","                         combinations_ctr = combinations_ctr,\n","                         per_feature_ctr = per_feature_ctr,\n","                         task_type = task_type,\n","                         device_config = device_config,\n","                         devices = devices,\n","                         bootstrap_type = bootstrap_type,\n","                         subsample = subsample,\n","                         sampling_unit = sampling_unit,\n","                         dev_score_calc_obj_block_size = dev_score_calc_obj_block_size,\n","                         max_depth = max_depth,\n","                         n_estimators = n_estimators,\n","                         num_boost_round = num_boost_round,\n","                         num_trees = num_trees,\n","                         colsample_bylevel = colsample_bylevel,\n","                         random_state = random_state,\n","                         reg_lambda = reg_lambda,\n","                         objective = objective,\n","                         eta = eta,\n","                         max_bin = max_bin,\n","                         scale_pos_weight = scale_pos_weight,\n","                         gpu_cat_features_storage = gpu_cat_features_storage,\n","                         data_partition = data_partition,\n","                         metadata = metadata,\n","                         early_stopping_rounds = early_stopping_rounds,\n","                         cat_features = cat_features,\n","                         grow_policy = grow_policy,\n","                         min_data_in_leaf = min_data_in_leaf,\n","                         min_child_samples = min_child_samples,\n","                         max_leaves = max_leaves,\n","                         num_leaves = num_leaves,\n","                         score_function = score_function,\n","                         leaf_estimation_backtracking = leaf_estimation_backtracking,\n","                         ctr_history_unit = ctr_history_unit,\n","                         monotone_constraints = monotone_constraints,\n","                         feature_weights = feature_weights,\n","                         penalties_coefficient = penalties_coefficient,\n","                         first_feature_use_penalties = first_feature_use_penalties,\n","                         model_shrink_rate = model_shrink_rate,\n","                         model_shrink_mode = model_shrink_mode,\n","                         langevin = langevin,\n","                         diffusion_temperature = diffusion_temperature,\n","                         posterior_sampling = posterior_sampling,\n","                         boost_from_average = boost_from_average,\n","                         text_features = text_features,\n","                         tokenizers = tokenizers,\n","                         dictionaries = dictionaries,\n","                         feature_calcers = feature_calcers,\n","                         text_processing = text_processing,\n","                         fixed_binary_splits = fixed_binary_splits)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","\n","# regressors\n","class MyLinearRegressor (MyRegressor, LinearRegression):\n","    def __init__(self, targetVar=None, fit_intercept=True):\n","        self.targetVar = targetVar\n","        self.fit_intercept = fit_intercept\n","\n","        self.model = LinearRegression(fit_intercept=fit_intercept)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","\n","    def predict(self, X):\n","        # the usual function for sklearn regressors\n","        ret = self.model.predict(X)[:, 0]\n","        # if not isWithOptimization:\n","        # ret = ret[:,1]#[v[1] for v in ret0]\n","        # ret = list(np.concatenate(ret, axis=0 ))\n","        return ret.tolist()\n","class MySVR (MyRegressor, SVR):\n","    def __init__(self, targetVar=None,\n","                 C=1,\n","                 epsilon=0.1,\n","                 coef0=0,\n","                 degree=3,\n","                 gamma='scale',\n","                 kernel='rbf',\n","                 tol=1e-3):\n","        self.targetVar = targetVar\n","        self.C = C\n","        self.epsilon = epsilon\n","        self.coef0 = coef0\n","        self.degree = degree\n","        self.gamma = gamma\n","        self.kernel = kernel\n","        self.tol = tol\n","\n","        self.model = SVR(C=C, epsilon=epsilon,\n","                         coef0=coef0,\n","                         degree=degree,\n","                         gamma=gamma,\n","                         kernel=kernel,\n","                         tol=tol,\n","                         verbose=False)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MyDecisionTreeRegressor (MyRegressor, DecisionTreeRegressor):\n","    def __init__(self, targetVar=None,\n","                 ccp_alpha=0,\n","                 max_depth=None,\n","                 min_samples_leaf=1,\n","                 min_samples_split=2,\n","                 splitter='best'):\n","        # self.targetVar = targetVar\n","        self.ccp_alpha = ccp_alpha\n","        self.max_depth = max_depth\n","        self.min_samples_leaf = min_samples_leaf\n","        self.min_samples_split = min_samples_split\n","        self.splitter = splitter\n","\n","        self.model = DecisionTreeRegressor(\n","            ccp_alpha=self.ccp_alpha,\n","            max_depth=self.max_depth,\n","            min_samples_leaf=self.min_samples_leaf,\n","            min_samples_split=self.min_samples_split,\n","            splitter=self.splitter,\n","            random_state=0)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MyRandomForestRegressor (MyRegressor, RandomForestRegressor):\n","    def __init__(self, targetVar=None,\n","                 n_estimators=100,\n","                 ccp_alpha=0,\n","                 max_depth=None,\n","                 min_samples_leaf=1,\n","                 min_samples_split=2):\n","        # self.targetVar = targetVar\n","        self.n_estimators = n_estimators\n","        self.ccp_alpha = ccp_alpha\n","        self.max_depth = max_depth\n","        self.min_samples_leaf = min_samples_leaf\n","        self.min_samples_split = min_samples_split\n","\n","        self.model = RandomForestRegressor(\n","            ccp_alpha=self.ccp_alpha,\n","            max_depth=self.max_depth,\n","            min_samples_leaf=self.min_samples_leaf,\n","            min_samples_split=self.min_samples_split,\n","            random_state=0)\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MyHistGBRegressor (MyRegressor, HistGradientBoostingRegressor):\n","    def __init__(self, targetVar=None, \n","                loss  = \"squared_error\",\n","                quantile  = None,\n","                learning_rate  = 0.1,\n","                max_iter  =  100,\n","                max_leaf_nodes  =  31,\n","                max_depth  = None,\n","                min_samples_leaf  =  20,\n","                l2_regularization  =  0,\n","                max_bins  =  255,\n","                categorical_features  = None,\n","                monotonic_cst  = None,\n","                interaction_cst  = None,\n","                warm_start  = False,\n","                early_stopping  = \"auto\",\n","                scoring  = \"loss\",\n","                validation_fraction  = 0.1,\n","                n_iter_no_change  =  10,\n","                tol  =  1e-07,\n","                verbose  =  0,\n","                random_state  = None):\n","\n","        self.model = HistGradientBoostingRegressor(loss  =  loss,\n","                            quantile  =  quantile,\n","                            learning_rate  =  learning_rate,\n","                            max_iter  =  max_iter,\n","                            max_leaf_nodes  =  max_leaf_nodes,\n","                            max_depth  =  max_depth,\n","                            min_samples_leaf  =  min_samples_leaf,\n","                            l2_regularization  =  l2_regularization,\n","                            max_bins  =  max_bins,\n","                            categorical_features  =  categorical_features,\n","                            monotonic_cst  =  monotonic_cst,\n","                            interaction_cst  =  interaction_cst,\n","                            warm_start  =  warm_start,\n","                            early_stopping  =  early_stopping,\n","                            scoring  =  scoring,\n","                            validation_fraction  =  validation_fraction,\n","                            n_iter_no_change  =  n_iter_no_change,\n","                            tol  =  tol,\n","                            verbose  =  verbose,\n","                            random_state  =  random_state\n","                            )\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MyMLPRegressor (MyRegressor, MLPRegressor):\n","    def __init__(self, targetVar=None,\n","                 random_state=0, activation='relu',\n","                 early_stopping=False,\n","                 validation_fraction=0.1,\n","                 n_iter_no_change=10,\n","                 batch_size=\"auto\", hidden_layer_sizes=(100,),\n","                 verbose=False, max_iter=200):\n","        # self.targetVar = targetVar\n","        self.random_state = random_state\n","        self.activation = activation\n","        self.hidden_layer_sizes = hidden_layer_sizes\n","        self.batch_size = batch_size\n","        self.early_stopping = early_stopping\n","        self.validation_fraction = validation_fraction\n","        self.n_iter_no_change = n_iter_no_change\n","        self.verbose = verbose\n","        self.max_iter = max_iter\n","        self.model = MLPRegressor(random_state=self.random_state,\n","                                  activation=self.activation,\n","                                  hidden_layer_sizes=self.hidden_layer_sizes,\n","                                  batch_size=self.batch_size,\n","                                  n_iter_no_change=self.n_iter_no_change,\n","                                  validation_fraction=self.validation_fraction,\n","                                  early_stopping=self.early_stopping,\n","                                  verbose=self.verbose, max_iter=self.max_iter\n","                                  )\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","class MyTfRNNRegressor (MyTfANN):\n","    def __init__(self, targetVar, phase, hidden_layer_sizes=(2, 2, 2),\n","                 hidden_layer_dropout_rates=(.2, .2, .2),\n","                 hidden_layer_activations=('relu', 'relu', 'relu'),\n","                 learningRate=3e-3,\n","                 inpute_layer_dropout_rate=.2):\n","        MyTfANN.__init__(self=self, targetVar=targetVar,\n","                         phase=phase,\n","                         hidden_layer_sizes=hidden_layer_sizes,\n","                         hidden_layer_dropout_rates=hidden_layer_dropout_rates,\n","                         hidden_layer_activations=hidden_layer_activations,\n","                         learningRate=learningRate,\n","                         inpute_layer_dropout_rate=inpute_layer_dropout_rate,\n","                         hidden_layer_functions=[keras.layers.LSTM],\n","                         outputActivationFunction='linear',\n","                         loss='mse')  # 'log_loss'\n","class MyTfMLPRegressor (MyTfANN):\n","    def __init__(self, targetVar, phase, hidden_layer_sizes=(2, 2, 2),\n","                 hidden_layer_dropout_rates=(.2, .2, .2),\n","                 hidden_layer_activations=('relu', 'relu', 'relu'),\n","                 learningRate=3e-3,\n","                 inpute_layer_dropout_rate=.2):\n","        MyTfANN.__init__(self=self, targetVar=targetVar,\n","                         phase=phase,\n","                         hidden_layer_sizes=hidden_layer_sizes,\n","                         hidden_layer_dropout_rates=hidden_layer_dropout_rates,\n","                         hidden_layer_activations=hidden_layer_activations,\n","                         learningRate=learningRate,\n","                         inpute_layer_dropout_rate=inpute_layer_dropout_rate,\n","                         hidden_layer_functions=[keras.layers.Dense],\n","                         outputActivationFunction='linear',\n","                         loss='mse')  # 'log_loss'\n","class MyXGBRegressor (MyRegressor, MyXGB):\n","    def __init__(self, targetVar=None, colsample_bytree=1, eta=0.3,\n","                 max_depth=6, n_estimators=100,\n","                 objective='reg:squarederror', seed=0, subsample=1, gamma=0):\n","        self.model = xg.XGBRegressor(colsample_bytree=colsample_bytree,\n","                                     eta=eta, max_depth=max_depth,\n","                                     n_estimators=n_estimators, subsample=subsample,\n","                                     objective=objective, seed=seed, gamma=gamma)\n","        MyXGB.__init__(self, targetVar=targetVar,\n","                       colsample_bytree=colsample_bytree,\n","                       eta=eta, max_depth=max_depth, n_estimators=n_estimators,\n","                       objective=objective, seed=seed, subsample=subsample, gamma=gamma,\n","                       model=self.model)\n","class MyLGBMRegressor (MyRegressor, MyLGBM):\n","    def __init__(self, targetVar=None, min_split_gain=0,\n","                 learning_rate=0.1,\n","                 min_child_samples=20,\n","                 max_depth=-1,\n","                 n_estimators=100,\n","                 random_state=0,\n","                 num_leaves=31):\n","\n","        self.model = lgb.LGBMRegressor(min_split_gain=min_split_gain,\n","                                       learning_rate=learning_rate,\n","                                       min_child_samples=min_child_samples,\n","                                       max_depth=max_depth,\n","                                       n_estimators=n_estimators,\n","                                       random_state=random_state,\n","                                       num_leaves=num_leaves)\n","\n","        MyLGBM.__init__(self, targetVar=targetVar, min_split_gain=min_split_gain,\n","                        learning_rate=learning_rate,\n","                        min_child_samples=min_child_samples,\n","                        max_depth=max_depth,\n","                        n_estimators=n_estimators,\n","                        random_state=random_state,\n","                        num_leaves=num_leaves,\n","                        model=self.model, eval_metric=\"rmse\")\n","class MyCatBRegressor (MyRegressor, CatBoostRegressor):\n","    def __init__(self, targetVar=None, \n","                iterations = None,\n","                learning_rate = None,\n","                depth = None,\n","                l2_leaf_reg = None,\n","                model_size_reg = None,\n","                rsm = None,\n","                loss_function = 'RMSE',\n","                border_count = None,\n","                feature_border_type = None,\n","                per_float_feature_quantization = None,\n","                input_borders = None,\n","                output_borders = None,\n","                fold_permutation_block = None,\n","                od_pval = None,\n","                od_wait = None,\n","                od_type = None,\n","                nan_mode = None,\n","                counter_calc_method = None,\n","                leaf_estimation_iterations = None,\n","                leaf_estimation_method = None,\n","                thread_count = None,\n","                random_seed = None,\n","                use_best_model = None,\n","                best_model_min_trees = None,\n","                verbose = None,\n","                silent = None,\n","                logging_level = None,\n","                metric_period = None,\n","                ctr_leaf_count_limit = None,\n","                store_all_simple_ctr = None,\n","                max_ctr_complexity = None,\n","                has_time = None,\n","                allow_const_label = None,\n","                one_hot_max_size = None,\n","                random_strength = None,\n","                name = None,\n","                ignored_features = None,\n","                train_dir = None,\n","                custom_metric = None,\n","                eval_metric = None,\n","                bagging_temperature = None,\n","                save_snapshot = None,\n","                snapshot_file = None,\n","                snapshot_interval = None,\n","                fold_len_multiplier = None,\n","                used_ram_limit = None,\n","                gpu_ram_part = None,\n","                pinned_memory_size = None,\n","                allow_writing_files = None,\n","                final_ctr_computation_mode = None,\n","                approx_on_full_history = None,\n","                boosting_type = None,\n","                simple_ctr = None,\n","                combinations_ctr = None,\n","                per_feature_ctr = None,\n","                ctr_target_border_count = None,\n","                task_type = None,\n","                device_config = None,\n","                devices = None,\n","                bootstrap_type = None,\n","                subsample = None,\n","                sampling_unit = None,\n","                dev_score_calc_obj_block_size = None,\n","                max_depth = None,\n","                n_estimators = None,\n","                num_boost_round = None,\n","                num_trees = None,\n","                colsample_bylevel = None,\n","                random_state = None,\n","                reg_lambda = None,\n","                objective = None,\n","                eta = None,\n","                max_bin = None,\n","                gpu_cat_features_storage = None,\n","                data_partition = None,\n","                metadata = None,\n","                early_stopping_rounds = None,\n","                cat_features = None,\n","                grow_policy = None,\n","                min_data_in_leaf = None,\n","                min_child_samples = None,\n","                max_leaves = None,\n","                num_leaves = None,\n","                score_function = None,\n","                leaf_estimation_backtracking = None,\n","                ctr_history_unit = None,\n","                monotone_constraints = None,\n","                feature_weights = None,\n","                penalties_coefficient = None,\n","                first_feature_use_penalties = None,\n","                model_shrink_rate = None,\n","                model_shrink_mode = None,\n","                langevin = None,\n","                diffusion_temperature = None,\n","                posterior_sampling = None,\n","                boost_from_average = None,\n","                fixed_binary_splits = None):\n","\n","        self.model = CatBoostRegressor(iterations = iterations,\n","                        learning_rate = learning_rate,\n","                        depth = depth,\n","                        l2_leaf_reg = l2_leaf_reg,\n","                        model_size_reg = model_size_reg,\n","                        rsm = rsm,\n","                        loss_function = loss_function,\n","                        border_count = border_count,\n","                        feature_border_type = feature_border_type,\n","                        per_float_feature_quantization = per_float_feature_quantization,\n","                        input_borders = input_borders,\n","                        output_borders = output_borders,\n","                        fold_permutation_block = fold_permutation_block,\n","                        od_pval = od_pval,\n","                        od_wait = od_wait,\n","                        od_type = od_type,\n","                        nan_mode = nan_mode,\n","                        counter_calc_method = counter_calc_method,\n","                        leaf_estimation_iterations = leaf_estimation_iterations,\n","                        leaf_estimation_method = leaf_estimation_method,\n","                        thread_count = thread_count,\n","                        random_seed = random_seed,\n","                        use_best_model = use_best_model,\n","                        best_model_min_trees = best_model_min_trees,\n","                        verbose = verbose,\n","                        silent = silent,\n","                        logging_level = logging_level,\n","                        metric_period = metric_period,\n","                        ctr_leaf_count_limit = ctr_leaf_count_limit,\n","                        store_all_simple_ctr = store_all_simple_ctr,\n","                        max_ctr_complexity = max_ctr_complexity,\n","                        has_time = has_time,\n","                        allow_const_label = allow_const_label,\n","                        one_hot_max_size = one_hot_max_size,\n","                        random_strength = random_strength,\n","                        name = name,\n","                        ignored_features = ignored_features,\n","                        train_dir = train_dir,\n","                        custom_metric = custom_metric,\n","                        eval_metric = eval_metric,\n","                        bagging_temperature = bagging_temperature,\n","                        save_snapshot = save_snapshot,\n","                        snapshot_file = snapshot_file,\n","                        snapshot_interval = snapshot_interval,\n","                        fold_len_multiplier = fold_len_multiplier,\n","                        used_ram_limit = used_ram_limit,\n","                        gpu_ram_part = gpu_ram_part,\n","                        pinned_memory_size = pinned_memory_size,\n","                        allow_writing_files = allow_writing_files,\n","                        final_ctr_computation_mode = final_ctr_computation_mode,\n","                        approx_on_full_history = approx_on_full_history,\n","                        boosting_type = boosting_type,\n","                        simple_ctr = simple_ctr,\n","                        combinations_ctr = combinations_ctr,\n","                        per_feature_ctr = per_feature_ctr,\n","                        ctr_target_border_count = ctr_target_border_count,\n","                        task_type = task_type,\n","                        device_config = device_config,\n","                        devices = devices,\n","                        bootstrap_type = bootstrap_type,\n","                        subsample = subsample,\n","                        sampling_unit = sampling_unit,\n","                        dev_score_calc_obj_block_size = dev_score_calc_obj_block_size,\n","                        max_depth = max_depth,\n","                        n_estimators = n_estimators,\n","                        num_boost_round = num_boost_round,\n","                        num_trees = num_trees,\n","                        colsample_bylevel = colsample_bylevel,\n","                        random_state = random_state,\n","                        reg_lambda = reg_lambda,\n","                        objective = objective,\n","                        eta = eta,\n","                        max_bin = max_bin,\n","                        gpu_cat_features_storage = gpu_cat_features_storage,\n","                        data_partition = data_partition,\n","                        metadata = metadata,\n","                        early_stopping_rounds = early_stopping_rounds,\n","                        cat_features = cat_features,\n","                        grow_policy = grow_policy,\n","                        min_data_in_leaf = min_data_in_leaf,\n","                        min_child_samples = min_child_samples,\n","                        max_leaves = max_leaves,\n","                        num_leaves = num_leaves,\n","                        score_function = score_function,\n","                        leaf_estimation_backtracking = leaf_estimation_backtracking,\n","                        ctr_history_unit = ctr_history_unit,\n","                        monotone_constraints = monotone_constraints,\n","                        feature_weights = feature_weights,\n","                        penalties_coefficient = penalties_coefficient,\n","                        first_feature_use_penalties = first_feature_use_penalties,\n","                        model_shrink_rate = model_shrink_rate,\n","                        model_shrink_mode = model_shrink_mode,\n","                        langevin = langevin,\n","                        diffusion_temperature = diffusion_temperature,\n","                        posterior_sampling = posterior_sampling,\n","                        boost_from_average = boost_from_average,\n","                        fixed_binary_splits = fixed_binary_splits,\n","                        )\n","        MyEstimator.__init__(self=self, targetVar=targetVar, model=self.model,\n","                             saveExtension='.sav', xVarsNms=None)\n","        "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:35.342196Z","iopub.status.busy":"2023-05-05T21:24:35.341736Z","iopub.status.idle":"2023-05-05T21:24:44.198980Z","shell.execute_reply":"2023-05-05T21:24:44.197412Z","shell.execute_reply.started":"2023-05-05T21:24:35.342158Z"},"trusted":true},"outputs":[],"source":["#initialModelsObjs\n","initialModelsObjs['MyLinearRegressor'] = MyLinearRegressor(u, fit_intercept = True)\n","initialModelsObjs['MyLogisticRegression'] = MyLogisticRegression(u, verbose=True, \n","                                                                 C = 1.5, \n","                                                                 tol = 1e-1,\n","                                                                 max_iter=100, \n","                                                                 fit_intercept = True)\n","initialModelsObjs['MySVC'] = MySVC(u, C=1, gamma = 1/(nImportantFeatures*4))\n","initialModelsObjs['MyLGBMClassifier'] = MyLGBMClassifier(u)#, min_split_gain = .01, learning_rate= 0.05, min_child_samples=1000, n_estimators = 70)\n","initialModelsObjs['MyXGBClassifier'] = MyXGBClassifier(u, n_estimators = 100,\n","                                        learning_rate = 0.413327571405248,\n","                                        booster = 'gbtree',\n","                                        reg_lambda = 0.0000263894617720096,\n","                                        alpha = 0.000463768723479341,\n","                                        subsample = 0.237467672874133,\n","                                        colsample_bytree = 0.618829300507829,\n","                                        max_depth = 5,\n","                                        min_child_weight = 9,\n","                                        eta = 2.09477807126539E-06,\n","                                        gamma = 0.000847289463422307,\n","                                        grow_policy = 'depthwise',\n","                                        n_jobs = -1,\n","                                        objective = 'binary:logistic',\n","                                        # eval_metric = 'logloss',\n","                                        verbosity = 0)\n","initialModelsObjs['MyDecisionTreeClassifier'] = MyDecisionTreeClassifier(u, min_samples_leaf= 20)\n","initialModelsObjs['MyRandomForestClassifier'] = MyRandomForestClassifier(u, min_samples_split=80, n_estimators=4)\n","initialModelsObjs['MyMLPClassifier'] = MyMLPClassifier(u, \n","                hidden_layer_sizes=[100, 50, 20, 10, 5],\n","                early_stopping= True, \n","                validation_fraction = 0.2, \n","                verbose = True,\n","                n_iter_no_change = TfPatience, \n","                batch_size=TfBatchSize)\n","initialModelsObjs['MyTfMLPClassifier'] = MyTfMLPClassifier(u,'initialModel', \n","        hidden_layer_sizes = [1],#[100, 50, 20, 10, 5], \n","        hidden_layer_dropout_rates = [0], \n","        hidden_layer_activations = ['relu'],#*5 + ['sigmoid']*3,#sigmoid\n","        learningRate = 1e-3, inpute_layer_dropout_rate = 0)\n","initialModelsObjs['MyTfRNNClassifier'] = MyTfRNNClassifier(u,'initialModel', \n","        hidden_layer_sizes = [100, 50, 20, 10, 5, 3, 2], \n","        hidden_layer_dropout_rates = [0], \n","        learningRate = 1e-3, inpute_layer_dropout_rate = 0)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:44.201536Z","iopub.status.busy":"2023-05-05T21:24:44.201153Z","iopub.status.idle":"2023-05-05T21:24:55.233442Z","shell.execute_reply":"2023-05-05T21:24:55.232131Z","shell.execute_reply.started":"2023-05-05T21:24:44.201502Z"},"trusted":true},"outputs":[],"source":["#errorModelsObjs\n","errorModelsObjs['MyDecisionTreeRegressor'] = MyDecisionTreeRegressor(u, ccp_alpha= 4.62257081366534e-08, max_depth= 2, min_samples_leaf= 27, min_samples_split= 2, splitter= 'best')\n","errorModelsObjs['MyLGBMRegressor'] = MyLGBMRegressor(u, learning_rate= 0.1, max_depth= 3, n_estimators= 5, num_leaves = 1000)\n","errorModelsObjs['MyRandomForestRegressor'] = MyRandomForestRegressor(u, min_samples_split=100, n_estimators=5)\n","errorModelsObjs['MyXGBRegressor'] = MyXGBRegressor(u, max_depth= 5, n_estimators= 1000)\n","errorModelsObjs['MySVR'] = MySVR(u, C= 1, coef0= 2, degree= 2, gamma= 0.2, kernel= 'poly')\n","errorModelsObjs['MyMLPRegressor'] = MyMLPRegressor(u, random_state=0, activation='relu', hidden_layer_sizes=(25, 15, 5, 3))\n","errorModelsObjs['MyTfMLPRegressor'] = MyTfMLPRegressor(u, 'errorModel', \n","        hidden_layer_sizes = (100, 60, 40, 30, 20, 10, 5, 3, 2), \n","        hidden_layer_dropout_rates = [0], \n","        hidden_layer_activations = ['relu'],#*5 + ['sigmoid']*3,#sigmoid\n","        learningRate = 1e-3, inpute_layer_dropout_rate = 0)\n","errorModelsObjs['MyTfRNNRegressor'] = MyTfRNNRegressor(u, 'errorModel', \n","        hidden_layer_sizes = [100, 50, 40, 30, 20, 10, 5, 3, 2], \n","        hidden_layer_dropout_rates = [0], \n","        learningRate = 1e-3, inpute_layer_dropout_rate = 0)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:55.235525Z","iopub.status.busy":"2023-05-05T21:24:55.235117Z","iopub.status.idle":"2023-05-05T21:24:55.246759Z","shell.execute_reply":"2023-05-05T21:24:55.245745Z","shell.execute_reply.started":"2023-05-05T21:24:55.235488Z"},"trusted":true},"outputs":[],"source":["#isToRunInitialModels, isToRunErrorModels, isToRunCombinerModels, isToRunXModels\n","isToRunInitialModels = {\n","        'MyLinearRegressor':        True,\n","        'MyLogisticRegression':     True,\n","        'MySVC':                    True,\n","        'MyLGBMClassifier':         True,\n","        'MyXGBClassifier':          True,\n","        'MyDecisionTreeClassifier': True,\n","        'MyRandomForestClassifier': True,\n","        'MyMLPClassifier':          False,\n","        'MyTfMLPClassifier':        False,\n","        'MyTfRNNClassifier':        False,\n","        }\n","isToRunErrorModels = {\n","        'MyDecisionTreeRegressor': True,\n","        'MyLGBMRegressor':         True,\n","        'MyRandomForestRegressor': True,\n","        'MyXGBRegressor':          True,\n","        'MySVR':                   True,\n","        'MyMLPRegressor':          False,\n","        'MyTfMLPRegressor':        False,\n","        'MyTfRNNRegressor':        False,\n","        }\n","\n","isToRunCombinerModels = {'cSA':  True,\n","                         'cMd':  True,\n","                         'cMV':  True,\n","                         'cRNN': False,\n","                         }\n","# isToRunXModels = {'xTransfLinear': True, #xModels['xTransfLinear']= MyLinearRegressor().fit(X=x.values.reshape(-1, 1), y=y)\n","#     'xTransfXg': True, #xModels['xTransfXg']= MyXGBClassifier(objective='reg:squarederror', seed=0).fit(X=x, y=y)\n","#     'xTransfSVC': True,#xModels['xTransfSVC']= MultiOutputClassifier(SVC(verbose=False)).fit(X = x.values.reshape(-1, 1), y = y)\n","# }#Try 'xTransfXg': False, 'xTransfSVC': False ... it achieved the my best public score (60.6)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Descriptive data analysis\n","\n","First of all, lets start loading the datasets"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:55.248970Z","iopub.status.busy":"2023-05-05T21:24:55.248226Z","iopub.status.idle":"2023-05-05T21:24:56.126379Z","shell.execute_reply":"2023-05-05T21:24:56.125408Z","shell.execute_reply.started":"2023-05-05T21:24:55.248929Z"},"trusted":true},"outputs":[],"source":["tv_general = pd.read_csv(DATA_ROOT+'train.csv')\n","tv_greeks = pd.read_csv(DATA_ROOT+'greeks.csv')\n","test_general = pd.read_csv(DATA_ROOT+'test.csv')\n","sample_submission = pd.read_csv(DATA_ROOT+'sample_submission.csv')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.129304Z","iopub.status.busy":"2023-05-05T21:24:56.127980Z","iopub.status.idle":"2023-05-05T21:24:56.138663Z","shell.execute_reply":"2023-05-05T21:24:56.137346Z","shell.execute_reply.started":"2023-05-05T21:24:56.129252Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["******** training-validation data ********\n","tv_general:  (617, 58)\n","tv_greeks:  (617, 6)\n","******** test data ********\n","test_general:  (5, 57)\n","******** sample_submission data ********\n","sample_submission:  (5, 3)\n"]}],"source":["#Seeing the datasets shape\n","print('******** training-validation data ********')\n","print('tv_general: ', tv_general.shape)\n","print('tv_greeks: ', tv_greeks.shape)\n","\n","print('******** test data ********')\n","print('test_general: ', test_general.shape)\n","\n","print('******** sample_submission data ********')\n","print('sample_submission: ', sample_submission.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["EJ\n","B    395\n","A    222\n","Name: count, dtype: int64"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["#the only categorical feature\n","tv_general.EJ.value_counts()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.144146Z","iopub.status.busy":"2023-05-05T21:24:56.143644Z","iopub.status.idle":"2023-05-05T21:24:56.155316Z","shell.execute_reply":"2023-05-05T21:24:56.153832Z","shell.execute_reply.started":"2023-05-05T21:24:56.144109Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["there is no variable named \"EJ\"\n","******** training-validation data ********\n","tv_general:  Index(['Id', 'AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BN',\n","       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CR', 'CS',\n","       'CU', 'CW', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n","       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD', 'FE', 'FI',\n","       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'Class'],\n","      dtype='object')\n","tv_greeks:  Index(['Id', 'Alpha', 'Beta', 'Gamma', 'Delta', 'Epsilon'], dtype='object')\n","******** test data ********\n","test_general:  Index(['Id', 'AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BN',\n","       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CR', 'CS',\n","       'CU', 'CW', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n","       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD', 'FE', 'FI',\n","       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","      dtype='object')\n","******** test data ********\n","sample_submission:  Index(['Id', 'class_0', 'class_1'], dtype='object')\n"]}],"source":["#Seeing the columns\n","def performPrimeTransformations(df):\n","    names = df.columns.tolist()\n","    features = [x.replace(' ', '') for x in names]\n","    df.columns = features    \n","    try:\n","        df['EJ'] = np.where(df['EJ'] == 'A', 0, 1)\n","    except:\n","        print('there is no variable named \"EJ\"')\n","\n","performPrimeTransformations(tv_general)\n","performPrimeTransformations(tv_greeks)\n","performPrimeTransformations(test_general)\n","\n","print('******** training-validation data ********')\n","print('tv_general: ', tv_general.columns)\n","print('tv_greeks: ', tv_greeks.columns)\n","\n","print('******** test data ********')\n","print('test_general: ', test_general.columns)\n","\n","print('******** test data ********')\n","print('sample_submission: ', sample_submission.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We can see that the datasets have some shared columns (visit_id, visit_month, Id) that we could use to merge the data and also columns that are specific for each dataset. "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.157715Z","iopub.status.busy":"2023-05-05T21:24:56.157220Z","iopub.status.idle":"2023-05-05T21:24:56.203384Z","shell.execute_reply":"2023-05-05T21:24:56.201985Z","shell.execute_reply.started":"2023-05-05T21:24:56.157667Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 617 entries, 0 to 616\n","Data columns (total 58 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   Id      617 non-null    object \n"," 1   AB      617 non-null    float64\n"," 2   AF      617 non-null    float64\n"," 3   AH      617 non-null    float64\n"," 4   AM      617 non-null    float64\n"," 5   AR      617 non-null    float64\n"," 6   AX      617 non-null    float64\n"," 7   AY      617 non-null    float64\n"," 8   AZ      617 non-null    float64\n"," 9   BC      617 non-null    float64\n"," 10  BD      617 non-null    float64\n"," 11  BN      617 non-null    float64\n"," 12  BP      617 non-null    float64\n"," 13  BQ      557 non-null    float64\n"," 14  BR      617 non-null    float64\n"," 15  BZ      617 non-null    float64\n"," 16  CB      615 non-null    float64\n"," 17  CC      614 non-null    float64\n"," 18  CD      617 non-null    float64\n"," 19  CF      617 non-null    float64\n"," 20  CH      617 non-null    float64\n"," 21  CL      617 non-null    float64\n"," 22  CR      617 non-null    float64\n"," 23  CS      617 non-null    float64\n"," 24  CU      617 non-null    float64\n"," 25  CW      617 non-null    float64\n"," 26  DA      617 non-null    float64\n"," 27  DE      617 non-null    float64\n"," 28  DF      617 non-null    float64\n"," 29  DH      617 non-null    float64\n"," 30  DI      617 non-null    float64\n"," 31  DL      617 non-null    float64\n"," 32  DN      617 non-null    float64\n"," 33  DU      616 non-null    float64\n"," 34  DV      617 non-null    float64\n"," 35  DY      617 non-null    float64\n"," 36  EB      617 non-null    float64\n"," 37  EE      617 non-null    float64\n"," 38  EG      617 non-null    float64\n"," 39  EH      617 non-null    float64\n"," 40  EJ      617 non-null    int32  \n"," 41  EL      557 non-null    float64\n"," 42  EP      617 non-null    float64\n"," 43  EU      617 non-null    float64\n"," 44  FC      616 non-null    float64\n"," 45  FD      617 non-null    float64\n"," 46  FE      617 non-null    float64\n"," 47  FI      617 non-null    float64\n"," 48  FL      616 non-null    float64\n"," 49  FR      617 non-null    float64\n"," 50  FS      615 non-null    float64\n"," 51  GB      617 non-null    float64\n"," 52  GE      617 non-null    float64\n"," 53  GF      617 non-null    float64\n"," 54  GH      617 non-null    float64\n"," 55  GI      617 non-null    float64\n"," 56  GL      616 non-null    float64\n"," 57  Class   617 non-null    int64  \n","dtypes: float64(55), int32(1), int64(1), object(1)\n","memory usage: 277.3+ KB\n"]}],"source":["#Looking closer to the data info of each dataset\n","tv_general.info()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.205686Z","iopub.status.busy":"2023-05-05T21:24:56.205015Z","iopub.status.idle":"2023-05-05T21:24:56.371394Z","shell.execute_reply":"2023-05-05T21:24:56.369808Z","shell.execute_reply.started":"2023-05-05T21:24:56.205641Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 617 entries, 0 to 616\n","Data columns (total 6 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   Id       617 non-null    object\n"," 1   Alpha    617 non-null    object\n"," 2   Beta     617 non-null    object\n"," 3   Gamma    617 non-null    object\n"," 4   Delta    617 non-null    object\n"," 5   Epsilon  617 non-null    object\n","dtypes: object(6)\n","memory usage: 29.0+ KB\n"]}],"source":["tv_greeks.info()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.374297Z","iopub.status.busy":"2023-05-05T21:24:56.373919Z","iopub.status.idle":"2023-05-05T21:24:56.392729Z","shell.execute_reply":"2023-05-05T21:24:56.391089Z","shell.execute_reply.started":"2023-05-05T21:24:56.374264Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5 entries, 0 to 4\n","Data columns (total 57 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   Id      5 non-null      object \n"," 1   AB      5 non-null      float64\n"," 2   AF      5 non-null      float64\n"," 3   AH      5 non-null      float64\n"," 4   AM      5 non-null      float64\n"," 5   AR      5 non-null      float64\n"," 6   AX      5 non-null      float64\n"," 7   AY      5 non-null      float64\n"," 8   AZ      5 non-null      float64\n"," 9   BC      5 non-null      float64\n"," 10  BD      5 non-null      float64\n"," 11  BN      5 non-null      float64\n"," 12  BP      5 non-null      float64\n"," 13  BQ      5 non-null      float64\n"," 14  BR      5 non-null      float64\n"," 15  BZ      5 non-null      float64\n"," 16  CB      5 non-null      float64\n"," 17  CC      5 non-null      float64\n"," 18  CD      5 non-null      float64\n"," 19  CF      5 non-null      float64\n"," 20  CH      5 non-null      float64\n"," 21  CL      5 non-null      float64\n"," 22  CR      5 non-null      float64\n"," 23  CS      5 non-null      float64\n"," 24  CU      5 non-null      float64\n"," 25  CW      5 non-null      float64\n"," 26  DA      5 non-null      float64\n"," 27  DE      5 non-null      float64\n"," 28  DF      5 non-null      float64\n"," 29  DH      5 non-null      float64\n"," 30  DI      5 non-null      float64\n"," 31  DL      5 non-null      float64\n"," 32  DN      5 non-null      float64\n"," 33  DU      5 non-null      float64\n"," 34  DV      5 non-null      float64\n"," 35  DY      5 non-null      float64\n"," 36  EB      5 non-null      float64\n"," 37  EE      5 non-null      float64\n"," 38  EG      5 non-null      float64\n"," 39  EH      5 non-null      float64\n"," 40  EJ      5 non-null      int32  \n"," 41  EL      5 non-null      float64\n"," 42  EP      5 non-null      float64\n"," 43  EU      5 non-null      float64\n"," 44  FC      5 non-null      float64\n"," 45  FD      5 non-null      float64\n"," 46  FE      5 non-null      float64\n"," 47  FI      5 non-null      float64\n"," 48  FL      5 non-null      float64\n"," 49  FR      5 non-null      float64\n"," 50  FS      5 non-null      float64\n"," 51  GB      5 non-null      float64\n"," 52  GE      5 non-null      float64\n"," 53  GF      5 non-null      float64\n"," 54  GH      5 non-null      float64\n"," 55  GI      5 non-null      float64\n"," 56  GL      5 non-null      float64\n","dtypes: float64(55), int32(1), object(1)\n","memory usage: 2.3+ KB\n"]}],"source":["test_general.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We can see that we will be handling a considerable amount of data (mainly in the peptides dataset). The corresponding columns in the three datasets have the same data types and the proteins and peptide datasets do not have null values. The clinical data dataset have some null values, mainly in the 'upd23b_clinical_state_on_medication'. In the next setps we will need to analyze if we will use all the columns and what we will do with null values if it is necessary to use the columns with nulls. "]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.396163Z","iopub.status.busy":"2023-05-05T21:24:56.395573Z","iopub.status.idle":"2023-05-05T21:24:56.416630Z","shell.execute_reply":"2023-05-05T21:24:56.415134Z","shell.execute_reply.started":"2023-05-05T21:24:56.396109Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\"tv_general\" number of Ids:  617\n","\"tv_greeks\" number of Ids:  617\n","\"test_general\" number of Ids:  5\n"]}],"source":["print('\"tv_general\" number of Ids: ', tv_general.Id.nunique())\n","print('\"tv_greeks\" number of Ids: ', tv_greeks.Id.nunique())\n","print('\"test_general\" number of Ids: ', test_general.Id.nunique())\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.419548Z","iopub.status.busy":"2023-05-05T21:24:56.418851Z","iopub.status.idle":"2023-05-05T21:24:56.438331Z","shell.execute_reply":"2023-05-05T21:24:56.437164Z","shell.execute_reply.started":"2023-05-05T21:24:56.419496Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\"tv_general\" number of Ids: \n"," count              617\n","unique             617\n","top       000ff2bfdfe9\n","freq                 1\n","Name: Id, dtype: object\n","\"tv_greeks\" number of Ids: \n"," count              617\n","unique             617\n","top       000ff2bfdfe9\n","freq                 1\n","Name: Id, dtype: object\n","\"test_general\" number of Ids: \n"," count                5\n","unique               5\n","top       00eed32682bb\n","freq                 1\n","Name: Id, dtype: object\n"]}],"source":["print('\"tv_general\" number of Ids: \\n', tv_general.Id.describe())\n","print('\"tv_greeks\" number of Ids: \\n', tv_greeks.Id.describe())\n","print('\"test_general\" number of Ids: \\n', test_general.Id.describe())\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The ``visit_monhts`` from ``tv_clinical`` has two months more than ``tv_proteins`` and ``tv_proteins`` (months 9, 42, )"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.440566Z","iopub.status.busy":"2023-05-05T21:24:56.440086Z","iopub.status.idle":"2023-05-05T21:24:56.459779Z","shell.execute_reply":"2023-05-05T21:24:56.458426Z","shell.execute_reply.started":"2023-05-05T21:24:56.440527Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>...</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000ff2bfdfe9</td>\n","      <td>0.209377</td>\n","      <td>3109.03329</td>\n","      <td>85.200147</td>\n","      <td>22.394407</td>\n","      <td>8.138688</td>\n","      <td>0.699861</td>\n","      <td>0.025578</td>\n","      <td>9.812214</td>\n","      <td>5.555634</td>\n","      <td>...</td>\n","      <td>7.298162</td>\n","      <td>1.73855</td>\n","      <td>0.094822</td>\n","      <td>11.339138</td>\n","      <td>72.611063</td>\n","      <td>2003.810319</td>\n","      <td>22.136229</td>\n","      <td>69.834944</td>\n","      <td>0.120343</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>007255e47698</td>\n","      <td>0.145282</td>\n","      <td>978.76416</td>\n","      <td>85.200147</td>\n","      <td>36.968889</td>\n","      <td>8.138688</td>\n","      <td>3.632190</td>\n","      <td>0.025578</td>\n","      <td>13.517790</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.568932</td>\n","      <td>9.292698</td>\n","      <td>72.611063</td>\n","      <td>27981.562750</td>\n","      <td>29.135430</td>\n","      <td>32.131996</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>013f2bd269f5</td>\n","      <td>0.470030</td>\n","      <td>2635.10654</td>\n","      <td>85.200147</td>\n","      <td>32.360553</td>\n","      <td>8.138688</td>\n","      <td>6.732840</td>\n","      <td>0.025578</td>\n","      <td>12.824570</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>7.709560</td>\n","      <td>0.97556</td>\n","      <td>1.198821</td>\n","      <td>37.077772</td>\n","      <td>88.609437</td>\n","      <td>13676.957810</td>\n","      <td>28.022851</td>\n","      <td>35.192676</td>\n","      <td>0.196941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>043ac50845d5</td>\n","      <td>0.252107</td>\n","      <td>3819.65177</td>\n","      <td>120.201618</td>\n","      <td>77.112203</td>\n","      <td>8.138688</td>\n","      <td>3.685344</td>\n","      <td>0.025578</td>\n","      <td>11.053708</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>6.122162</td>\n","      <td>0.49706</td>\n","      <td>0.284466</td>\n","      <td>18.529584</td>\n","      <td>82.416803</td>\n","      <td>2094.262452</td>\n","      <td>39.948656</td>\n","      <td>90.493248</td>\n","      <td>0.155829</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>044fb8a146ec</td>\n","      <td>0.380297</td>\n","      <td>3733.04844</td>\n","      <td>85.200147</td>\n","      <td>14.103738</td>\n","      <td>8.138688</td>\n","      <td>3.942255</td>\n","      <td>0.054810</td>\n","      <td>3.396778</td>\n","      <td>102.151980</td>\n","      <td>...</td>\n","      <td>8.153058</td>\n","      <td>48.50134</td>\n","      <td>0.121914</td>\n","      <td>16.408728</td>\n","      <td>146.109943</td>\n","      <td>8524.370502</td>\n","      <td>45.381316</td>\n","      <td>36.262628</td>\n","      <td>0.096614</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>612</th>\n","      <td>fd3dafe738fd</td>\n","      <td>0.149555</td>\n","      <td>3130.05946</td>\n","      <td>123.763599</td>\n","      <td>9.513984</td>\n","      <td>13.020852</td>\n","      <td>3.499305</td>\n","      <td>0.077343</td>\n","      <td>8.545512</td>\n","      <td>2.804172</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.26092</td>\n","      <td>0.067730</td>\n","      <td>8.967128</td>\n","      <td>217.148554</td>\n","      <td>8095.932828</td>\n","      <td>24.640462</td>\n","      <td>69.191944</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>fd895603f071</td>\n","      <td>0.435846</td>\n","      <td>5462.03438</td>\n","      <td>85.200147</td>\n","      <td>46.551007</td>\n","      <td>15.973224</td>\n","      <td>5.979825</td>\n","      <td>0.025882</td>\n","      <td>12.622906</td>\n","      <td>3.777550</td>\n","      <td>...</td>\n","      <td>10.223150</td>\n","      <td>1.24236</td>\n","      <td>0.426699</td>\n","      <td>35.896418</td>\n","      <td>496.994214</td>\n","      <td>3085.308063</td>\n","      <td>29.648928</td>\n","      <td>124.808872</td>\n","      <td>0.145340</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>fd8ef6377f76</td>\n","      <td>0.427300</td>\n","      <td>2459.10720</td>\n","      <td>130.138587</td>\n","      <td>55.355778</td>\n","      <td>10.005552</td>\n","      <td>8.070549</td>\n","      <td>0.025578</td>\n","      <td>15.408390</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>19.962092</td>\n","      <td>128.896894</td>\n","      <td>6474.652866</td>\n","      <td>26.166072</td>\n","      <td>119.559420</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>fe1942975e40</td>\n","      <td>0.363205</td>\n","      <td>1263.53524</td>\n","      <td>85.200147</td>\n","      <td>23.685856</td>\n","      <td>8.138688</td>\n","      <td>7.981959</td>\n","      <td>0.025578</td>\n","      <td>7.524588</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>9.256996</td>\n","      <td>0.78764</td>\n","      <td>0.670527</td>\n","      <td>24.594488</td>\n","      <td>72.611063</td>\n","      <td>1965.343176</td>\n","      <td>25.116750</td>\n","      <td>37.155112</td>\n","      <td>0.184622</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>ffcca4ded3bb</td>\n","      <td>0.482849</td>\n","      <td>2672.53426</td>\n","      <td>546.663930</td>\n","      <td>112.006102</td>\n","      <td>8.138688</td>\n","      <td>3.198099</td>\n","      <td>0.116928</td>\n","      <td>3.396778</td>\n","      <td>7.948668</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.14492</td>\n","      <td>0.149006</td>\n","      <td>13.673940</td>\n","      <td>72.611063</td>\n","      <td>6850.484442</td>\n","      <td>45.745974</td>\n","      <td>114.842372</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>617 rows × 58 columns</p>\n","</div>"],"text/plain":["               Id        AB          AF          AH          AM         AR   \n","0    000ff2bfdfe9  0.209377  3109.03329   85.200147   22.394407   8.138688  \\\n","1    007255e47698  0.145282   978.76416   85.200147   36.968889   8.138688   \n","2    013f2bd269f5  0.470030  2635.10654   85.200147   32.360553   8.138688   \n","3    043ac50845d5  0.252107  3819.65177  120.201618   77.112203   8.138688   \n","4    044fb8a146ec  0.380297  3733.04844   85.200147   14.103738   8.138688   \n","..            ...       ...         ...         ...         ...        ...   \n","612  fd3dafe738fd  0.149555  3130.05946  123.763599    9.513984  13.020852   \n","613  fd895603f071  0.435846  5462.03438   85.200147   46.551007  15.973224   \n","614  fd8ef6377f76  0.427300  2459.10720  130.138587   55.355778  10.005552   \n","615  fe1942975e40  0.363205  1263.53524   85.200147   23.685856   8.138688   \n","616  ffcca4ded3bb  0.482849  2672.53426  546.663930  112.006102   8.138688   \n","\n","           AX        AY         AZ          BC  ...         FL        FR   \n","0    0.699861  0.025578   9.812214    5.555634  ...   7.298162   1.73855  \\\n","1    3.632190  0.025578  13.517790    1.229900  ...   0.173229   0.49706   \n","2    6.732840  0.025578  12.824570    1.229900  ...   7.709560   0.97556   \n","3    3.685344  0.025578  11.053708    1.229900  ...   6.122162   0.49706   \n","4    3.942255  0.054810   3.396778  102.151980  ...   8.153058  48.50134   \n","..        ...       ...        ...         ...  ...        ...       ...   \n","612  3.499305  0.077343   8.545512    2.804172  ...   0.173229   1.26092   \n","613  5.979825  0.025882  12.622906    3.777550  ...  10.223150   1.24236   \n","614  8.070549  0.025578  15.408390    1.229900  ...   0.173229   0.49706   \n","615  7.981959  0.025578   7.524588    1.229900  ...   9.256996   0.78764   \n","616  3.198099  0.116928   3.396778    7.948668  ...   0.173229   1.14492   \n","\n","           FS         GB          GE            GF         GH          GI   \n","0    0.094822  11.339138   72.611063   2003.810319  22.136229   69.834944  \\\n","1    0.568932   9.292698   72.611063  27981.562750  29.135430   32.131996   \n","2    1.198821  37.077772   88.609437  13676.957810  28.022851   35.192676   \n","3    0.284466  18.529584   82.416803   2094.262452  39.948656   90.493248   \n","4    0.121914  16.408728  146.109943   8524.370502  45.381316   36.262628   \n","..        ...        ...         ...           ...        ...         ...   \n","612  0.067730   8.967128  217.148554   8095.932828  24.640462   69.191944   \n","613  0.426699  35.896418  496.994214   3085.308063  29.648928  124.808872   \n","614  0.067730  19.962092  128.896894   6474.652866  26.166072  119.559420   \n","615  0.670527  24.594488   72.611063   1965.343176  25.116750   37.155112   \n","616  0.149006  13.673940   72.611063   6850.484442  45.745974  114.842372   \n","\n","            GL  Class  \n","0     0.120343      1  \n","1    21.978000      0  \n","2     0.196941      0  \n","3     0.155829      0  \n","4     0.096614      1  \n","..         ...    ...  \n","612  21.978000      0  \n","613   0.145340      0  \n","614  21.978000      0  \n","615   0.184622      0  \n","616  21.978000      0  \n","\n","[617 rows x 58 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["tv_general#.groupby(['visit_id'])"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Alpha</th>\n","      <th>Beta</th>\n","      <th>Gamma</th>\n","      <th>Delta</th>\n","      <th>Epsilon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000ff2bfdfe9</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>G</td>\n","      <td>D</td>\n","      <td>3/19/2019</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>007255e47698</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>013f2bd269f5</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>043ac50845d5</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>044fb8a146ec</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>F</td>\n","      <td>B</td>\n","      <td>3/25/2020</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>612</th>\n","      <td>fd3dafe738fd</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>9/13/2020</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>fd895603f071</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>9/8/2020</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>fd8ef6377f76</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>7/24/2019</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>fe1942975e40</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>1/31/2019</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>ffcca4ded3bb</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>617 rows × 6 columns</p>\n","</div>"],"text/plain":["               Id Alpha Beta Gamma Delta    Epsilon\n","0    000ff2bfdfe9     B    C     G     D  3/19/2019\n","1    007255e47698     A    C     M     B    Unknown\n","2    013f2bd269f5     A    C     M     B    Unknown\n","3    043ac50845d5     A    C     M     B    Unknown\n","4    044fb8a146ec     D    B     F     B  3/25/2020\n","..            ...   ...  ...   ...   ...        ...\n","612  fd3dafe738fd     A    B     M     B  9/13/2020\n","613  fd895603f071     A    B     M     B   9/8/2020\n","614  fd8ef6377f76     A    C     M     B  7/24/2019\n","615  fe1942975e40     A    C     M     B  1/31/2019\n","616  ffcca4ded3bb     A    C     M     B    Unknown\n","\n","[617 rows x 6 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tv_greeks"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>...</th>\n","      <th>FI</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00eed32682bb</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>010ebe33f668</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>02fa521e1838</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>040e15f562a2</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>046e85c7cc7f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 57 columns</p>\n","</div>"],"text/plain":["             Id   AB   AF   AH   AM   AR   AX   AY   AZ   BC  ...   FI   FL   \n","0  00eed32682bb  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  \\\n","1  010ebe33f668  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n","2  02fa521e1838  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n","3  040e15f562a2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n","4  046e85c7cc7f  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n","\n","    FR   FS   GB   GE   GF   GH   GI   GL  \n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","\n","[5 rows x 57 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["test_general"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["all columns in df1 are present in df2, but ['Class']\n","columns in df1 are absent in df2: ['Alpha', 'Beta', 'Gamma', 'Delta', 'Epsilon']\n"]}],"source":["#verifying if test columns are in tv_general\n","def columnsVerification(df1, df2):\n","    colNms1 = df1.columns.to_list()\n","    colNms2 = df2.columns.to_list()\n","    nCols1 = len(colNms1)\n","    nCols2 = len(colNms2)\n","    count = 0\n","    absents = []\n","    for c1Nm in colNms1:\n","        if c1Nm in colNms2: \n","            count += 1\n","        else: \n","            absents.append(c1Nm)\n","    if count == nCols1 or count == nCols2:\n","        print ('all columns in df1 are present in df2, but', absents)\n","    else:\n","        print ('columns in df1 are absent in df2:', absents)\n","columnsVerification(df1 = tv_general, df2 = test_general)\n","columnsVerification(df1 = tv_greeks, df2 = test_general)\n","    "]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.462386Z","iopub.status.busy":"2023-05-05T21:24:56.461456Z","iopub.status.idle":"2023-05-05T21:24:56.476952Z","shell.execute_reply":"2023-05-05T21:24:56.475536Z","shell.execute_reply.started":"2023-05-05T21:24:56.462345Z"},"trusted":true},"outputs":[],"source":["def getQtDf(df, qtVar, qlVar, prefix, qlCats = None, justRead = True, isToSave = False):\n","    dfQt = None\n","    if justRead==True:\n","        dfQt = pd.read_csv(PREPROCESSED_DATA_ROOT+qlVar+qtVar+'.csv')#, index_col=False)\n","    else:\n","        if qlCats is None:\n","            qlCats = df[qlVar].unique()\n","        qlVarQtColumns = [prefix+qlCat for qlCat in qlCats]\n","        # prQt\n","        dfQtColumns = ['visit_id', 'visit_month',\t'Id'] + qlVarQtColumns#,\tUniProt\tNPX]\n","        dfQt = pd.DataFrame(columns=dfQtColumns)\n","        visit_ids = df['visit_id'].unique()\n","        n_m = len(visit_ids)\n","        perc = 0\n","        cum = 10#%\n","        print('||', qlVar+qtVar, '|| getQtDf completed: 0%', end='... ')\n","        for i in range(n_m):#[:5]:\n","            visit_id = visit_ids[i]\n","            data = df[df['visit_id']==visit_id].reset_index()\n","            row = {}\n","            row['visit_id'] = visit_id; \n","            row['visit_month'] = data.loc[0, 'visit_month']\n","            row['Id'] = data.loc[0, 'Id']\n","            for qlVarQtColumn in qlVarQtColumns:\n","                row[qlVarQtColumn] = 0\n","            qlValues = data[qlVar]; qtValues = data[qtVar]\n","            nCases = len(qlValues)\n","            for j in range(nCases):\n","                qlValue = qlValues[j]; \n","                qtValue = qtValues[j]\n","                if qlValue not in qlCats:\n","                    qlValue = 'OTHERS'\n","                row[prefix+qlValue] = qtValue\n","            dfQt.loc[i] = row\n","            # print(visit_id, 'ok!', end=', ')\n","            perc = round(100*(i/n_m), 0)\n","            if perc >= cum:\n","                print(str(perc)+'%', end = '... ')\n","                cum += cum\n","        # ret = pd.DataFrame(dfQt, index=range(n_m))\n","        print(str(perc)+'%!')\n","        if isToSave:\n","            dfQt.to_csv(PREPROCESSED_DATA_ROOT+qlVar+qtVar+'.csv', index=False)\n","    return dfQt"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.478810Z","iopub.status.busy":"2023-05-05T21:24:56.478418Z","iopub.status.idle":"2023-05-05T21:24:56.590853Z","shell.execute_reply":"2023-05-05T21:24:56.589512Z","shell.execute_reply.started":"2023-05-05T21:24:56.478778Z"},"trusted":true},"outputs":[],"source":["# #Proteins: converting quali UniProt vs quanti NPX relationship into quantitative variables\n","# tv_UniProtCatgories = ['OTHERS'] + list(tv_proteins['UniProt'].unique())\n","# # qt_tv_pr = getQtDf(df = tv_proteins, qtVar = 'NPX', qlVar = 'UniProt', \n","# #                    prefix = 'pr_', qlCats = tv_UniProtCatgories, justRead = True)\n","# qt_tv_pr = pd.read_csv(PREPROCESSED_DATA_ROOT+'UniProt'+'NPX'+'.csv')\n","# qt_tv_pr"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.592909Z","iopub.status.busy":"2023-05-05T21:24:56.592523Z","iopub.status.idle":"2023-05-05T21:24:56.939819Z","shell.execute_reply":"2023-05-05T21:24:56.938333Z","shell.execute_reply.started":"2023-05-05T21:24:56.592872Z"},"trusted":true},"outputs":[],"source":["# #Peptides: converting quali Peptide vs quanti PeptideAbundance relationship into quantitative variables\n","# tv_peptideCatgories = ['OTHERS'] + list(tv_peptides['Peptide'].unique())\n","# # qt_tv_pe = getQtDf(df = tv_peptides, qtVar = 'PeptideAbundance', qlVar = 'Peptide', \n","# #                    prefix = 'pe_', qlCats = tv_peptideCatgories, justRead = True)\n","# qt_tv_pe = pd.read_csv(PREPROCESSED_DATA_ROOT+'Peptide'+'PeptideAbundance'+'.csv')\n","# qt_tv_pe"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.968617Z","iopub.status.busy":"2023-05-05T21:24:56.967306Z","iopub.status.idle":"2023-05-05T21:24:56.982532Z","shell.execute_reply":"2023-05-05T21:24:56.981165Z","shell.execute_reply.started":"2023-05-05T21:24:56.968436Z"},"trusted":true},"outputs":[{"data":{"text/plain":["count    617.0\n","mean       1.0\n","std        0.0\n","min        1.0\n","25%        1.0\n","50%        1.0\n","75%        1.0\n","max        1.0\n","Name: count, dtype: float64"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["count    5.0\n","mean     1.0\n","std      0.0\n","min      1.0\n","25%      1.0\n","50%      1.0\n","75%      1.0\n","max      1.0\n","Name: count, dtype: float64"]},"metadata":{},"output_type":"display_data"}],"source":["#there is no repetition of visit_id in the tv_clinical data\n","display(tv_general.Id.value_counts().describe())\n","display(test_general.Id.value_counts().describe())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Pre-processing part 1\n","\n","Lets merge the datasets"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:56.984382Z","iopub.status.busy":"2023-05-05T21:24:56.984001Z","iopub.status.idle":"2023-05-05T21:24:57.300417Z","shell.execute_reply":"2023-05-05T21:24:57.298813Z","shell.execute_reply.started":"2023-05-05T21:24:56.984348Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["************** train_validation ***********\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>...</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000ff2bfdfe9</td>\n","      <td>0.209377</td>\n","      <td>3109.03329</td>\n","      <td>85.200147</td>\n","      <td>22.394407</td>\n","      <td>8.138688</td>\n","      <td>0.699861</td>\n","      <td>0.025578</td>\n","      <td>9.812214</td>\n","      <td>5.555634</td>\n","      <td>...</td>\n","      <td>7.298162</td>\n","      <td>1.73855</td>\n","      <td>0.094822</td>\n","      <td>11.339138</td>\n","      <td>72.611063</td>\n","      <td>2003.810319</td>\n","      <td>22.136229</td>\n","      <td>69.834944</td>\n","      <td>0.120343</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>007255e47698</td>\n","      <td>0.145282</td>\n","      <td>978.76416</td>\n","      <td>85.200147</td>\n","      <td>36.968889</td>\n","      <td>8.138688</td>\n","      <td>3.632190</td>\n","      <td>0.025578</td>\n","      <td>13.517790</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.568932</td>\n","      <td>9.292698</td>\n","      <td>72.611063</td>\n","      <td>27981.562750</td>\n","      <td>29.135430</td>\n","      <td>32.131996</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>013f2bd269f5</td>\n","      <td>0.470030</td>\n","      <td>2635.10654</td>\n","      <td>85.200147</td>\n","      <td>32.360553</td>\n","      <td>8.138688</td>\n","      <td>6.732840</td>\n","      <td>0.025578</td>\n","      <td>12.824570</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>7.709560</td>\n","      <td>0.97556</td>\n","      <td>1.198821</td>\n","      <td>37.077772</td>\n","      <td>88.609437</td>\n","      <td>13676.957810</td>\n","      <td>28.022851</td>\n","      <td>35.192676</td>\n","      <td>0.196941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>043ac50845d5</td>\n","      <td>0.252107</td>\n","      <td>3819.65177</td>\n","      <td>120.201618</td>\n","      <td>77.112203</td>\n","      <td>8.138688</td>\n","      <td>3.685344</td>\n","      <td>0.025578</td>\n","      <td>11.053708</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>6.122162</td>\n","      <td>0.49706</td>\n","      <td>0.284466</td>\n","      <td>18.529584</td>\n","      <td>82.416803</td>\n","      <td>2094.262452</td>\n","      <td>39.948656</td>\n","      <td>90.493248</td>\n","      <td>0.155829</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>044fb8a146ec</td>\n","      <td>0.380297</td>\n","      <td>3733.04844</td>\n","      <td>85.200147</td>\n","      <td>14.103738</td>\n","      <td>8.138688</td>\n","      <td>3.942255</td>\n","      <td>0.054810</td>\n","      <td>3.396778</td>\n","      <td>102.151980</td>\n","      <td>...</td>\n","      <td>8.153058</td>\n","      <td>48.50134</td>\n","      <td>0.121914</td>\n","      <td>16.408728</td>\n","      <td>146.109943</td>\n","      <td>8524.370502</td>\n","      <td>45.381316</td>\n","      <td>36.262628</td>\n","      <td>0.096614</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>612</th>\n","      <td>fd3dafe738fd</td>\n","      <td>0.149555</td>\n","      <td>3130.05946</td>\n","      <td>123.763599</td>\n","      <td>9.513984</td>\n","      <td>13.020852</td>\n","      <td>3.499305</td>\n","      <td>0.077343</td>\n","      <td>8.545512</td>\n","      <td>2.804172</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.26092</td>\n","      <td>0.067730</td>\n","      <td>8.967128</td>\n","      <td>217.148554</td>\n","      <td>8095.932828</td>\n","      <td>24.640462</td>\n","      <td>69.191944</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>fd895603f071</td>\n","      <td>0.435846</td>\n","      <td>5462.03438</td>\n","      <td>85.200147</td>\n","      <td>46.551007</td>\n","      <td>15.973224</td>\n","      <td>5.979825</td>\n","      <td>0.025882</td>\n","      <td>12.622906</td>\n","      <td>3.777550</td>\n","      <td>...</td>\n","      <td>10.223150</td>\n","      <td>1.24236</td>\n","      <td>0.426699</td>\n","      <td>35.896418</td>\n","      <td>496.994214</td>\n","      <td>3085.308063</td>\n","      <td>29.648928</td>\n","      <td>124.808872</td>\n","      <td>0.145340</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>fd8ef6377f76</td>\n","      <td>0.427300</td>\n","      <td>2459.10720</td>\n","      <td>130.138587</td>\n","      <td>55.355778</td>\n","      <td>10.005552</td>\n","      <td>8.070549</td>\n","      <td>0.025578</td>\n","      <td>15.408390</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>19.962092</td>\n","      <td>128.896894</td>\n","      <td>6474.652866</td>\n","      <td>26.166072</td>\n","      <td>119.559420</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>fe1942975e40</td>\n","      <td>0.363205</td>\n","      <td>1263.53524</td>\n","      <td>85.200147</td>\n","      <td>23.685856</td>\n","      <td>8.138688</td>\n","      <td>7.981959</td>\n","      <td>0.025578</td>\n","      <td>7.524588</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>9.256996</td>\n","      <td>0.78764</td>\n","      <td>0.670527</td>\n","      <td>24.594488</td>\n","      <td>72.611063</td>\n","      <td>1965.343176</td>\n","      <td>25.116750</td>\n","      <td>37.155112</td>\n","      <td>0.184622</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>ffcca4ded3bb</td>\n","      <td>0.482849</td>\n","      <td>2672.53426</td>\n","      <td>546.663930</td>\n","      <td>112.006102</td>\n","      <td>8.138688</td>\n","      <td>3.198099</td>\n","      <td>0.116928</td>\n","      <td>3.396778</td>\n","      <td>7.948668</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.14492</td>\n","      <td>0.149006</td>\n","      <td>13.673940</td>\n","      <td>72.611063</td>\n","      <td>6850.484442</td>\n","      <td>45.745974</td>\n","      <td>114.842372</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>617 rows × 58 columns</p>\n","</div>"],"text/plain":["               Id        AB          AF          AH          AM         AR   \n","0    000ff2bfdfe9  0.209377  3109.03329   85.200147   22.394407   8.138688  \\\n","1    007255e47698  0.145282   978.76416   85.200147   36.968889   8.138688   \n","2    013f2bd269f5  0.470030  2635.10654   85.200147   32.360553   8.138688   \n","3    043ac50845d5  0.252107  3819.65177  120.201618   77.112203   8.138688   \n","4    044fb8a146ec  0.380297  3733.04844   85.200147   14.103738   8.138688   \n","..            ...       ...         ...         ...         ...        ...   \n","612  fd3dafe738fd  0.149555  3130.05946  123.763599    9.513984  13.020852   \n","613  fd895603f071  0.435846  5462.03438   85.200147   46.551007  15.973224   \n","614  fd8ef6377f76  0.427300  2459.10720  130.138587   55.355778  10.005552   \n","615  fe1942975e40  0.363205  1263.53524   85.200147   23.685856   8.138688   \n","616  ffcca4ded3bb  0.482849  2672.53426  546.663930  112.006102   8.138688   \n","\n","           AX        AY         AZ          BC  ...         FL        FR   \n","0    0.699861  0.025578   9.812214    5.555634  ...   7.298162   1.73855  \\\n","1    3.632190  0.025578  13.517790    1.229900  ...   0.173229   0.49706   \n","2    6.732840  0.025578  12.824570    1.229900  ...   7.709560   0.97556   \n","3    3.685344  0.025578  11.053708    1.229900  ...   6.122162   0.49706   \n","4    3.942255  0.054810   3.396778  102.151980  ...   8.153058  48.50134   \n","..        ...       ...        ...         ...  ...        ...       ...   \n","612  3.499305  0.077343   8.545512    2.804172  ...   0.173229   1.26092   \n","613  5.979825  0.025882  12.622906    3.777550  ...  10.223150   1.24236   \n","614  8.070549  0.025578  15.408390    1.229900  ...   0.173229   0.49706   \n","615  7.981959  0.025578   7.524588    1.229900  ...   9.256996   0.78764   \n","616  3.198099  0.116928   3.396778    7.948668  ...   0.173229   1.14492   \n","\n","           FS         GB          GE            GF         GH          GI   \n","0    0.094822  11.339138   72.611063   2003.810319  22.136229   69.834944  \\\n","1    0.568932   9.292698   72.611063  27981.562750  29.135430   32.131996   \n","2    1.198821  37.077772   88.609437  13676.957810  28.022851   35.192676   \n","3    0.284466  18.529584   82.416803   2094.262452  39.948656   90.493248   \n","4    0.121914  16.408728  146.109943   8524.370502  45.381316   36.262628   \n","..        ...        ...         ...           ...        ...         ...   \n","612  0.067730   8.967128  217.148554   8095.932828  24.640462   69.191944   \n","613  0.426699  35.896418  496.994214   3085.308063  29.648928  124.808872   \n","614  0.067730  19.962092  128.896894   6474.652866  26.166072  119.559420   \n","615  0.670527  24.594488   72.611063   1965.343176  25.116750   37.155112   \n","616  0.149006  13.673940   72.611063   6850.484442  45.745974  114.842372   \n","\n","            GL  Class  \n","0     0.120343      1  \n","1    21.978000      0  \n","2     0.196941      0  \n","3     0.155829      0  \n","4     0.096614      1  \n","..         ...    ...  \n","612  21.978000      0  \n","613   0.145340      0  \n","614  21.978000      0  \n","615   0.184622      0  \n","616  21.978000      0  \n","\n","[617 rows x 58 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# train_validation = tv_clinical.merge(qt_tv_pe, on=['visit_id', 'visit_month', 'Id'], how='left')\n","# train_validation = train_validation.merge(qt_tv_pr, on=['visit_id', 'visit_month', 'Id'], how='right')\n","# train_validation.to_csv(DATA_ROOT+'train_validation.csv', index=False)\n","train_validation = tv_general#pd.read_csv(PREPROCESSED_DATA_ROOT+'train_validation.csv')\n","print('************** train_validation ***********')\n","display(train_validation)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:57.302635Z","iopub.status.busy":"2023-05-05T21:24:57.302145Z","iopub.status.idle":"2023-05-05T21:24:57.362667Z","shell.execute_reply":"2023-05-05T21:24:57.361253Z","shell.execute_reply.started":"2023-05-05T21:24:57.302590Z"},"trusted":true},"outputs":[],"source":["# #Reviewing the results of getQtDf with respect to tv_proteins\n","# import random\n","# trashCase = random.sample(tv_proteins.UniProt.unique().tolist(), 1)[0]\n","# print('**************** train_validation ***************')\n","# display(train_validation[['visit_id','pr_'+trashCase]][:6])\n","# print('**************** tv_proteins ***************')\n","# display(tv_proteins[tv_proteins.UniProt==trashCase][['visit_id','UniProt', 'NPX']][:6])"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:57.364314Z","iopub.status.busy":"2023-05-05T21:24:57.363984Z","iopub.status.idle":"2023-05-05T21:24:57.551567Z","shell.execute_reply":"2023-05-05T21:24:57.550128Z","shell.execute_reply.started":"2023-05-05T21:24:57.364284Z"},"trusted":true},"outputs":[],"source":["# #Reviewing the results of getQtDf with respect to tv_peptides\n","# import random\n","# trashCase = random.sample(tv_peptides.Peptide.unique().tolist(), 1)[0]\n","# print('**************** train_validation ***************')\n","# display(train_validation[['visit_id','pe_'+trashCase]][:6])\n","# print('**************** tv_peptides ***************')\n","# display(tv_peptides[tv_peptides.Peptide==trashCase][['visit_id','Peptide', 'PeptideAbundance']][:6])"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:57.553648Z","iopub.status.busy":"2023-05-05T21:24:57.553246Z","iopub.status.idle":"2023-05-05T21:24:57.972946Z","shell.execute_reply":"2023-05-05T21:24:57.971720Z","shell.execute_reply.started":"2023-05-05T21:24:57.553612Z"},"trusted":true},"outputs":[],"source":["# #computing test data\n","# def getTestQtDf(test_proteins, test_peptides, test_general, isToPrint = False, isToSave = False):\n","#     #Test Proteins: converting quali UniProt vs quanti NPX relationship into quantitative variables\n","#     qt_test_pr = getQtDf(df = test_proteins, qtVar = 'NPX', qlVar = 'UniProt', \n","#                     prefix = 'pr_', qlCats = tv_UniProtCatgories, justRead = False, isToSave = False)\n","#     #Test Peptides: converting quali Peptide vs quanti PeptideAbundance relationship into quantitative variables\n","#     qt_test_pe = getQtDf(df = test_peptides, qtVar = 'PeptideAbundance', qlVar = 'Peptide', \n","#                     prefix = 'pe_', qlCats = tv_peptideCatgories, justRead = False, isToSave = False)\n","#     test = test_general.merge(qt_test_pe, on=['visit_id', 'visit_month', 'Id'], how='left')\n","#     test = test.merge(qt_test_pr, on=['visit_id', 'visit_month', 'Id'], how='left')\n","#     if isToPrint:\n","#         print('************** qt_test_pr **************')\n","#         display(qt_test_pr.head(3))\n","#         print('************** qt_test_pe **************')\n","#         display(qt_test_pe.head(3))\n","#         print('************** test **************')\n","#         display(test)\n","#     return(test)\n","# test = getTestQtDf(test_proteins, test_peptides, test_general)\n","# display(test)\n","test = test_general"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["As said by the owners, there are peptides in the test set that are absent in the train-validation set...:\n","As there is no machine learning regarding these 'new' peptides, they nust be neglected by the predictors"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:57.975442Z","iopub.status.busy":"2023-05-05T21:24:57.975048Z","iopub.status.idle":"2023-05-05T21:24:58.018093Z","shell.execute_reply":"2023-05-05T21:24:58.016567Z","shell.execute_reply.started":"2023-05-05T21:24:57.975406Z"},"trusted":true},"outputs":[],"source":["# print(\"*********** train_validation *********\")\n","# display(train_validation[['pr_OTHERS', 'pe_OTHERS']].describe())\n","# print(\"*********** test *********\")\n","# display(test[['pr_OTHERS', 'pe_OTHERS']].describe())"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.020337Z","iopub.status.busy":"2023-05-05T21:24:58.019739Z","iopub.status.idle":"2023-05-05T21:24:58.029748Z","shell.execute_reply":"2023-05-05T21:24:58.028095Z","shell.execute_reply.started":"2023-05-05T21:24:58.020287Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["*ids from df1 present in df2: []\n","*ids from df1 absent in df2: ['000ff2bfdfe9', '007255e47698', '013f2bd269f5', '043ac50845d5', '044fb8a146ec', '04517a3c90bd', '049232ca8356', '057287f2da6d', '0594b00fb30a', '05f2bc0155cd', '06055f3f6785', '06554e7b9979', '068a4e4bbbab', '06c0ddf265c5', '075bd937ab85', '07760b4cf3f8', '094c0bd5ebe6', '0aa059dad7f3', '0b2cc0b0e6c5', '0c3a256bcec7', '0cdf781c81b9', '0ce8b2aeeead', '0cf19653f4c5', '0cf6c827b8bb', '0d1b855c7635', '0d733722754b', '0da59360d722', '0db07bc343e3', '0e17c8abe9b6', '0e1f6a8eebab', '0e705a0eddf6', '0e798fd4e6e7', '0f5fba133cb7', '0f9257f237b4', '0fa0daef7ac0', '10187958312d', '103f611fdfc4', '1073082e7823', '10aaf6adb652', '10b874d01acd', '1106df45b12e', '1136a2966ed2', '124cd364aa2e', '124eefa2ae00', '128cc82dc5d6', '12d002d52230', '1319c3883fff', '1337ba12ff02', '135f1d1da85e', '1360fac6a227', '13ac854b5fe7', '13c79963c34c', '13ef6c55286a', '1426f76716de', '14713ec51d95', '14a3f3cc04bd', '152979207440', '1540bbf8825b', '157861ebc981', '1591cd66c34e', '15d85eea0e11', '174ba5dc00b1', '17d49f84524b', '17d9a3a45da4', '1899e6e0d7d9', '18dd7c934463', '1900828cbfc4', '1919e4c3a7cc', '19bf6e929506', '19e4c52ea251', '1a14973e1785', '1a6d2336590f', '1a954a747373', '1a9fecf65695', '1b31df9e8971', '1bac22586f27', '1bcdc1af3458', '1c004f1d37be', '1c612f931833', '1ce075e25399', '1e3c4189f04b', '1e4b78cada73', '1e5e59a7f331', '1f829da7c6ed', '20731b639de9', '211b95ea8f90', '21b3d18c0340', '21d33a9fee44', '228524bde6a3', '23ab7ab965d5', '2449608e49a9', '245a3f44cfc0', '2471b27e99fc', '24b40510d6a2', '24dfe3da6769', '2508534155a6', '26c79809c5ea', '271737344017', '273efaff6f8a', '27bfa971821f', '284efb30decc', '28ade6fa7bc3', '2901ef1394b9', '298989cc4e92', '29cba3a7b8dc', '2bb2902bd5e1', '2bd50291b64d', '2c495dfbaacf', '2ca6bdf04280', '2cddd2d70d72', '2d5d2874b058', '2d7ba928287d', '2dc8b3d2980b', '2e03488a03ca', '2e4e80b95e24', '2e637b444de7', '2f020a35ce2b', '2f1e32eac20e', '2f4e5de3de9c', '2fd659800f75', '30202b353d8a', '3026974712cd', '3101fca6b743', '312661adb2ff', '319f7e210021', '321f58c2e5d1', '324d6f4b6b37', '32c1d5bdae8d', '332a3850302f', '333bff494437', '3493c79c8f35', '34a025893d36', '34dc3190c6fb', '34f10f630b68', '355bdddccdbd', '3581cb92b427', '36d298d32eb9', '36f2fbc0a810', '37342e4943f2', '381e08d38c92', '381ff0376cb0', '38325b0c36e5', '3840054e6aa5', '386a027efe36', '38c9a1f2eacf', '3924089e4396', '3a288ec2811f', '3a73fce81608', '3b280978a051', '3b8959ffdfa9', '3bbe922b2cdb', '3bf81aff9bd6', '3c299fce6b56', '3d4109150b32', '3db179cf1a7d', '3e2d6dca77ec', '3e610a5ff8d1', '3eb3be63b62c', '3f004b7190f3', '3f367f9652ff', '3f4bfe72745d', '3fad66987cf9', '401ca61716e4', '407436e7ec52', '40ffdee110b8', '41216f6cee66', '41475fa34ab3', '41698cf1a1bd', '41e9e3cec765', '431c73b16f33', '43365f867d38', '434b3925094e', '4376800c31fd', '43eab2b837d1', '4401d2485580', '44c7768642a7', '44e759955f6e', '4537a9a3ecde', '4572189340c4', '457d8d386eb2', '459c432b15ae', '463035913640', '4652c8c5705c', '4671650635ab', '46a2c24d2624', '46b876fc8933', '46fe2d3b9e7b', '470d18ff7777', '47d8bacb43bb', '47e4c756d4a6', '48485c8c1ef7', '48c64ab517c9', '48f422645d0e', '49b8f248a42f', '49e14acf8ffb', '4a3d7459976a', '4bc8f3ea493a', '4c92a971cf91', '4d4e63393080', '4d54e3a957e6', '4e6477903aa3', '4e9059199e3d', '4ec197e84caf', '4f17ecd66363', '4feabef01f7a', '4fef9a973791', '4ff6c37484ee', '50183292c0e7', '508bb5c5cf00', '51111505c6f2', '514d2ac4fdb5', '51a5b926ab4d', '528dd2afeb79', '52acfa7cc2fc', '53468141b7c9', '535a9e672d18', '55122c3c02a0', '571a56646e47', '582ef2696f72', '58843604dcb5', '58dcdd9d6e89', '58e74efe7aa5', '59bf633c1018', '59bf79fac3fa', '59bfbb4ad480', '59eb23495fa7', '5a87a6061488', '5c03d177da66', '5c522f58308c', '5c63c7b71282', '5ce5f23fff0d', '5d547eb551a9', '5d694ba9aa16', '5d8a1a0fb062', '5dc5360a3fc8', '5e27b0147126', '5ee622a3e3be', '5f20ad0ec630', '5fe47095520d', '60013ee40a0a', '6002d5f39711', '600c445d3351', '60474d8ff770', '6192b3e210ae', '619aac34f423', '61af8fde49eb', '61e882a215f4', '6204fd873dcd', '62176aa5de57', '6468478fce4c', '6487b5140ab2', '657d27cacf2b', '658e0b2992bb', '65c5772a4afa', '65de682cc48c', '661b3a326a9d', '667b389f278d', '670b295eaa0f', '67122d4bce03', '679465bb38ba', '67ba3c5d8baf', '67c8bfe99f1c', '67d932a88814', '684d62aeae9e', '6850ef5b0092', '68597a95792d', '6860e7cbccad', '68729b79859b', '687ebf4e5d7d', '68918798c769', '68c35486588c', '6955c8adcd36', '69de76778344', '69e627ec5d3e', '6a2fa7569189', '6ab2d09883de', '6bf666677588', '6c231f862f11', '6c679dc63744', '6c6db7987cd5', '6ed97ed5defe', '6ef1fe86ad00', '6f5908450956', '7017fab77607', '703c183d0c6c', '70926a82d4e1', '7180e4b7d21a', '71f07ea5a770', '72ee3bca17f6', '73468ffe1cb5', '73483f848b67', '7392d21fc103', '7416fea10b6b', '7429ed35535c', '7445f4eac4de', '7530ec447c5d', '778e1213d462', '77ccceb44f4e', '7800130b9140', '7804b14ee22b', '7830dec4b764', '785a0d3c4c41', '78f3ccd568c6', '793d5c26bd0e', '79b44ed25c29', '7a5c4b008308', '7a705feced42', '7af31043202c', '7b8cda4bc33e', '7bcb9a31014b', '7c02caf1b94f', '7c21c57859d6', '7c2df9f2fbe2', '7cb9a95a62fc', '7cc870296984', '7dd96a41647c', '7e4d70590a71', '7eb06d1c9234', '7f6d8841c044', '7feabcc65b6b', '800440b155b1', '8006877fc82a', '800c6b3239c6', '80348b62c82e', '8065efe77fab', '80841417ca53', '809087be105e', '8093b3b92b28', '80c47659c7c6', '80ee5615ebdf', '81015c6c3404', '810ff5afd0e2', '815cc64eb1cc', '8266debd5234', '8296caddae14', '82c5014b0d57', '8353e4690948', '8408bf4d3d2f', '8457871d9624', '84c5b2d3eace', '84efa38972ba', '860833bfe713', '8767b93c7948', '87f6d81bb2f7', '8803ec4462c1', '8856a9d8e2b4', '88ceb24fa799', '894a982c52c1', '89a5ed9b71a8', '8a3cb69b2242', '8a3e1acd2ff2', '8ae3966cdb92', '8b4dfe76ff44', '8b7131974251', '8b77f91fde3e', '8b866016ac44', '8b9d72eec14e', '8ba157c016ba', '8ba2487388f2', '8bb44f5c60a4', '8c58bec30f78', '8d0d4a6510bf', '8d505de1fa59', '8d7e1ef24fb8', '8d7f231c9cb7', '8e22648bf996', '8e35c5943760', '8e5a0d625d98', '8ead0a51d11c', '8eefb589a7aa', '8f411ab61450', '8f5b7d4621da', '9025eee0ab7d', '905a7dbaaf9a', '91004fe0a0fd', '91275f6ae0a2', '913a3374da32', '913b30965ae1', '9230d1831db3', '92b3778f624f', '93205d43a401', '948043d08210', '948b3f28db47', '948e868ba395', '94f28a9c879b', '968491b9238f', '96ee4e851fbd', '96fbcce4f0c0', '9708ba6b2fa2', '975235e7d941', '97b6c7088bc6', '98102929d244', '98944bb311a4', '991587f97e45', '9949a1749e2c', '9a3ec17a57a0', '9b25a5047a23', '9b6aeb66b22a', '9b9e6e21b830', '9ba8bfa26e8a', '9c0f8307a7ec', '9c43f9559e4c', '9c8d738c0272', '9ce745fc98c4', '9d19cb5327b5', '9e725e00b348', '9ed6b861e9f7', '9ee887ad93d5', '9ef1886b810c', '9f10f72ca154', 'a02d41dc2cc4', 'a0693256491d', 'a082f422799b', 'a20ba8577583', 'a20c68851e9b', 'a22a15853970', 'a3493d6aca6e', 'a46b439e1eac', 'a4f476550c49', 'a5faa9a52bcb', 'a633a258eeed', 'a795db8ca395', 'a7b1c7b83f53', 'a7d4dd890a1b', 'a904c19b5e22', 'a92580fda1c3', 'aa54a308dbb4', 'aa6c6160804f', 'aa8185fbee33', 'aac8bafe74ef', 'ab39fd701211', 'ab4bc55cb79e', 'ac2074c4eeb5', 'ac38de805eff', 'acc1f36dca1c', 'acd97f3380e4', 'ad8e95777bf2', 'ad9a26b80957', 'adb67a0dd661', 'add78517b003', 'aee064d35f72', 'af0802c15f01', 'af1a304f3c89', 'af2c482fb8d7', 'afad421356e3', 'b002a6adb6be', 'b06b043e7abe', 'b1056bf99b86', 'b1080294e1f2', 'b10bae274dfc', 'b10f6f101138', 'b1143beb212d', 'b1195f8f1afa', 'b22ebf6851bb', 'b231b1b0962c', 'b2aec42acb00', 'b2b3ec04caf6', 'b301f38c110c', 'b358f0fdb95b', 'b3807c5f43e8', 'b4d611fab6c5', 'b5b51b3db693', 'b6efe1e60280', 'b74762c1d521', 'b85846bebd78', 'b874e25c20aa', 'b90c555e8c3c', 'b9856a5d8f13', 'b9e388b48268', 'ba0c42e12f1f', 'ba4443b0170c', 'bbb1066a9afd', 'bbbb36522060', 'bbc27c1326a5', 'bcc36efe8096', 'bdd7b0f36488', 'be0d0e810303', 'bf12446bf394', 'bfcbf52e5449', 'c08f5a77f267', 'c1ffde2da7d9', 'c214d487e2db', 'c25704512231', 'c38cbd7f61dd', 'c49cbf1cac11', 'c556791ceee9', 'c5c8ffd0c908', 'c5cc9b3fa0b9', 'c5e5456ccaa2', 'c5f4346394b9', 'c5f4dc4ae7fb', 'c60e0e7b6ca1', 'c6c3a77ec885', 'c7f5064f4265', 'c809ac237df8', 'c82e5a429e5b', 'c86be787cb28', 'c8a5264f7458', 'c90977976ffe', 'c9e8391da0ea', 'c9f71bcf8be0', 'ca3ae6c8dede', 'ca4b0957e0c8', 'caff00fb82e2', 'cc42ed28ac3f', 'cc9f47d89979', 'ccd8b4b583df', 'cd5d5458c163', 'ce42176962b9', 'cf5439add02c', 'cf81f032b88e', 'cf84868cd1ce', 'd00b37ba63e7', 'd02c11462079', 'd061b54c6650', 'd0b72acaecdd', 'd0ecfae80796', 'd10976c44b2b', 'd1a9f56adc4a', 'd1f14dbe348c', 'd1fa22631c9c', 'd2910aee04cd', 'd2960230a353', 'd2dd462f90b5', 'd32f445d4d75', 'd35148a64ca9', 'd3ce7974230c', 'd3d8c9d232f1', 'd42783629bbc', 'd44d3320d240', 'd482356ae08f', 'd5463b93905d', 'd7353855bf36', 'd75aafac1e86', 'd7dbf59b37f9', 'd7f01114e6db', 'd8dae19a0df0', 'd9d5fdfa030c', 'da1a5aec1818', 'da68b4918818', 'da6c7e4e124d', 'dbf5f8b82b43', 'dc9b175cbf1e', 'dd3515028d71', 'dd65e067165c', 'dd8bcfab8df9', 'deaf77f02382', 'df956c379776', 'dfa4ccdd5f4a', 'e00086407736', 'e0bf5a4a77d2', 'e0f325c4df28', 'e15ae7d5194f', 'e18129dade8f', 'e235af39779b', 'e253dc2f97c0', 'e2ef2a51ed65', 'e42344ea440c', 'e4ba2e28e184', 'e52a2f7ad6a5', 'e6aa6fa49abd', 'e70889ea6013', 'e70b5934b571', 'e76aa8f0f2e7', 'e7a607afea3d', 'e7bedc8fb9a5', 'e8c119eb3e16', 'e8dde9331551', 'e9417cc82b93', 'e999bb1c01d7', 'e9c343dc7736', 'e9d084428900', 'ea50b3c5bd63', 'eada36b0bf31', 'eb9c2a590373', 'ecf1ac3d6dfc', 'ed3486389307', 'ed4a24c7ec54', 'ee48d4f9dc81', 'efcba7fac353', 'f003d68995be', 'f03b541de10c', 'f0d7d98bfe21', 'f12d8570682a', 'f13b1485ba1f', 'f16b095a433f', 'f1a68746ca6e', 'f206becd4ffd', 'f26ee0cee841', 'f3eb9ac222f9', 'f3f2071d2453', 'f404680da866', 'f405c0b5836f', 'f44978084805', 'f46e39a96ee9', 'f56e7620836e', 'f62ef7cc0a22', 'f71ef203fae7', 'f7a862a414de', 'f82b07dfd7fb', 'f8eb43047d69', 'f944d35cb6c4', 'f955c0ed8895', 'f96e7ca4a16c', 'f9a7ea889307', 'fb27f6e58eaa', 'fb7584f887fd', 'fb786fb02a65', 'fbb79ba9d642', 'fbc241daef00', 'fbd12c4ae88b', 'fd1dd68d51b4', 'fd3dafe738fd', 'fd895603f071', 'fd8ef6377f76', 'fe1942975e40', 'ffcca4ded3bb']\n"]}],"source":["def verifyingIdsInTrainAndTest(df1, df2):\n","    ids1 = df1.Id\n","    ids2 = df2.Id\n","    # count=0\n","    absents = []; presents = []\n","    for id1 in ids1:\n","        if id1 in ids2:\n","            presents.append(id1)\n","        else:\n","            absents.append(id1)\n","    print('*ids from df1 present in df2:', presents)\n","    print('*ids from df1 absent in df2:', absents)\n","verifyingIdsInTrainAndTest(df1 = train_validation, df2 = test)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The ``Id`` 3342 and 50423 are used for testing... These ids are absent in the training set... ;( "]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.051222Z","iopub.status.busy":"2023-05-05T21:24:58.050793Z","iopub.status.idle":"2023-05-05T21:24:58.236516Z","shell.execute_reply":"2023-05-05T21:24:58.235125Z","shell.execute_reply.started":"2023-05-05T21:24:58.051184Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Id       617\n","AB       217\n","AF       599\n","AH       227\n","AM       605\n","AR       130\n","AX       427\n","AY       148\n","AZ       484\n","BC       259\n","BD       617\n","BN        53\n","BP       612\n","BQ       515\n","BR       566\n","BZ       115\n","CB       553\n","CC       602\n","CD       584\n","CF       586\n","CH       135\n","CL       123\n","CR       595\n","CS       576\n","CU       307\n","CW       426\n","DA       611\n","DE       616\n","DF       137\n","DH       191\n","DI       571\n","DL       604\n","DN       576\n","DU       253\n","DV        39\n","DY       590\n","EB       439\n","EE       513\n","EG       610\n","EH       127\n","EJ         2\n","EL       311\n","EP       275\n","EU       455\n","FC       600\n","FD       337\n","FE       615\n","FI       498\n","FL       388\n","FR       435\n","FS       161\n","GB       560\n","GE       264\n","GF       611\n","GH       596\n","GI       615\n","GL       355\n","Class      2\n","dtype: int64"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["train_validation.nunique()"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.238342Z","iopub.status.busy":"2023-05-05T21:24:58.237845Z","iopub.status.idle":"2023-05-05T21:24:58.245862Z","shell.execute_reply":"2023-05-05T21:24:58.244479Z","shell.execute_reply.started":"2023-05-05T21:24:58.238295Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train_validation.columns Index(['Id', 'AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BN',\n","       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CR', 'CS',\n","       'CU', 'CW', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n","       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD', 'FE', 'FI',\n","       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'Class'],\n","      dtype='object')\n","test.columns Index(['Id', 'AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BN',\n","       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CR', 'CS',\n","       'CU', 'CW', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n","       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD', 'FE', 'FI',\n","       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","      dtype='object')\n"]}],"source":["print('train_validation.columns', train_validation.columns)\n","print('test.columns', test.columns)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.248243Z","iopub.status.busy":"2023-05-05T21:24:58.247702Z","iopub.status.idle":"2023-05-05T21:24:58.267712Z","shell.execute_reply":"2023-05-05T21:24:58.265992Z","shell.execute_reply.started":"2023-05-05T21:24:58.248192Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>class_0</th>\n","      <th>class_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00eed32682bb</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>010ebe33f668</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>02fa521e1838</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>040e15f562a2</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>046e85c7cc7f</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Id  class_0  class_1\n","0  00eed32682bb      0.5      0.5\n","1  010ebe33f668      0.5      0.5\n","2  02fa521e1838      0.5      0.5\n","3  040e15f562a2      0.5      0.5\n","4  046e85c7cc7f      0.5      0.5"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["sample_submission"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Exploratory analysis\n","\n","Now that we already know the data structure, let's extract some insights from it. "]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.269883Z","iopub.status.busy":"2023-05-05T21:24:58.269447Z","iopub.status.idle":"2023-05-05T21:24:58.341932Z","shell.execute_reply":"2023-05-05T21:24:58.341006Z","shell.execute_reply.started":"2023-05-05T21:24:58.269845Z"},"trusted":true},"outputs":[{"data":{"text/plain":["EL       60\n","BQ       60\n","CC        3\n","FS        2\n","CB        2\n","FL        1\n","FC        1\n","DU        1\n","GL        1\n","EE        0\n","EB        0\n","EU        0\n","DY        0\n","EH        0\n","EJ        0\n","DV        0\n","EP        0\n","EG        0\n","Id        0\n","DL        0\n","FD        0\n","FE        0\n","FI        0\n","FR        0\n","GB        0\n","GE        0\n","GF        0\n","GH        0\n","GI        0\n","DN        0\n","DH        0\n","DI        0\n","BR        0\n","AF        0\n","AH        0\n","AM        0\n","AR        0\n","AX        0\n","AY        0\n","AZ        0\n","BC        0\n","BD        0\n","BN        0\n","BP        0\n","BZ        0\n","AB        0\n","CD        0\n","CF        0\n","CH        0\n","CL        0\n","CR        0\n","CS        0\n","CU        0\n","CW        0\n","DA        0\n","DE        0\n","DF        0\n","Class     0\n","dtype: int64"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["train_validation.isna().sum().sort_values(ascending=False)#.plot(xlabel='feature', ylabel='# NAs', kind='bar');#.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["One can see that there are missing values."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data sets split for train and validation"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.343412Z","iopub.status.busy":"2023-05-05T21:24:58.343039Z","iopub.status.idle":"2023-05-05T21:24:58.532473Z","shell.execute_reply":"2023-05-05T21:24:58.531195Z","shell.execute_reply.started":"2023-05-05T21:24:58.343367Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["******** train[0]********\n","n = 154\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>...</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>007255e47698</td>\n","      <td>0.145282</td>\n","      <td>978.76416</td>\n","      <td>85.200147</td>\n","      <td>36.968889</td>\n","      <td>8.138688</td>\n","      <td>3.632190</td>\n","      <td>0.025578</td>\n","      <td>13.517790</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.568932</td>\n","      <td>9.292698</td>\n","      <td>72.611063</td>\n","      <td>27981.562750</td>\n","      <td>29.135430</td>\n","      <td>32.131996</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>06554e7b9979</td>\n","      <td>0.760594</td>\n","      <td>6957.75289</td>\n","      <td>200.089275</td>\n","      <td>23.462872</td>\n","      <td>8.138688</td>\n","      <td>7.627599</td>\n","      <td>0.025578</td>\n","      <td>16.794830</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>6.890084</td>\n","      <td>1.09011</td>\n","      <td>1.266551</td>\n","      <td>42.928730</td>\n","      <td>72.611063</td>\n","      <td>8192.631033</td>\n","      <td>32.659217</td>\n","      <td>53.813956</td>\n","      <td>0.437845</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>06c0ddf265c5</td>\n","      <td>0.534125</td>\n","      <td>4784.80222</td>\n","      <td>90.704235</td>\n","      <td>8.739734</td>\n","      <td>8.138688</td>\n","      <td>7.003039</td>\n","      <td>0.025578</td>\n","      <td>10.152522</td>\n","      <td>14.836108</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>45.62222</td>\n","      <td>0.067730</td>\n","      <td>35.784794</td>\n","      <td>72.611063</td>\n","      <td>895.517451</td>\n","      <td>46.069701</td>\n","      <td>62.044356</td>\n","      <td>21.978000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>075bd937ab85</td>\n","      <td>0.508487</td>\n","      <td>1632.12907</td>\n","      <td>85.200147</td>\n","      <td>11.864607</td>\n","      <td>17.617218</td>\n","      <td>7.104918</td>\n","      <td>0.234160</td>\n","      <td>12.938006</td>\n","      <td>11.438070</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.58427</td>\n","      <td>0.067730</td>\n","      <td>11.246118</td>\n","      <td>72.611063</td>\n","      <td>11777.141530</td>\n","      <td>34.482507</td>\n","      <td>8.564760</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>094c0bd5ebe6</td>\n","      <td>0.252107</td>\n","      <td>5180.17214</td>\n","      <td>85.200147</td>\n","      <td>14.438214</td>\n","      <td>8.138688</td>\n","      <td>4.819296</td>\n","      <td>0.184527</td>\n","      <td>10.644078</td>\n","      <td>8.707692</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.72152</td>\n","      <td>0.067730</td>\n","      <td>13.701846</td>\n","      <td>72.611063</td>\n","      <td>37275.608540</td>\n","      <td>44.343157</td>\n","      <td>51.527448</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>581</th>\n","      <td>f03b541de10c</td>\n","      <td>1.096024</td>\n","      <td>4348.11080</td>\n","      <td>546.489750</td>\n","      <td>72.469800</td>\n","      <td>8.138688</td>\n","      <td>3.167092</td>\n","      <td>0.102921</td>\n","      <td>3.396778</td>\n","      <td>13.381312</td>\n","      <td>...</td>\n","      <td>5.760795</td>\n","      <td>2.02884</td>\n","      <td>0.182871</td>\n","      <td>12.283291</td>\n","      <td>72.611063</td>\n","      <td>2184.856740</td>\n","      <td>33.204344</td>\n","      <td>40.169496</td>\n","      <td>0.077344</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>597</th>\n","      <td>f71ef203fae7</td>\n","      <td>0.478576</td>\n","      <td>2756.53488</td>\n","      <td>85.200147</td>\n","      <td>20.424715</td>\n","      <td>8.138688</td>\n","      <td>4.367487</td>\n","      <td>0.025578</td>\n","      <td>11.154540</td>\n","      <td>3.668616</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.98708</td>\n","      <td>0.067730</td>\n","      <td>11.404252</td>\n","      <td>72.611063</td>\n","      <td>18878.557980</td>\n","      <td>47.252979</td>\n","      <td>42.530592</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>fbb79ba9d642</td>\n","      <td>0.636677</td>\n","      <td>2996.11246</td>\n","      <td>85.200147</td>\n","      <td>157.135586</td>\n","      <td>25.533036</td>\n","      <td>4.934463</td>\n","      <td>0.025578</td>\n","      <td>12.660718</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>36.144542</td>\n","      <td>0.49706</td>\n","      <td>0.135460</td>\n","      <td>11.562386</td>\n","      <td>145.420891</td>\n","      <td>7134.676344</td>\n","      <td>16.833804</td>\n","      <td>48.536212</td>\n","      <td>0.027231</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>609</th>\n","      <td>fbc241daef00</td>\n","      <td>0.367478</td>\n","      <td>4461.60154</td>\n","      <td>85.200147</td>\n","      <td>25.842917</td>\n","      <td>8.138688</td>\n","      <td>5.731773</td>\n","      <td>0.032277</td>\n","      <td>8.444680</td>\n","      <td>5.882436</td>\n","      <td>...</td>\n","      <td>4.234008</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>25.217722</td>\n","      <td>72.611063</td>\n","      <td>7113.007548</td>\n","      <td>25.831182</td>\n","      <td>17.505032</td>\n","      <td>0.208286</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>ffcca4ded3bb</td>\n","      <td>0.482849</td>\n","      <td>2672.53426</td>\n","      <td>546.663930</td>\n","      <td>112.006102</td>\n","      <td>8.138688</td>\n","      <td>3.198099</td>\n","      <td>0.116928</td>\n","      <td>3.396778</td>\n","      <td>7.948668</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.14492</td>\n","      <td>0.149006</td>\n","      <td>13.673940</td>\n","      <td>72.611063</td>\n","      <td>6850.484442</td>\n","      <td>45.745974</td>\n","      <td>114.842372</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 58 columns</p>\n","</div>"],"text/plain":["               Id        AB          AF          AH          AM         AR   \n","1    007255e47698  0.145282   978.76416   85.200147   36.968889   8.138688  \\\n","11   06554e7b9979  0.760594  6957.75289  200.089275   23.462872   8.138688   \n","13   06c0ddf265c5  0.534125  4784.80222   90.704235    8.739734   8.138688   \n","14   075bd937ab85  0.508487  1632.12907   85.200147   11.864607  17.617218   \n","16   094c0bd5ebe6  0.252107  5180.17214   85.200147   14.438214   8.138688   \n","..            ...       ...         ...         ...         ...        ...   \n","581  f03b541de10c  1.096024  4348.11080  546.489750   72.469800   8.138688   \n","597  f71ef203fae7  0.478576  2756.53488   85.200147   20.424715   8.138688   \n","608  fbb79ba9d642  0.636677  2996.11246   85.200147  157.135586  25.533036   \n","609  fbc241daef00  0.367478  4461.60154   85.200147   25.842917   8.138688   \n","616  ffcca4ded3bb  0.482849  2672.53426  546.663930  112.006102   8.138688   \n","\n","           AX        AY         AZ         BC  ...         FL        FR   \n","1    3.632190  0.025578  13.517790   1.229900  ...   0.173229   0.49706  \\\n","11   7.627599  0.025578  16.794830   1.229900  ...   6.890084   1.09011   \n","13   7.003039  0.025578  10.152522  14.836108  ...   0.173229  45.62222   \n","14   7.104918  0.234160  12.938006  11.438070  ...   0.173229   1.58427   \n","16   4.819296  0.184527  10.644078   8.707692  ...   0.173229   0.72152   \n","..        ...       ...        ...        ...  ...        ...       ...   \n","581  3.167092  0.102921   3.396778  13.381312  ...   5.760795   2.02884   \n","597  4.367487  0.025578  11.154540   3.668616  ...   0.173229   1.98708   \n","608  4.934463  0.025578  12.660718   1.229900  ...  36.144542   0.49706   \n","609  5.731773  0.032277   8.444680   5.882436  ...   4.234008   0.49706   \n","616  3.198099  0.116928   3.396778   7.948668  ...   0.173229   1.14492   \n","\n","           FS         GB          GE            GF         GH          GI   \n","1    0.568932   9.292698   72.611063  27981.562750  29.135430   32.131996  \\\n","11   1.266551  42.928730   72.611063   8192.631033  32.659217   53.813956   \n","13   0.067730  35.784794   72.611063    895.517451  46.069701   62.044356   \n","14   0.067730  11.246118   72.611063  11777.141530  34.482507    8.564760   \n","16   0.067730  13.701846   72.611063  37275.608540  44.343157   51.527448   \n","..        ...        ...         ...           ...        ...         ...   \n","581  0.182871  12.283291   72.611063   2184.856740  33.204344   40.169496   \n","597  0.067730  11.404252   72.611063  18878.557980  47.252979   42.530592   \n","608  0.135460  11.562386  145.420891   7134.676344  16.833804   48.536212   \n","609  0.067730  25.217722   72.611063   7113.007548  25.831182   17.505032   \n","616  0.149006  13.673940   72.611063   6850.484442  45.745974  114.842372   \n","\n","            GL  Class  \n","1    21.978000      0  \n","11    0.437845      0  \n","13   21.978000      1  \n","14   21.978000      0  \n","16   21.978000      0  \n","..         ...    ...  \n","581   0.077344      0  \n","597  21.978000      0  \n","608   0.027231      1  \n","609   0.208286      0  \n","616  21.978000      0  \n","\n","[154 rows x 58 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["******** train[1]********\n","n = 308\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>...</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000ff2bfdfe9</td>\n","      <td>0.209377</td>\n","      <td>3109.03329</td>\n","      <td>85.200147</td>\n","      <td>22.394407</td>\n","      <td>8.138688</td>\n","      <td>0.699861</td>\n","      <td>0.025578</td>\n","      <td>9.812214</td>\n","      <td>5.555634</td>\n","      <td>...</td>\n","      <td>7.298162</td>\n","      <td>1.73855</td>\n","      <td>0.094822</td>\n","      <td>11.339138</td>\n","      <td>72.611063</td>\n","      <td>2003.810319</td>\n","      <td>22.136229</td>\n","      <td>69.834944</td>\n","      <td>0.120343</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>007255e47698</td>\n","      <td>0.145282</td>\n","      <td>978.76416</td>\n","      <td>85.200147</td>\n","      <td>36.968889</td>\n","      <td>8.138688</td>\n","      <td>3.632190</td>\n","      <td>0.025578</td>\n","      <td>13.517790</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.568932</td>\n","      <td>9.292698</td>\n","      <td>72.611063</td>\n","      <td>27981.562750</td>\n","      <td>29.135430</td>\n","      <td>32.131996</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>049232ca8356</td>\n","      <td>0.348249</td>\n","      <td>1733.65412</td>\n","      <td>85.200147</td>\n","      <td>8.377385</td>\n","      <td>15.312480</td>\n","      <td>1.913544</td>\n","      <td>0.025578</td>\n","      <td>6.547778</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>4.408484</td>\n","      <td>0.86130</td>\n","      <td>0.467337</td>\n","      <td>17.878444</td>\n","      <td>192.453107</td>\n","      <td>3332.467494</td>\n","      <td>34.166222</td>\n","      <td>100.086808</td>\n","      <td>0.065096</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>057287f2da6d</td>\n","      <td>0.269199</td>\n","      <td>966.45483</td>\n","      <td>85.200147</td>\n","      <td>21.174189</td>\n","      <td>8.138688</td>\n","      <td>4.987617</td>\n","      <td>0.025578</td>\n","      <td>9.408886</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>6.591896</td>\n","      <td>0.49706</td>\n","      <td>0.277693</td>\n","      <td>18.445866</td>\n","      <td>109.693986</td>\n","      <td>21371.759850</td>\n","      <td>35.208102</td>\n","      <td>31.424696</td>\n","      <td>0.092873</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>06554e7b9979</td>\n","      <td>0.760594</td>\n","      <td>6957.75289</td>\n","      <td>200.089275</td>\n","      <td>23.462872</td>\n","      <td>8.138688</td>\n","      <td>7.627599</td>\n","      <td>0.025578</td>\n","      <td>16.794830</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>6.890084</td>\n","      <td>1.09011</td>\n","      <td>1.266551</td>\n","      <td>42.928730</td>\n","      <td>72.611063</td>\n","      <td>8192.631033</td>\n","      <td>32.659217</td>\n","      <td>53.813956</td>\n","      <td>0.437845</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>609</th>\n","      <td>fbc241daef00</td>\n","      <td>0.367478</td>\n","      <td>4461.60154</td>\n","      <td>85.200147</td>\n","      <td>25.842917</td>\n","      <td>8.138688</td>\n","      <td>5.731773</td>\n","      <td>0.032277</td>\n","      <td>8.444680</td>\n","      <td>5.882436</td>\n","      <td>...</td>\n","      <td>4.234008</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>25.217722</td>\n","      <td>72.611063</td>\n","      <td>7113.007548</td>\n","      <td>25.831182</td>\n","      <td>17.505032</td>\n","      <td>0.208286</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>611</th>\n","      <td>fd1dd68d51b4</td>\n","      <td>0.175193</td>\n","      <td>2607.26686</td>\n","      <td>85.200147</td>\n","      <td>7.067354</td>\n","      <td>8.138688</td>\n","      <td>4.030845</td>\n","      <td>0.025578</td>\n","      <td>3.396778</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.89486</td>\n","      <td>1.395238</td>\n","      <td>16.911036</td>\n","      <td>246.093155</td>\n","      <td>10960.364830</td>\n","      <td>38.380254</td>\n","      <td>41.007968</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>612</th>\n","      <td>fd3dafe738fd</td>\n","      <td>0.149555</td>\n","      <td>3130.05946</td>\n","      <td>123.763599</td>\n","      <td>9.513984</td>\n","      <td>13.020852</td>\n","      <td>3.499305</td>\n","      <td>0.077343</td>\n","      <td>8.545512</td>\n","      <td>2.804172</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.26092</td>\n","      <td>0.067730</td>\n","      <td>8.967128</td>\n","      <td>217.148554</td>\n","      <td>8095.932828</td>\n","      <td>24.640462</td>\n","      <td>69.191944</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>fd8ef6377f76</td>\n","      <td>0.427300</td>\n","      <td>2459.10720</td>\n","      <td>130.138587</td>\n","      <td>55.355778</td>\n","      <td>10.005552</td>\n","      <td>8.070549</td>\n","      <td>0.025578</td>\n","      <td>15.408390</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>19.962092</td>\n","      <td>128.896894</td>\n","      <td>6474.652866</td>\n","      <td>26.166072</td>\n","      <td>119.559420</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>ffcca4ded3bb</td>\n","      <td>0.482849</td>\n","      <td>2672.53426</td>\n","      <td>546.663930</td>\n","      <td>112.006102</td>\n","      <td>8.138688</td>\n","      <td>3.198099</td>\n","      <td>0.116928</td>\n","      <td>3.396778</td>\n","      <td>7.948668</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.14492</td>\n","      <td>0.149006</td>\n","      <td>13.673940</td>\n","      <td>72.611063</td>\n","      <td>6850.484442</td>\n","      <td>45.745974</td>\n","      <td>114.842372</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>308 rows × 58 columns</p>\n","</div>"],"text/plain":["               Id        AB          AF          AH          AM         AR   \n","0    000ff2bfdfe9  0.209377  3109.03329   85.200147   22.394407   8.138688  \\\n","1    007255e47698  0.145282   978.76416   85.200147   36.968889   8.138688   \n","6    049232ca8356  0.348249  1733.65412   85.200147    8.377385  15.312480   \n","7    057287f2da6d  0.269199   966.45483   85.200147   21.174189   8.138688   \n","11   06554e7b9979  0.760594  6957.75289  200.089275   23.462872   8.138688   \n","..            ...       ...         ...         ...         ...        ...   \n","609  fbc241daef00  0.367478  4461.60154   85.200147   25.842917   8.138688   \n","611  fd1dd68d51b4  0.175193  2607.26686   85.200147    7.067354   8.138688   \n","612  fd3dafe738fd  0.149555  3130.05946  123.763599    9.513984  13.020852   \n","614  fd8ef6377f76  0.427300  2459.10720  130.138587   55.355778  10.005552   \n","616  ffcca4ded3bb  0.482849  2672.53426  546.663930  112.006102   8.138688   \n","\n","           AX        AY         AZ        BC  ...        FL       FR   \n","0    0.699861  0.025578   9.812214  5.555634  ...  7.298162  1.73855  \\\n","1    3.632190  0.025578  13.517790  1.229900  ...  0.173229  0.49706   \n","6    1.913544  0.025578   6.547778  1.229900  ...  4.408484  0.86130   \n","7    4.987617  0.025578   9.408886  1.229900  ...  6.591896  0.49706   \n","11   7.627599  0.025578  16.794830  1.229900  ...  6.890084  1.09011   \n","..        ...       ...        ...       ...  ...       ...      ...   \n","609  5.731773  0.032277   8.444680  5.882436  ...  4.234008  0.49706   \n","611  4.030845  0.025578   3.396778  1.229900  ...  0.173229  1.89486   \n","612  3.499305  0.077343   8.545512  2.804172  ...  0.173229  1.26092   \n","614  8.070549  0.025578  15.408390  1.229900  ...  0.173229  0.49706   \n","616  3.198099  0.116928   3.396778  7.948668  ...  0.173229  1.14492   \n","\n","           FS         GB          GE            GF         GH          GI   \n","0    0.094822  11.339138   72.611063   2003.810319  22.136229   69.834944  \\\n","1    0.568932   9.292698   72.611063  27981.562750  29.135430   32.131996   \n","6    0.467337  17.878444  192.453107   3332.467494  34.166222  100.086808   \n","7    0.277693  18.445866  109.693986  21371.759850  35.208102   31.424696   \n","11   1.266551  42.928730   72.611063   8192.631033  32.659217   53.813956   \n","..        ...        ...         ...           ...        ...         ...   \n","609  0.067730  25.217722   72.611063   7113.007548  25.831182   17.505032   \n","611  1.395238  16.911036  246.093155  10960.364830  38.380254   41.007968   \n","612  0.067730   8.967128  217.148554   8095.932828  24.640462   69.191944   \n","614  0.067730  19.962092  128.896894   6474.652866  26.166072  119.559420   \n","616  0.149006  13.673940   72.611063   6850.484442  45.745974  114.842372   \n","\n","            GL  Class  \n","0     0.120343      1  \n","1    21.978000      0  \n","6     0.065096      0  \n","7     0.092873      0  \n","11    0.437845      0  \n","..         ...    ...  \n","609   0.208286      0  \n","611  21.978000      0  \n","612  21.978000      0  \n","614  21.978000      0  \n","616  21.978000      0  \n","\n","[308 rows x 58 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["******** train[2]********\n","n = 463\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>...</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000ff2bfdfe9</td>\n","      <td>0.209377</td>\n","      <td>3109.03329</td>\n","      <td>85.200147</td>\n","      <td>22.394407</td>\n","      <td>8.138688</td>\n","      <td>0.699861</td>\n","      <td>0.025578</td>\n","      <td>9.812214</td>\n","      <td>5.555634</td>\n","      <td>...</td>\n","      <td>7.298162</td>\n","      <td>1.73855</td>\n","      <td>0.094822</td>\n","      <td>11.339138</td>\n","      <td>72.611063</td>\n","      <td>2003.810319</td>\n","      <td>22.136229</td>\n","      <td>69.834944</td>\n","      <td>0.120343</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>007255e47698</td>\n","      <td>0.145282</td>\n","      <td>978.76416</td>\n","      <td>85.200147</td>\n","      <td>36.968889</td>\n","      <td>8.138688</td>\n","      <td>3.632190</td>\n","      <td>0.025578</td>\n","      <td>13.517790</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.568932</td>\n","      <td>9.292698</td>\n","      <td>72.611063</td>\n","      <td>27981.562750</td>\n","      <td>29.135430</td>\n","      <td>32.131996</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>013f2bd269f5</td>\n","      <td>0.470030</td>\n","      <td>2635.10654</td>\n","      <td>85.200147</td>\n","      <td>32.360553</td>\n","      <td>8.138688</td>\n","      <td>6.732840</td>\n","      <td>0.025578</td>\n","      <td>12.824570</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>7.709560</td>\n","      <td>0.97556</td>\n","      <td>1.198821</td>\n","      <td>37.077772</td>\n","      <td>88.609437</td>\n","      <td>13676.957810</td>\n","      <td>28.022851</td>\n","      <td>35.192676</td>\n","      <td>0.196941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>044fb8a146ec</td>\n","      <td>0.380297</td>\n","      <td>3733.04844</td>\n","      <td>85.200147</td>\n","      <td>14.103738</td>\n","      <td>8.138688</td>\n","      <td>3.942255</td>\n","      <td>0.054810</td>\n","      <td>3.396778</td>\n","      <td>102.151980</td>\n","      <td>...</td>\n","      <td>8.153058</td>\n","      <td>48.50134</td>\n","      <td>0.121914</td>\n","      <td>16.408728</td>\n","      <td>146.109943</td>\n","      <td>8524.370502</td>\n","      <td>45.381316</td>\n","      <td>36.262628</td>\n","      <td>0.096614</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>049232ca8356</td>\n","      <td>0.348249</td>\n","      <td>1733.65412</td>\n","      <td>85.200147</td>\n","      <td>8.377385</td>\n","      <td>15.312480</td>\n","      <td>1.913544</td>\n","      <td>0.025578</td>\n","      <td>6.547778</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>4.408484</td>\n","      <td>0.86130</td>\n","      <td>0.467337</td>\n","      <td>17.878444</td>\n","      <td>192.453107</td>\n","      <td>3332.467494</td>\n","      <td>34.166222</td>\n","      <td>100.086808</td>\n","      <td>0.065096</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>609</th>\n","      <td>fbc241daef00</td>\n","      <td>0.367478</td>\n","      <td>4461.60154</td>\n","      <td>85.200147</td>\n","      <td>25.842917</td>\n","      <td>8.138688</td>\n","      <td>5.731773</td>\n","      <td>0.032277</td>\n","      <td>8.444680</td>\n","      <td>5.882436</td>\n","      <td>...</td>\n","      <td>4.234008</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>25.217722</td>\n","      <td>72.611063</td>\n","      <td>7113.007548</td>\n","      <td>25.831182</td>\n","      <td>17.505032</td>\n","      <td>0.208286</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>611</th>\n","      <td>fd1dd68d51b4</td>\n","      <td>0.175193</td>\n","      <td>2607.26686</td>\n","      <td>85.200147</td>\n","      <td>7.067354</td>\n","      <td>8.138688</td>\n","      <td>4.030845</td>\n","      <td>0.025578</td>\n","      <td>3.396778</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.89486</td>\n","      <td>1.395238</td>\n","      <td>16.911036</td>\n","      <td>246.093155</td>\n","      <td>10960.364830</td>\n","      <td>38.380254</td>\n","      <td>41.007968</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>612</th>\n","      <td>fd3dafe738fd</td>\n","      <td>0.149555</td>\n","      <td>3130.05946</td>\n","      <td>123.763599</td>\n","      <td>9.513984</td>\n","      <td>13.020852</td>\n","      <td>3.499305</td>\n","      <td>0.077343</td>\n","      <td>8.545512</td>\n","      <td>2.804172</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.26092</td>\n","      <td>0.067730</td>\n","      <td>8.967128</td>\n","      <td>217.148554</td>\n","      <td>8095.932828</td>\n","      <td>24.640462</td>\n","      <td>69.191944</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>fd8ef6377f76</td>\n","      <td>0.427300</td>\n","      <td>2459.10720</td>\n","      <td>130.138587</td>\n","      <td>55.355778</td>\n","      <td>10.005552</td>\n","      <td>8.070549</td>\n","      <td>0.025578</td>\n","      <td>15.408390</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>19.962092</td>\n","      <td>128.896894</td>\n","      <td>6474.652866</td>\n","      <td>26.166072</td>\n","      <td>119.559420</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>ffcca4ded3bb</td>\n","      <td>0.482849</td>\n","      <td>2672.53426</td>\n","      <td>546.663930</td>\n","      <td>112.006102</td>\n","      <td>8.138688</td>\n","      <td>3.198099</td>\n","      <td>0.116928</td>\n","      <td>3.396778</td>\n","      <td>7.948668</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.14492</td>\n","      <td>0.149006</td>\n","      <td>13.673940</td>\n","      <td>72.611063</td>\n","      <td>6850.484442</td>\n","      <td>45.745974</td>\n","      <td>114.842372</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>463 rows × 58 columns</p>\n","</div>"],"text/plain":["               Id        AB          AF          AH          AM         AR   \n","0    000ff2bfdfe9  0.209377  3109.03329   85.200147   22.394407   8.138688  \\\n","1    007255e47698  0.145282   978.76416   85.200147   36.968889   8.138688   \n","2    013f2bd269f5  0.470030  2635.10654   85.200147   32.360553   8.138688   \n","4    044fb8a146ec  0.380297  3733.04844   85.200147   14.103738   8.138688   \n","6    049232ca8356  0.348249  1733.65412   85.200147    8.377385  15.312480   \n","..            ...       ...         ...         ...         ...        ...   \n","609  fbc241daef00  0.367478  4461.60154   85.200147   25.842917   8.138688   \n","611  fd1dd68d51b4  0.175193  2607.26686   85.200147    7.067354   8.138688   \n","612  fd3dafe738fd  0.149555  3130.05946  123.763599    9.513984  13.020852   \n","614  fd8ef6377f76  0.427300  2459.10720  130.138587   55.355778  10.005552   \n","616  ffcca4ded3bb  0.482849  2672.53426  546.663930  112.006102   8.138688   \n","\n","           AX        AY         AZ          BC  ...        FL        FR   \n","0    0.699861  0.025578   9.812214    5.555634  ...  7.298162   1.73855  \\\n","1    3.632190  0.025578  13.517790    1.229900  ...  0.173229   0.49706   \n","2    6.732840  0.025578  12.824570    1.229900  ...  7.709560   0.97556   \n","4    3.942255  0.054810   3.396778  102.151980  ...  8.153058  48.50134   \n","6    1.913544  0.025578   6.547778    1.229900  ...  4.408484   0.86130   \n","..        ...       ...        ...         ...  ...       ...       ...   \n","609  5.731773  0.032277   8.444680    5.882436  ...  4.234008   0.49706   \n","611  4.030845  0.025578   3.396778    1.229900  ...  0.173229   1.89486   \n","612  3.499305  0.077343   8.545512    2.804172  ...  0.173229   1.26092   \n","614  8.070549  0.025578  15.408390    1.229900  ...  0.173229   0.49706   \n","616  3.198099  0.116928   3.396778    7.948668  ...  0.173229   1.14492   \n","\n","           FS         GB          GE            GF         GH          GI   \n","0    0.094822  11.339138   72.611063   2003.810319  22.136229   69.834944  \\\n","1    0.568932   9.292698   72.611063  27981.562750  29.135430   32.131996   \n","2    1.198821  37.077772   88.609437  13676.957810  28.022851   35.192676   \n","4    0.121914  16.408728  146.109943   8524.370502  45.381316   36.262628   \n","6    0.467337  17.878444  192.453107   3332.467494  34.166222  100.086808   \n","..        ...        ...         ...           ...        ...         ...   \n","609  0.067730  25.217722   72.611063   7113.007548  25.831182   17.505032   \n","611  1.395238  16.911036  246.093155  10960.364830  38.380254   41.007968   \n","612  0.067730   8.967128  217.148554   8095.932828  24.640462   69.191944   \n","614  0.067730  19.962092  128.896894   6474.652866  26.166072  119.559420   \n","616  0.149006  13.673940   72.611063   6850.484442  45.745974  114.842372   \n","\n","            GL  Class  \n","0     0.120343      1  \n","1    21.978000      0  \n","2     0.196941      0  \n","4     0.096614      1  \n","6     0.065096      0  \n","..         ...    ...  \n","609   0.208286      0  \n","611  21.978000      0  \n","612  21.978000      0  \n","614  21.978000      0  \n","616  21.978000      0  \n","\n","[463 rows x 58 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["******** train[3]********\n","n = 154\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>...</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>043ac50845d5</td>\n","      <td>0.252107</td>\n","      <td>3819.65177</td>\n","      <td>120.201618</td>\n","      <td>77.112203</td>\n","      <td>8.138688</td>\n","      <td>3.685344</td>\n","      <td>0.025578</td>\n","      <td>11.053708</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>6.122162</td>\n","      <td>0.49706</td>\n","      <td>0.284466</td>\n","      <td>18.529584</td>\n","      <td>82.416803</td>\n","      <td>2094.262452</td>\n","      <td>39.948656</td>\n","      <td>90.493248</td>\n","      <td>0.155829</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>04517a3c90bd</td>\n","      <td>0.209377</td>\n","      <td>2615.81430</td>\n","      <td>85.200147</td>\n","      <td>8.541526</td>\n","      <td>8.138688</td>\n","      <td>4.013127</td>\n","      <td>0.025578</td>\n","      <td>12.547282</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>1.164956</td>\n","      <td>21.915512</td>\n","      <td>72.611063</td>\n","      <td>24177.595550</td>\n","      <td>28.525186</td>\n","      <td>82.527764</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0594b00fb30a</td>\n","      <td>0.346113</td>\n","      <td>3238.43674</td>\n","      <td>85.200147</td>\n","      <td>28.888816</td>\n","      <td>8.138688</td>\n","      <td>4.021986</td>\n","      <td>0.025578</td>\n","      <td>8.243016</td>\n","      <td>3.626448</td>\n","      <td>...</td>\n","      <td>4.762291</td>\n","      <td>1.18262</td>\n","      <td>0.067730</td>\n","      <td>17.245908</td>\n","      <td>147.218610</td>\n","      <td>4589.611956</td>\n","      <td>29.771721</td>\n","      <td>54.675576</td>\n","      <td>0.073416</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>068a4e4bbbab</td>\n","      <td>0.491395</td>\n","      <td>2627.29962</td>\n","      <td>138.377301</td>\n","      <td>48.969764</td>\n","      <td>8.138688</td>\n","      <td>4.216884</td>\n","      <td>0.025578</td>\n","      <td>12.068330</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>5.661638</td>\n","      <td>0.97614</td>\n","      <td>0.149006</td>\n","      <td>23.301510</td>\n","      <td>72.611063</td>\n","      <td>25583.307300</td>\n","      <td>26.143746</td>\n","      <td>45.776456</td>\n","      <td>0.180321</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0aa059dad7f3</td>\n","      <td>0.448665</td>\n","      <td>3516.61453</td>\n","      <td>109.454712</td>\n","      <td>56.644130</td>\n","      <td>8.138688</td>\n","      <td>5.864658</td>\n","      <td>0.028623</td>\n","      <td>11.179748</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>4.464619</td>\n","      <td>1.53758</td>\n","      <td>0.257374</td>\n","      <td>10.176388</td>\n","      <td>72.611063</td>\n","      <td>49250.995060</td>\n","      <td>38.344905</td>\n","      <td>7.314768</td>\n","      <td>0.233809</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>599</th>\n","      <td>f82b07dfd7fb</td>\n","      <td>1.106707</td>\n","      <td>3279.32506</td>\n","      <td>118.764633</td>\n","      <td>48.660064</td>\n","      <td>8.138688</td>\n","      <td>8.212293</td>\n","      <td>0.025578</td>\n","      <td>9.988670</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>0.434226</td>\n","      <td>1.14086</td>\n","      <td>1.713569</td>\n","      <td>20.855084</td>\n","      <td>72.611063</td>\n","      <td>13738.933020</td>\n","      <td>43.200810</td>\n","      <td>21.648524</td>\n","      <td>1.566000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>602</th>\n","      <td>f955c0ed8895</td>\n","      <td>0.350386</td>\n","      <td>5431.63797</td>\n","      <td>85.200147</td>\n","      <td>11.607556</td>\n","      <td>8.138688</td>\n","      <td>7.565586</td>\n","      <td>0.025578</td>\n","      <td>10.269109</td>\n","      <td>2.393034</td>\n","      <td>...</td>\n","      <td>4.764967</td>\n","      <td>0.49706</td>\n","      <td>0.704392</td>\n","      <td>12.027486</td>\n","      <td>212.210348</td>\n","      <td>9146.473587</td>\n","      <td>17.287766</td>\n","      <td>30.712252</td>\n","      <td>0.171600</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>610</th>\n","      <td>fbd12c4ae88b</td>\n","      <td>0.581128</td>\n","      <td>4268.30888</td>\n","      <td>85.200147</td>\n","      <td>43.212441</td>\n","      <td>11.835708</td>\n","      <td>6.343044</td>\n","      <td>0.025578</td>\n","      <td>7.045636</td>\n","      <td>11.188576</td>\n","      <td>...</td>\n","      <td>0.173229</td>\n","      <td>1.20640</td>\n","      <td>0.196417</td>\n","      <td>17.255210</td>\n","      <td>72.611063</td>\n","      <td>38475.318010</td>\n","      <td>27.766102</td>\n","      <td>133.988340</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>fd895603f071</td>\n","      <td>0.435846</td>\n","      <td>5462.03438</td>\n","      <td>85.200147</td>\n","      <td>46.551007</td>\n","      <td>15.973224</td>\n","      <td>5.979825</td>\n","      <td>0.025882</td>\n","      <td>12.622906</td>\n","      <td>3.777550</td>\n","      <td>...</td>\n","      <td>10.223150</td>\n","      <td>1.24236</td>\n","      <td>0.426699</td>\n","      <td>35.896418</td>\n","      <td>496.994214</td>\n","      <td>3085.308063</td>\n","      <td>29.648928</td>\n","      <td>124.808872</td>\n","      <td>0.145340</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>fe1942975e40</td>\n","      <td>0.363205</td>\n","      <td>1263.53524</td>\n","      <td>85.200147</td>\n","      <td>23.685856</td>\n","      <td>8.138688</td>\n","      <td>7.981959</td>\n","      <td>0.025578</td>\n","      <td>7.524588</td>\n","      <td>1.229900</td>\n","      <td>...</td>\n","      <td>9.256996</td>\n","      <td>0.78764</td>\n","      <td>0.670527</td>\n","      <td>24.594488</td>\n","      <td>72.611063</td>\n","      <td>1965.343176</td>\n","      <td>25.116750</td>\n","      <td>37.155112</td>\n","      <td>0.184622</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 58 columns</p>\n","</div>"],"text/plain":["               Id        AB          AF          AH         AM         AR   \n","3    043ac50845d5  0.252107  3819.65177  120.201618  77.112203   8.138688  \\\n","5    04517a3c90bd  0.209377  2615.81430   85.200147   8.541526   8.138688   \n","8    0594b00fb30a  0.346113  3238.43674   85.200147  28.888816   8.138688   \n","12   068a4e4bbbab  0.491395  2627.29962  138.377301  48.969764   8.138688   \n","17   0aa059dad7f3  0.448665  3516.61453  109.454712  56.644130   8.138688   \n","..            ...       ...         ...         ...        ...        ...   \n","599  f82b07dfd7fb  1.106707  3279.32506  118.764633  48.660064   8.138688   \n","602  f955c0ed8895  0.350386  5431.63797   85.200147  11.607556   8.138688   \n","610  fbd12c4ae88b  0.581128  4268.30888   85.200147  43.212441  11.835708   \n","613  fd895603f071  0.435846  5462.03438   85.200147  46.551007  15.973224   \n","615  fe1942975e40  0.363205  1263.53524   85.200147  23.685856   8.138688   \n","\n","           AX        AY         AZ         BC  ...         FL       FR   \n","3    3.685344  0.025578  11.053708   1.229900  ...   6.122162  0.49706  \\\n","5    4.013127  0.025578  12.547282   1.229900  ...   0.173229  0.49706   \n","8    4.021986  0.025578   8.243016   3.626448  ...   4.762291  1.18262   \n","12   4.216884  0.025578  12.068330   1.229900  ...   5.661638  0.97614   \n","17   5.864658  0.028623  11.179748   1.229900  ...   4.464619  1.53758   \n","..        ...       ...        ...        ...  ...        ...      ...   \n","599  8.212293  0.025578   9.988670   1.229900  ...   0.434226  1.14086   \n","602  7.565586  0.025578  10.269109   2.393034  ...   4.764967  0.49706   \n","610  6.343044  0.025578   7.045636  11.188576  ...   0.173229  1.20640   \n","613  5.979825  0.025882  12.622906   3.777550  ...  10.223150  1.24236   \n","615  7.981959  0.025578   7.524588   1.229900  ...   9.256996  0.78764   \n","\n","           FS         GB          GE            GF         GH          GI   \n","3    0.284466  18.529584   82.416803   2094.262452  39.948656   90.493248  \\\n","5    1.164956  21.915512   72.611063  24177.595550  28.525186   82.527764   \n","8    0.067730  17.245908  147.218610   4589.611956  29.771721   54.675576   \n","12   0.149006  23.301510   72.611063  25583.307300  26.143746   45.776456   \n","17   0.257374  10.176388   72.611063  49250.995060  38.344905    7.314768   \n","..        ...        ...         ...           ...        ...         ...   \n","599  1.713569  20.855084   72.611063  13738.933020  43.200810   21.648524   \n","602  0.704392  12.027486  212.210348   9146.473587  17.287766   30.712252   \n","610  0.196417  17.255210   72.611063  38475.318010  27.766102  133.988340   \n","613  0.426699  35.896418  496.994214   3085.308063  29.648928  124.808872   \n","615  0.670527  24.594488   72.611063   1965.343176  25.116750   37.155112   \n","\n","            GL  Class  \n","3     0.155829      0  \n","5    21.978000      0  \n","8     0.073416      0  \n","12    0.180321      0  \n","17    0.233809      0  \n","..         ...    ...  \n","599   1.566000      0  \n","602   0.171600      0  \n","610  21.978000      0  \n","613   0.145340      0  \n","615   0.184622      0  \n","\n","[154 rows x 58 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["import random\n","random.seed(0)\n","patient_ids = train_validation['Id'].unique().tolist()\n","train = {}\n","nDataSubsets = len(dataSubsetsProps); \n","ns = [0]*nDataSubsets\n","nPatients = len(patient_ids)\n","random_ids = random.sample(patient_ids, nPatients)\n","previous_n = 0\n","for i in range(nDataSubsets):\n","    ns[i] = round(nPatients*dataSubsetsProps[i])\n","    train[i] = train_validation[train_validation.Id.isin(random_ids[previous_n:ns[i]+previous_n])]\n","    train[i] = train[i].sort_values(by=['Id'], ascending=True)\n","    if np.sum(dataSubsetsProps) == 1 or i==2:\n","        previous_n += ns[i]\n","    # validation = train_validation[train_validation.Id.isin(random_ids[n:])]\n","    print('******** train[' + str(i)+ ']********')\n","    print('n =', ns[i])\n","    display(train[i])\n","    # print('******** validation ********')\n","    # display(validation)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.534216Z","iopub.status.busy":"2023-05-05T21:24:58.533855Z","iopub.status.idle":"2023-05-05T21:24:58.545967Z","shell.execute_reply":"2023-05-05T21:24:58.544318Z","shell.execute_reply.started":"2023-05-05T21:24:58.534184Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["we have 56 quanti vars. The fisrt 10):  ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD']\n"]}],"source":["targetVars = ['Class']\n","# variables types\n","quantiVars = train_validation.columns.to_list()\n","for case in ['Id', 'Class']: quantiVars.remove(case)\n","# qualiVars = ['EJ']\n","# for u in targetVars:\n","#     quantiVars = ['visit_month']\n","#     if PRED_PREFIX == 'pe':\n","#         quantiVars += ['pe_'+pe for pe in tv_peptideCatgories]; quantiVars.remove('pe_OTHERS')\n","#     elif PRED_PREFIX == 'pr':\n","#         quantiVars += ['pr_'+pr for pr in tv_UniProtCatgories]; quantiVars.remove('pr_OTHERS')\n","print('we have', str(len(quantiVars)), 'quanti vars. The fisrt 10): ', quantiVars[:10])\n","# print('we have', str(len(qualiVars)), 'quali var: ', qualiVars)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Feature engineering"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.570387Z","iopub.status.busy":"2023-05-05T21:24:58.569862Z","iopub.status.idle":"2023-05-05T21:24:58.833795Z","shell.execute_reply":"2023-05-05T21:24:58.832532Z","shell.execute_reply.started":"2023-05-05T21:24:58.570344Z"},"trusted":true},"outputs":[],"source":["# #ranked peptides (all, plus visit_month and eventually some target)\n","quantiVars = ['EJ',\n"," 'DU',\n"," 'FD',\n"," 'CH',\n"," 'FI',\n"," 'AB',\n"," 'DI',\n"," 'BQ',\n"," 'EP',\n"," 'DN',\n"," 'DY',\n"," 'CW',\n"," 'FL',\n"," 'AX',\n"," 'EE',\n"," 'AZ',\n"," 'CD',\n"," 'GB',\n"," 'EB',\n"," 'DA',\n"," 'BC',\n"," 'AR',\n"," 'DH',\n"," 'GH',\n"," 'CU',\n"," 'GL',\n"," 'GE',\n"," 'FR',\n"," 'CB',\n"," 'FC',\n"," 'FE',\n"," 'CL',\n"," 'EH',\n"," 'FS',\n"," 'CR',\n"," 'AH',\n"," 'DV',\n"," 'GI',\n"," 'EG',\n"," 'EL',\n"," 'BZ',\n"," 'AM',\n"," 'BR',\n"," 'AY',\n"," 'AF',\n"," 'EU',\n"," 'DL',\n"," 'CS',\n"," 'BN',\n"," 'GF',\n"," 'CF',\n"," 'CC',\n"," 'BP',\n"," 'BD',\n"," 'DF',\n"," 'DE']\n"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.835745Z","iopub.status.busy":"2023-05-05T21:24:58.835400Z","iopub.status.idle":"2023-05-05T21:24:58.843301Z","shell.execute_reply":"2023-05-05T21:24:58.841568Z","shell.execute_reply.started":"2023-05-05T21:24:58.835713Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["quantiVars ['EJ', 'DU', 'FD', 'CH', 'FI', 'AB', 'DI', 'BQ', 'EP', 'DN', 'DY', 'CW', 'FL', 'AX', 'EE', 'AZ', 'CD', 'GB', 'EB', 'DA', 'BC', 'AR', 'DH', 'GH', 'CU', 'GL', 'GE', 'FR', 'CB', 'FC', 'FE', 'CL', 'EH', 'FS', 'CR', 'AH', 'DV', 'GI', 'EG', 'EL', 'BZ', 'AM', 'BR', 'AY', 'AF', 'EU', 'DL', 'CS', 'BN', 'GF', 'CF', 'CC', 'BP', 'BD', 'DF', 'DE']\n"]}],"source":["# Separating promising/interesting/important pr and/or pe features (according to the UPDRS log-linear models)\n","# for u in targetVars:\n","quantiVars = quantiVars[:nImportantFeatures]\n","print('quantiVars', quantiVars)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.845742Z","iopub.status.busy":"2023-05-05T21:24:58.845325Z","iopub.status.idle":"2023-05-05T21:24:58.918624Z","shell.execute_reply":"2023-05-05T21:24:58.916909Z","shell.execute_reply.started":"2023-05-05T21:24:58.845706Z"},"trusted":true},"outputs":[],"source":["#defining the training and validation data\n","\n","t_ = {}# dictionaries for train and validation, per target\n","# for u in targetVars:\n","    # ltheoreticalMax = np.log1p(theoreticalMax)\n","t_ = {}\n","for i in range(nDataSubsets):\n","    t_[i] = train[i][quantiVars+[u]].dropna(subset=u)\n","    if i < nDataSubsets-1:#the last sample of the partition is complete\n","        t_[i] = t_[i][t_[i]>openMinimalTreshold]\n","        # t_[i] = np.log1p(t_[i])/ltheoreticalMax  # converting to log(1+x)\n"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:24:58.921252Z","iopub.status.busy":"2023-05-05T21:24:58.920821Z","iopub.status.idle":"2023-05-05T21:25:01.969162Z","shell.execute_reply":"2023-05-05T21:25:01.967725Z","shell.execute_reply.started":"2023-05-05T21:24:58.921212Z"},"trusted":true},"outputs":[],"source":["#plotTargets from https://www.kaggle.com/code/adityarahul/eda-linearregression\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","def plotTargets(minmalTreshold = 0, logScale = False):\n","    # colors = [\"green\", \"yellow\", \"orange\"]\n","    # sns.set_palette(sns.color_palette(colors))\n","    f, axes = plt.subplots(4, 2, layout=\"constrained\",\n","                            gridspec_kw={\"height_ratios\": (.15, .85, .15, .85)}, figsize=(11, 7))\n","    f.suptitle('UPDRS value distributions, values >'+str(minmalTreshold), fontsize=13)\n","    for i in [0,2]:\n","        for j in [0,1]:#range(len(targetVars)):\n","            u = targetVars[i+j]\n","            data = pd.concat([t_[k] for k in range(1)])#range(len(targetVars))\n","            subData = data[data>minmalTreshold]# if isWithoutZero else data\n","            x = subData if logScale else subData\n","            splot = sns.boxplot(ax=axes[i][j], x=x)\n","            splot.axes.get_xaxis().set_visible(False)\n","            splot.set_title(u+', sample size = '+str(len(subData)))\n","            splot = sns.histplot(ax=axes[i+1][j], x=x, kde=True, alpha=0.5, ec='black')\n","            splot.set_xlabel('Score')\n","            splot.set_ylabel('Count')\n","            # splot.set_title(u)\n","    plt.show()\n","# plotTargets(minmalTreshold = -1, logScale = True)\n","# plotTargets(minmalTreshold = 0, logScale = True)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:01.971859Z","iopub.status.busy":"2023-05-05T21:25:01.971366Z","iopub.status.idle":"2023-05-05T21:25:02.089331Z","shell.execute_reply":"2023-05-05T21:25:02.087720Z","shell.execute_reply.started":"2023-05-05T21:25:01.971809Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["********************* train paritiion 0  *********************\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 154 entries, 1 to 616\n","Data columns (total 57 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   EJ      154 non-null    int32  \n"," 1   DU      154 non-null    float64\n"," 2   FD      154 non-null    float64\n"," 3   CH      154 non-null    float64\n"," 4   FI      154 non-null    float64\n"," 5   AB      154 non-null    float64\n"," 6   DI      154 non-null    float64\n"," 7   BQ      140 non-null    float64\n"," 8   EP      154 non-null    float64\n"," 9   DN      154 non-null    float64\n"," 10  DY      154 non-null    float64\n"," 11  CW      154 non-null    float64\n"," 12  FL      154 non-null    float64\n"," 13  AX      154 non-null    float64\n"," 14  EE      154 non-null    float64\n"," 15  AZ      154 non-null    float64\n"," 16  CD      154 non-null    float64\n"," 17  GB      154 non-null    float64\n"," 18  EB      154 non-null    float64\n"," 19  DA      154 non-null    float64\n"," 20  BC      154 non-null    float64\n"," 21  AR      154 non-null    float64\n"," 22  DH      154 non-null    float64\n"," 23  GH      154 non-null    float64\n"," 24  CU      154 non-null    float64\n"," 25  GL      154 non-null    float64\n"," 26  GE      154 non-null    float64\n"," 27  FR      154 non-null    float64\n"," 28  CB      154 non-null    float64\n"," 29  FC      154 non-null    float64\n"," 30  FE      154 non-null    float64\n"," 31  CL      154 non-null    float64\n"," 32  EH      154 non-null    float64\n"," 33  FS      153 non-null    float64\n"," 34  CR      154 non-null    float64\n"," 35  AH      154 non-null    float64\n"," 36  DV      154 non-null    float64\n"," 37  GI      154 non-null    float64\n"," 38  EG      154 non-null    float64\n"," 39  EL      140 non-null    float64\n"," 40  BZ      154 non-null    float64\n"," 41  AM      154 non-null    float64\n"," 42  BR      154 non-null    float64\n"," 43  AY      154 non-null    float64\n"," 44  AF      154 non-null    float64\n"," 45  EU      154 non-null    float64\n"," 46  DL      154 non-null    float64\n"," 47  CS      154 non-null    float64\n"," 48  BN      154 non-null    float64\n"," 49  GF      154 non-null    float64\n"," 50  CF      154 non-null    float64\n"," 51  CC      154 non-null    float64\n"," 52  BP      154 non-null    float64\n"," 53  BD      154 non-null    float64\n"," 54  DF      154 non-null    float64\n"," 55  DE      154 non-null    float64\n"," 56  Class   154 non-null    int64  \n","dtypes: float64(55), int32(1), int64(1)\n","memory usage: 69.2 KB\n","None\n","********************* train paritiion 1  *********************\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 308 entries, 0 to 616\n","Data columns (total 57 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   EJ      308 non-null    int32  \n"," 1   DU      308 non-null    float64\n"," 2   FD      308 non-null    float64\n"," 3   CH      308 non-null    float64\n"," 4   FI      308 non-null    float64\n"," 5   AB      308 non-null    float64\n"," 6   DI      308 non-null    float64\n"," 7   BQ      285 non-null    float64\n"," 8   EP      308 non-null    float64\n"," 9   DN      308 non-null    float64\n"," 10  DY      308 non-null    float64\n"," 11  CW      308 non-null    float64\n"," 12  FL      308 non-null    float64\n"," 13  AX      308 non-null    float64\n"," 14  EE      308 non-null    float64\n"," 15  AZ      308 non-null    float64\n"," 16  CD      308 non-null    float64\n"," 17  GB      308 non-null    float64\n"," 18  EB      308 non-null    float64\n"," 19  DA      308 non-null    float64\n"," 20  BC      308 non-null    float64\n"," 21  AR      308 non-null    float64\n"," 22  DH      308 non-null    float64\n"," 23  GH      308 non-null    float64\n"," 24  CU      308 non-null    float64\n"," 25  GL      308 non-null    float64\n"," 26  GE      308 non-null    float64\n"," 27  FR      308 non-null    float64\n"," 28  CB      307 non-null    float64\n"," 29  FC      307 non-null    float64\n"," 30  FE      308 non-null    float64\n"," 31  CL      308 non-null    float64\n"," 32  EH      308 non-null    float64\n"," 33  FS      306 non-null    float64\n"," 34  CR      308 non-null    float64\n"," 35  AH      308 non-null    float64\n"," 36  DV      308 non-null    float64\n"," 37  GI      308 non-null    float64\n"," 38  EG      308 non-null    float64\n"," 39  EL      283 non-null    float64\n"," 40  BZ      308 non-null    float64\n"," 41  AM      308 non-null    float64\n"," 42  BR      308 non-null    float64\n"," 43  AY      308 non-null    float64\n"," 44  AF      308 non-null    float64\n"," 45  EU      308 non-null    float64\n"," 46  DL      308 non-null    float64\n"," 47  CS      308 non-null    float64\n"," 48  BN      308 non-null    float64\n"," 49  GF      308 non-null    float64\n"," 50  CF      308 non-null    float64\n"," 51  CC      306 non-null    float64\n"," 52  BP      308 non-null    float64\n"," 53  BD      308 non-null    float64\n"," 54  DF      308 non-null    float64\n"," 55  DE      308 non-null    float64\n"," 56  Class   308 non-null    int64  \n","dtypes: float64(55), int32(1), int64(1)\n","memory usage: 138.4 KB\n","None\n","********************* train paritiion 2  *********************\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 463 entries, 0 to 616\n","Data columns (total 57 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   EJ      463 non-null    int32  \n"," 1   DU      463 non-null    float64\n"," 2   FD      463 non-null    float64\n"," 3   CH      463 non-null    float64\n"," 4   FI      463 non-null    float64\n"," 5   AB      463 non-null    float64\n"," 6   DI      463 non-null    float64\n"," 7   BQ      424 non-null    float64\n"," 8   EP      463 non-null    float64\n"," 9   DN      463 non-null    float64\n"," 10  DY      463 non-null    float64\n"," 11  CW      463 non-null    float64\n"," 12  FL      463 non-null    float64\n"," 13  AX      463 non-null    float64\n"," 14  EE      463 non-null    float64\n"," 15  AZ      463 non-null    float64\n"," 16  CD      463 non-null    float64\n"," 17  GB      463 non-null    float64\n"," 18  EB      463 non-null    float64\n"," 19  DA      463 non-null    float64\n"," 20  BC      463 non-null    float64\n"," 21  AR      463 non-null    float64\n"," 22  DH      463 non-null    float64\n"," 23  GH      463 non-null    float64\n"," 24  CU      463 non-null    float64\n"," 25  GL      463 non-null    float64\n"," 26  GE      463 non-null    float64\n"," 27  FR      463 non-null    float64\n"," 28  CB      461 non-null    float64\n"," 29  FC      462 non-null    float64\n"," 30  FE      463 non-null    float64\n"," 31  CL      463 non-null    float64\n"," 32  EH      463 non-null    float64\n"," 33  FS      461 non-null    float64\n"," 34  CR      463 non-null    float64\n"," 35  AH      463 non-null    float64\n"," 36  DV      463 non-null    float64\n"," 37  GI      463 non-null    float64\n"," 38  EG      463 non-null    float64\n"," 39  EL      425 non-null    float64\n"," 40  BZ      463 non-null    float64\n"," 41  AM      463 non-null    float64\n"," 42  BR      463 non-null    float64\n"," 43  AY      463 non-null    float64\n"," 44  AF      463 non-null    float64\n"," 45  EU      463 non-null    float64\n"," 46  DL      463 non-null    float64\n"," 47  CS      463 non-null    float64\n"," 48  BN      463 non-null    float64\n"," 49  GF      463 non-null    float64\n"," 50  CF      463 non-null    float64\n"," 51  CC      460 non-null    float64\n"," 52  BP      463 non-null    float64\n"," 53  BD      463 non-null    float64\n"," 54  DF      463 non-null    float64\n"," 55  DE      463 non-null    float64\n"," 56  Class   463 non-null    int64  \n","dtypes: float64(55), int32(1), int64(1)\n","memory usage: 208.0 KB\n","None\n","********************* train paritiion 3  *********************\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 154 entries, 3 to 615\n","Data columns (total 57 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   EJ      154 non-null    int32  \n"," 1   DU      153 non-null    float64\n"," 2   FD      154 non-null    float64\n"," 3   CH      154 non-null    float64\n"," 4   FI      154 non-null    float64\n"," 5   AB      154 non-null    float64\n"," 6   DI      154 non-null    float64\n"," 7   BQ      133 non-null    float64\n"," 8   EP      154 non-null    float64\n"," 9   DN      154 non-null    float64\n"," 10  DY      154 non-null    float64\n"," 11  CW      154 non-null    float64\n"," 12  FL      153 non-null    float64\n"," 13  AX      154 non-null    float64\n"," 14  EE      154 non-null    float64\n"," 15  AZ      154 non-null    float64\n"," 16  CD      154 non-null    float64\n"," 17  GB      154 non-null    float64\n"," 18  EB      154 non-null    float64\n"," 19  DA      154 non-null    float64\n"," 20  BC      154 non-null    float64\n"," 21  AR      154 non-null    float64\n"," 22  DH      154 non-null    float64\n"," 23  GH      154 non-null    float64\n"," 24  CU      154 non-null    float64\n"," 25  GL      153 non-null    float64\n"," 26  GE      154 non-null    float64\n"," 27  FR      154 non-null    float64\n"," 28  CB      154 non-null    float64\n"," 29  FC      154 non-null    float64\n"," 30  FE      154 non-null    float64\n"," 31  CL      154 non-null    float64\n"," 32  EH      154 non-null    float64\n"," 33  FS      154 non-null    float64\n"," 34  CR      154 non-null    float64\n"," 35  AH      154 non-null    float64\n"," 36  DV      154 non-null    float64\n"," 37  GI      154 non-null    float64\n"," 38  EG      154 non-null    float64\n"," 39  EL      132 non-null    float64\n"," 40  BZ      154 non-null    float64\n"," 41  AM      154 non-null    float64\n"," 42  BR      154 non-null    float64\n"," 43  AY      154 non-null    float64\n"," 44  AF      154 non-null    float64\n"," 45  EU      154 non-null    float64\n"," 46  DL      154 non-null    float64\n"," 47  CS      154 non-null    float64\n"," 48  BN      154 non-null    float64\n"," 49  GF      154 non-null    float64\n"," 50  CF      154 non-null    float64\n"," 51  CC      154 non-null    float64\n"," 52  BP      154 non-null    float64\n"," 53  BD      154 non-null    float64\n"," 54  DF      154 non-null    float64\n"," 55  DE      154 non-null    float64\n"," 56  Class   154 non-null    int64  \n","dtypes: float64(55), int32(1), int64(1)\n","memory usage: 69.2 KB\n","None\n"]}],"source":["# for u in targetVars:\n","for i in range(nDataSubsets):\n","    print('********************* train paritiion', str(i),' *********************')\n","    print(t_[i].info())\n","    # print('********************* validation *********************')\n","    # print(v_.info())"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.091645Z","iopub.status.busy":"2023-05-05T21:25:02.091199Z","iopub.status.idle":"2023-05-05T21:25:02.103772Z","shell.execute_reply":"2023-05-05T21:25:02.101904Z","shell.execute_reply.started":"2023-05-05T21:25:02.091609Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["********************* train paritiion 0  *********************\n","maximal number of classes:  2\n","********************* train paritiion 1  *********************\n","maximal number of classes:  2\n","********************* train paritiion 2  *********************\n","maximal number of classes:  2\n","********************* train paritiion 3  *********************\n","maximal number of classes:  2\n"]}],"source":["# for u in targetVars:\n","for i in range(nDataSubsets):\n","    print('********************* train paritiion', str(i),' *********************')\n","    # print('number of patients: ', t_.Id.nunique())\n","    # try: \n","    print('maximal number of classes: ', t_[i].Class.nunique())#in the original tv_clinical there were 17 visits...\n","    # except:\n","    #     print('maximal number of visits not found: This UPDRS is dependent of a time-dependent UPDRS')\n","    # print('number of proteins: ', t_.UniProt.nunique())\n","    # print('number of pepitides in the training set: ', t_[i].Peptide.nunique())\n","    # print('**************  validation **************')\n","    # print('number of patients: ', t_.Id.nunique())\n","    # print('maximal number of visits: ', v_.visit_month.nunique())#in the original tv_clinical there were 17 visits...\n","    # print('number of proteins: ', v_.UniProt.nunique())\n","    # print('number of pepitides in the training set: ', v_.Peptide.nunique())\n"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.106553Z","iopub.status.busy":"2023-05-05T21:25:02.105938Z","iopub.status.idle":"2023-05-05T21:25:02.154965Z","shell.execute_reply":"2023-05-05T21:25:02.153429Z","shell.execute_reply.started":"2023-05-05T21:25:02.106497Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["********************* missing values in the train paritiion 0  *********************\n","0     54\n","14     2\n","1      1\n","Name: count, dtype: int64\n","********************* missing values in the train paritiion 1  *********************\n","0     51\n","1      2\n","2      2\n","23     1\n","25     1\n","Name: count, dtype: int64\n","********************* missing values in the train paritiion 2  *********************\n","0     51\n","2      2\n","39     1\n","1      1\n","38     1\n","3      1\n","Name: count, dtype: int64\n","********************* missing values in the train paritiion 3  *********************\n","0     52\n","1      3\n","21     1\n","22     1\n","Name: count, dtype: int64\n"]}],"source":["#Verifying how much missing values we have in each column per dependent variable data set\n","# for u in targetVars:\n","for i in range(nDataSubsets):\n","    print('********************* missing values in the train paritiion', str(i),' *********************')\n","    print(t_[i].isnull().sum().value_counts())\n"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.157644Z","iopub.status.busy":"2023-05-05T21:25:02.157129Z","iopub.status.idle":"2023-05-05T21:25:02.190911Z","shell.execute_reply":"2023-05-05T21:25:02.189428Z","shell.execute_reply.started":"2023-05-05T21:25:02.157580Z"},"trusted":true},"outputs":[],"source":["#separating target and features\n","x_t = {}; y_t= {}; #x_v= {}; y_v= {}; #X and Y variables per updrs\n","# for u in targetVars:\n","x_t = {}; y_t= {};\n","for i in range(nDataSubsets):\n","    x_t[i] = t_[i][quantiVars]\n","    y_t[i] = t_[i][[u]]\n"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.194344Z","iopub.status.busy":"2023-05-05T21:25:02.193195Z","iopub.status.idle":"2023-05-05T21:25:02.220795Z","shell.execute_reply":"2023-05-05T21:25:02.219346Z","shell.execute_reply.started":"2023-05-05T21:25:02.194299Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EJ</th>\n","      <th>DU</th>\n","      <th>FD</th>\n","      <th>CH</th>\n","      <th>FI</th>\n","      <th>AB</th>\n","      <th>DI</th>\n","      <th>BQ</th>\n","      <th>EP</th>\n","      <th>DN</th>\n","      <th>...</th>\n","      <th>DL</th>\n","      <th>CS</th>\n","      <th>BN</th>\n","      <th>GF</th>\n","      <th>CF</th>\n","      <th>CC</th>\n","      <th>BP</th>\n","      <th>BD</th>\n","      <th>DF</th>\n","      <th>DE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.005518</td>\n","      <td>0.296850</td>\n","      <td>0.031442</td>\n","      <td>10.358927</td>\n","      <td>0.145282</td>\n","      <td>110.581815</td>\n","      <td>14.754720</td>\n","      <td>95.415086</td>\n","      <td>37.532000</td>\n","      <td>...</td>\n","      <td>75.74548</td>\n","      <td>28.310953</td>\n","      <td>19.4205</td>\n","      <td>27981.562750</td>\n","      <td>6.085041</td>\n","      <td>0.484710</td>\n","      <td>155.868030</td>\n","      <td>5496.92824</td>\n","      <td>0.238680</td>\n","      <td>178.553100</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1</td>\n","      <td>1.338018</td>\n","      <td>17.698197</td>\n","      <td>0.039800</td>\n","      <td>13.942377</td>\n","      <td>0.760594</td>\n","      <td>89.286975</td>\n","      <td>28.949365</td>\n","      <td>78.526968</td>\n","      <td>25.910728</td>\n","      <td>...</td>\n","      <td>87.87188</td>\n","      <td>44.522016</td>\n","      <td>26.4825</td>\n","      <td>8192.631033</td>\n","      <td>4.067337</td>\n","      <td>0.659828</td>\n","      <td>392.658570</td>\n","      <td>12083.34891</td>\n","      <td>0.238680</td>\n","      <td>204.187400</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>0.005518</td>\n","      <td>0.296850</td>\n","      <td>0.047362</td>\n","      <td>8.972407</td>\n","      <td>0.534125</td>\n","      <td>140.831707</td>\n","      <td>344.644105</td>\n","      <td>137.514884</td>\n","      <td>31.489348</td>\n","      <td>...</td>\n","      <td>108.55778</td>\n","      <td>33.267724</td>\n","      <td>24.7170</td>\n","      <td>895.517451</td>\n","      <td>9.130603</td>\n","      <td>0.443620</td>\n","      <td>374.074794</td>\n","      <td>5535.14441</td>\n","      <td>0.238680</td>\n","      <td>211.886560</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0</td>\n","      <td>0.005518</td>\n","      <td>0.296850</td>\n","      <td>0.041790</td>\n","      <td>3.583450</td>\n","      <td>0.508487</td>\n","      <td>194.021745</td>\n","      <td>73.244785</td>\n","      <td>310.673707</td>\n","      <td>29.247664</td>\n","      <td>...</td>\n","      <td>84.74276</td>\n","      <td>70.358942</td>\n","      <td>26.4825</td>\n","      <td>11777.141530</td>\n","      <td>16.349936</td>\n","      <td>0.503945</td>\n","      <td>336.873330</td>\n","      <td>10563.27538</td>\n","      <td>1.425060</td>\n","      <td>203.934605</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0</td>\n","      <td>0.005518</td>\n","      <td>0.296850</td>\n","      <td>0.023880</td>\n","      <td>9.107476</td>\n","      <td>0.252107</td>\n","      <td>166.996575</td>\n","      <td>109.751255</td>\n","      <td>94.701373</td>\n","      <td>27.760032</td>\n","      <td>...</td>\n","      <td>114.42912</td>\n","      <td>38.116397</td>\n","      <td>18.7143</td>\n","      <td>37275.608540</td>\n","      <td>1.325876</td>\n","      <td>0.551287</td>\n","      <td>215.366634</td>\n","      <td>5944.79970</td>\n","      <td>0.953316</td>\n","      <td>464.242495</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>581</th>\n","      <td>1</td>\n","      <td>1.324224</td>\n","      <td>2.600406</td>\n","      <td>0.076814</td>\n","      <td>8.365977</td>\n","      <td>1.096024</td>\n","      <td>174.150075</td>\n","      <td>206.484023</td>\n","      <td>152.484319</td>\n","      <td>36.542520</td>\n","      <td>...</td>\n","      <td>89.43432</td>\n","      <td>35.724315</td>\n","      <td>21.8922</td>\n","      <td>2184.856740</td>\n","      <td>13.489876</td>\n","      <td>0.486283</td>\n","      <td>161.681818</td>\n","      <td>5281.91734</td>\n","      <td>0.238680</td>\n","      <td>804.211855</td>\n","    </tr>\n","    <tr>\n","      <th>597</th>\n","      <td>0</td>\n","      <td>0.005518</td>\n","      <td>0.296850</td>\n","      <td>0.032238</td>\n","      <td>11.516657</td>\n","      <td>0.478576</td>\n","      <td>164.585093</td>\n","      <td>69.024685</td>\n","      <td>124.065565</td>\n","      <td>35.498448</td>\n","      <td>...</td>\n","      <td>110.64068</td>\n","      <td>34.353924</td>\n","      <td>25.7763</td>\n","      <td>18878.557980</td>\n","      <td>23.395934</td>\n","      <td>0.862360</td>\n","      <td>199.631466</td>\n","      <td>4452.78705</td>\n","      <td>0.238680</td>\n","      <td>620.984265</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>1</td>\n","      <td>8.876439</td>\n","      <td>14.872185</td>\n","      <td>0.028656</td>\n","      <td>10.199050</td>\n","      <td>0.636677</td>\n","      <td>523.664437</td>\n","      <td>49.857095</td>\n","      <td>78.526968</td>\n","      <td>17.346608</td>\n","      <td>...</td>\n","      <td>50.20796</td>\n","      <td>28.263879</td>\n","      <td>20.1267</td>\n","      <td>7134.676344</td>\n","      <td>8.048006</td>\n","      <td>0.645660</td>\n","      <td>99.752148</td>\n","      <td>6191.70668</td>\n","      <td>1.123200</td>\n","      <td>321.506455</td>\n","    </tr>\n","    <tr>\n","      <th>609</th>\n","      <td>1</td>\n","      <td>0.531069</td>\n","      <td>3.259413</td>\n","      <td>0.026069</td>\n","      <td>9.063372</td>\n","      <td>0.367478</td>\n","      <td>99.539070</td>\n","      <td>102.040455</td>\n","      <td>114.731682</td>\n","      <td>38.831972</td>\n","      <td>...</td>\n","      <td>119.35176</td>\n","      <td>35.755698</td>\n","      <td>17.3019</td>\n","      <td>7113.007548</td>\n","      <td>12.060606</td>\n","      <td>0.526938</td>\n","      <td>209.538009</td>\n","      <td>4668.19745</td>\n","      <td>0.238680</td>\n","      <td>515.435700</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>0</td>\n","      <td>0.005518</td>\n","      <td>0.296850</td>\n","      <td>0.076018</td>\n","      <td>7.745765</td>\n","      <td>0.482849</td>\n","      <td>156.345390</td>\n","      <td>6.090490</td>\n","      <td>181.218219</td>\n","      <td>21.086160</td>\n","      <td>...</td>\n","      <td>82.54008</td>\n","      <td>42.799438</td>\n","      <td>21.1860</td>\n","      <td>6850.484442</td>\n","      <td>10.479286</td>\n","      <td>0.644837</td>\n","      <td>306.127863</td>\n","      <td>2818.01707</td>\n","      <td>0.238680</td>\n","      <td>889.496905</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 56 columns</p>\n","</div>"],"text/plain":["     EJ        DU         FD        CH         FI        AB          DI   \n","1     0  0.005518   0.296850  0.031442  10.358927  0.145282  110.581815  \\\n","11    1  1.338018  17.698197  0.039800  13.942377  0.760594   89.286975   \n","13    0  0.005518   0.296850  0.047362   8.972407  0.534125  140.831707   \n","14    0  0.005518   0.296850  0.041790   3.583450  0.508487  194.021745   \n","16    0  0.005518   0.296850  0.023880   9.107476  0.252107  166.996575   \n","..   ..       ...        ...       ...        ...       ...         ...   \n","581   1  1.324224   2.600406  0.076814   8.365977  1.096024  174.150075   \n","597   0  0.005518   0.296850  0.032238  11.516657  0.478576  164.585093   \n","608   1  8.876439  14.872185  0.028656  10.199050  0.636677  523.664437   \n","609   1  0.531069   3.259413  0.026069   9.063372  0.367478   99.539070   \n","616   0  0.005518   0.296850  0.076018   7.745765  0.482849  156.345390   \n","\n","             BQ          EP         DN  ...         DL         CS       BN   \n","1     14.754720   95.415086  37.532000  ...   75.74548  28.310953  19.4205  \\\n","11    28.949365   78.526968  25.910728  ...   87.87188  44.522016  26.4825   \n","13   344.644105  137.514884  31.489348  ...  108.55778  33.267724  24.7170   \n","14    73.244785  310.673707  29.247664  ...   84.74276  70.358942  26.4825   \n","16   109.751255   94.701373  27.760032  ...  114.42912  38.116397  18.7143   \n","..          ...         ...        ...  ...        ...        ...      ...   \n","581  206.484023  152.484319  36.542520  ...   89.43432  35.724315  21.8922   \n","597   69.024685  124.065565  35.498448  ...  110.64068  34.353924  25.7763   \n","608   49.857095   78.526968  17.346608  ...   50.20796  28.263879  20.1267   \n","609  102.040455  114.731682  38.831972  ...  119.35176  35.755698  17.3019   \n","616    6.090490  181.218219  21.086160  ...   82.54008  42.799438  21.1860   \n","\n","               GF         CF        CC          BP           BD        DF   \n","1    27981.562750   6.085041  0.484710  155.868030   5496.92824  0.238680  \\\n","11    8192.631033   4.067337  0.659828  392.658570  12083.34891  0.238680   \n","13     895.517451   9.130603  0.443620  374.074794   5535.14441  0.238680   \n","14   11777.141530  16.349936  0.503945  336.873330  10563.27538  1.425060   \n","16   37275.608540   1.325876  0.551287  215.366634   5944.79970  0.953316   \n","..            ...        ...       ...         ...          ...       ...   \n","581   2184.856740  13.489876  0.486283  161.681818   5281.91734  0.238680   \n","597  18878.557980  23.395934  0.862360  199.631466   4452.78705  0.238680   \n","608   7134.676344   8.048006  0.645660   99.752148   6191.70668  1.123200   \n","609   7113.007548  12.060606  0.526938  209.538009   4668.19745  0.238680   \n","616   6850.484442  10.479286  0.644837  306.127863   2818.01707  0.238680   \n","\n","             DE  \n","1    178.553100  \n","11   204.187400  \n","13   211.886560  \n","14   203.934605  \n","16   464.242495  \n","..          ...  \n","581  804.211855  \n","597  620.984265  \n","608  321.506455  \n","609  515.435700  \n","616  889.496905  \n","\n","[154 rows x 56 columns]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>581</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>597</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>609</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 1 columns</p>\n","</div>"],"text/plain":["     Class\n","1        0\n","11       0\n","13       1\n","14       0\n","16       0\n","..     ...\n","581      0\n","597      0\n","608      1\n","609      0\n","616      0\n","\n","[154 rows x 1 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(x_t[0])\n","display(y_t[0])"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.222832Z","iopub.status.busy":"2023-05-05T21:25:02.222440Z","iopub.status.idle":"2023-05-05T21:25:02.229386Z","shell.execute_reply":"2023-05-05T21:25:02.227930Z","shell.execute_reply.started":"2023-05-05T21:25:02.222796Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["phase 0 sample size = 154\n"]}],"source":["#sample sizes per target\n","# for u in targetVars:\n","print('phase 0 sample size =', len(y_t[0]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Classification & Regression\n","[Reference: Géron, Aurélien. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow. O'Reilly Media. 2019](https://universidadefe957-my.sharepoint.com/:b:/g/personal/paulo_firmino_ufca_edu_br/Ec_UL4nCLQRGnFpftnOkv5ABrePEllnHLR7rrqPreAvn6A?e=RFGcMB)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.232317Z","iopub.status.busy":"2023-05-05T21:25:02.231165Z","iopub.status.idle":"2023-05-05T21:25:02.246052Z","shell.execute_reply":"2023-05-05T21:25:02.244672Z","shell.execute_reply.started":"2023-05-05T21:25:02.232260Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['EJ', 'DU', 'FD', 'CH', 'FI', 'AB', 'DI', 'BQ', 'EP', 'DN', 'DY', 'CW',\n","       'FL', 'AX', 'EE', 'AZ', 'CD', 'GB', 'EB', 'DA', 'BC', 'AR', 'DH', 'GH',\n","       'CU', 'GL', 'GE', 'FR', 'CB', 'FC', 'FE', 'CL', 'EH', 'FS', 'CR', 'AH',\n","       'DV', 'GI', 'EG', 'EL', 'BZ', 'AM', 'BR', 'AY', 'AF', 'EU', 'DL', 'CS',\n","       'BN', 'GF', 'CF', 'CC', 'BP', 'BD', 'DF', 'DE', 'Class'],\n","      dtype='object')"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["t_[0].columns"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.247919Z","iopub.status.busy":"2023-05-05T21:25:02.247376Z","iopub.status.idle":"2023-05-05T21:25:02.266117Z","shell.execute_reply":"2023-05-05T21:25:02.264666Z","shell.execute_reply.started":"2023-05-05T21:25:02.247880Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["**************  train 0 **************\n","observed min= EJ          0.000000\n","DU          0.005518\n","FD          0.296850\n","CH          0.012338\n","FI          3.583450\n","AB          0.081187\n","DI         60.232470\n","BQ          1.331155\n","EP         78.526968\n","DN          6.339496\n","DY          0.804068\n","CW          7.030640\n","FL          0.173229\n","AX          0.699861\n","EE          0.286201\n","AZ          3.396778\n","CD         23.387600\n","GB          6.762554\n","EB          4.926396\n","DA          8.662100\n","BC          1.229900\n","AR          8.138688\n","DH          0.106587\n","GH          9.432735\n","CU          0.148959\n","GL          0.001129\n","GE         72.611063\n","FR          0.497060\n","CB         12.499760\n","FC          7.534128\n","FE       1914.394780\n","CL          1.050225\n","EH          0.003042\n","FS          0.067730\n","CR          0.069225\n","AH         85.200147\n","DV          1.743070\n","GI          3.914584\n","EG        185.594100\n","EL          6.912477\n","BZ        257.432377\n","AM          4.270763\n","BR         51.216883\n","AY          0.025578\n","AF        192.593280\n","EU          3.828384\n","DL         28.988880\n","CS         13.784111\n","BN         12.358500\n","GF         13.038894\n","CF          0.510888\n","CC          0.256434\n","BP         85.169988\n","BD       2185.257010\n","DF          0.238680\n","DE         38.189785\n","Class       0.000000\n","dtype: float64\n","observed max= EJ            1.000000\n","DU           17.801157\n","FD           23.195859\n","CH            0.076814\n","FI           21.517239\n","AB            2.029675\n","DI         1049.168078\n","BQ          344.644105\n","EP          310.673707\n","DN           49.938032\n","DY          103.554076\n","CW           64.521624\n","FL           97.303580\n","AX           13.447962\n","EE            9.888043\n","AZ           38.971568\n","CD          385.388008\n","GB           55.691074\n","EB           24.299784\n","DA          112.205720\n","BC          643.553960\n","AR           35.121690\n","DH            1.060404\n","GH           80.537324\n","CU            3.266064\n","GL           21.978000\n","GE         1497.351958\n","FR           45.622220\n","CB         1835.203734\n","FC         1374.929808\n","FE        73288.815860\n","CL           14.283060\n","EH            3.200184\n","FS            2.614378\n","CR            3.039675\n","AH          546.663930\n","DV           10.914260\n","GI          164.309648\n","EG        16845.249300\n","EL          109.125159\n","BZ         3002.687900\n","AM          630.518230\n","BR        57279.396470\n","AY            0.236901\n","AF        14503.256020\n","EU         6501.264480\n","DL          239.201720\n","CS           80.954192\n","BN           28.954200\n","GF       124340.327900\n","CF           40.016519\n","CC            3.241684\n","BP         1464.947532\n","BD        27276.361880\n","DF            6.576336\n","DE         1789.420495\n","Class         1.000000\n","dtype: float64\n","theoretical min= 0\n","theoretical max= 1\n","**************  train 1 **************\n","observed min= EJ          0.000000\n","DU          0.005518\n","FD          0.296850\n","CH          0.003184\n","FI          3.583450\n","AB          0.081187\n","DI         60.232470\n","BQ          1.331155\n","EP         78.526968\n","DN          6.339496\n","DY          0.804068\n","CW          7.030640\n","FL          0.173229\n","AX          0.699861\n","EE          0.286201\n","AZ          3.396778\n","CD         23.387600\n","GB          5.171912\n","EB          4.926396\n","DA          7.193520\n","BC          1.229900\n","AR          8.138688\n","DH          0.043728\n","GH          9.432735\n","CU          0.137925\n","GL          0.001129\n","GE         72.611063\n","FR          0.497060\n","CB         12.499760\n","FC          7.534128\n","FE       1820.703747\n","CL          1.050225\n","EH          0.003042\n","FS          0.067730\n","CR          0.069225\n","AH         85.200147\n","DV          1.743070\n","GI          2.091036\n","EG        185.594100\n","EL          5.394675\n","BZ        257.432377\n","AM          4.270763\n","BR         51.216883\n","AY          0.025578\n","AF        192.593280\n","EU          3.828384\n","DL         10.345600\n","CS         13.784111\n","BN          9.886800\n","GF         13.038894\n","CF          0.510888\n","CC          0.256434\n","BP         72.948951\n","BD       2103.143780\n","DF          0.238680\n","DE         35.998895\n","Class       0.000000\n","dtype: float64\n","observed max= EJ            1.000000\n","DU          136.132986\n","FD          160.518669\n","CH            0.224074\n","FI           21.517239\n","AB            6.161666\n","DI         1049.168078\n","BQ          344.644105\n","EP         1034.170137\n","DN           62.808096\n","DY          152.355164\n","CW           64.521624\n","FL           97.303580\n","AX           17.983770\n","EE           18.324926\n","AZ           38.971568\n","CD          633.534408\n","GB          135.781294\n","EB           94.958580\n","DA          190.131640\n","BC         1463.693448\n","AR          173.534448\n","DH            1.060404\n","GH           80.537324\n","CU            3.266064\n","GL           21.978000\n","GE         1497.351958\n","FR           54.948620\n","CB         1835.203734\n","FC         1374.929808\n","FE        73794.300530\n","CL           31.688153\n","EH            7.197372\n","FS            2.614378\n","CR            3.039675\n","AH         1910.123198\n","DV           24.949470\n","GI          191.194764\n","EG        30243.758780\n","EL          109.125159\n","BZ        50092.459300\n","AM          630.518230\n","BR        57279.396470\n","AY            0.595602\n","AF        18964.472780\n","EU         6501.264480\n","DL          326.236200\n","CS          258.874880\n","BN           28.954200\n","GF       143790.071200\n","CF          200.967526\n","CC            4.103032\n","BP         1464.947532\n","BD        53060.599240\n","DF           10.108098\n","DE         2103.405190\n","Class         1.000000\n","dtype: float64\n","theoretical min= 0\n","theoretical max= 1\n","**************  train 2 **************\n","observed min= EJ          0.000000\n","DU          0.005518\n","FD          0.296850\n","CH          0.003184\n","FI          3.583450\n","AB          0.081187\n","DI         60.232470\n","BQ          1.331155\n","EP         78.526968\n","DN          6.339496\n","DY          0.804068\n","CW          7.030640\n","FL          0.173229\n","AX          0.699861\n","EE          0.286201\n","AZ          3.396778\n","CD         23.387600\n","GB          4.102182\n","EB          4.926396\n","DA          6.906400\n","BC          1.229900\n","AR          8.138688\n","DH          0.043728\n","GH          9.432735\n","CU          0.137925\n","GL          0.001129\n","GE         72.611063\n","FR          0.497060\n","CB         12.499760\n","FC          7.534128\n","FE       1820.703747\n","CL          1.050225\n","EH          0.003042\n","FS          0.067730\n","CR          0.069225\n","AH         85.200147\n","DV          1.743070\n","GI          0.897628\n","EG        185.594100\n","EL          5.394675\n","BZ        257.432377\n","AM          3.177522\n","BR         51.216883\n","AY          0.025578\n","AF        192.593280\n","EU          3.828384\n","DL         10.345600\n","CS         13.784111\n","BN          9.886800\n","GF         13.038894\n","CF          0.510888\n","CC          0.176874\n","BP         72.948951\n","BD       1693.624320\n","DF          0.238680\n","DE         35.998895\n","Class       0.000000\n","dtype: float64\n","observed max= EJ            1.000000\n","DU          136.132986\n","FD          252.928074\n","CH            0.224074\n","FI           35.851039\n","AB            6.161666\n","DI         1049.168078\n","BQ          344.644105\n","EP         1034.170137\n","DN           62.808096\n","DY          152.355164\n","CW           64.521624\n","FL          110.342316\n","AX           38.270880\n","EE           18.324926\n","AZ           38.971568\n","CD          633.534408\n","GB          135.781294\n","EB           94.958580\n","DA          190.131640\n","BC         1463.693448\n","AR          173.534448\n","DH            1.060404\n","GH           81.210825\n","CU            4.951507\n","GL           21.978000\n","GE         1497.351958\n","FR         1244.227020\n","CB         2271.436167\n","FC         3030.655824\n","FE       143224.682300\n","CL           31.688153\n","EH           10.239372\n","FS            2.614378\n","CR            3.039675\n","AH         1910.123198\n","DV           24.949470\n","GI          191.194764\n","EG        30243.758780\n","EL          109.125159\n","BZ        50092.459300\n","AM          630.518230\n","BR        57279.396470\n","AY           10.315851\n","AF        28688.187660\n","EU         6501.264480\n","DL          326.236200\n","CS          258.874880\n","BN           29.307300\n","GF       143790.071200\n","CF          200.967526\n","CC            4.103032\n","BP         2447.810550\n","BD        53060.599240\n","DF           37.895013\n","DE         2103.405190\n","Class         1.000000\n","dtype: float64\n","theoretical min= 0\n","theoretical max= 1\n","**************  train 3 **************\n","observed min= EJ          0.000000\n","DU          0.005518\n","FD          0.296850\n","CH          0.012736\n","FI          3.583450\n","AB          0.119644\n","DI         60.232470\n","BQ          2.370550\n","EP         78.526968\n","DN          6.667048\n","DY          0.804068\n","CW          7.030640\n","FL          0.173229\n","AX          0.699861\n","EE          0.286201\n","AZ          3.396778\n","CD         23.387600\n","GB          4.874248\n","EB          4.926396\n","DA         10.683580\n","BC          1.229900\n","AR          8.138688\n","DH          0.040995\n","GH          9.432735\n","CU          0.297918\n","GL          0.001317\n","GE         72.611063\n","FR          0.497060\n","CB         12.499760\n","FC         14.131488\n","FE       1563.136688\n","CL          1.050225\n","EH          0.003042\n","FS          0.067730\n","CR          0.069225\n","AH         85.200147\n","DV          1.743070\n","GI          3.150700\n","EG        218.370100\n","EL          7.522944\n","BZ        257.432377\n","AM          5.562212\n","BR         51.216883\n","AY          0.025578\n","AF        192.593280\n","EU          3.828384\n","DL         24.072600\n","CS         13.784111\n","BN         10.239900\n","GF         13.038894\n","CF          0.510888\n","CC          0.245485\n","BP         92.935836\n","BD       2141.759450\n","DF          0.238680\n","DE         45.600670\n","Class       0.000000\n","dtype: float64\n","observed max= EJ            1.000000\n","DU          161.355315\n","FD         1578.654237\n","CH            0.179100\n","FI           17.762886\n","AB            2.004037\n","DI          416.100270\n","BQ          344.644105\n","EP         1063.594578\n","DN           61.047504\n","DY           97.665064\n","CW           56.325344\n","FL          137.932739\n","AX           12.127971\n","EE           15.499195\n","AZ           22.416214\n","CD          291.449136\n","GB           62.667574\n","EB           90.791994\n","DA          210.330920\n","BC          119.908222\n","AR          178.943634\n","DH            0.882759\n","GH           61.761158\n","CU            3.503295\n","GL           21.978000\n","GE          980.017458\n","FR           36.957890\n","CB          768.900678\n","FC          637.259280\n","FE        91696.755110\n","CL           24.842595\n","EH           42.569748\n","FS           31.365763\n","CR            3.039675\n","AH         1817.620554\n","DV           25.192930\n","GI          184.723612\n","EG        15691.552180\n","EL          109.125159\n","BZ         3968.310000\n","AM          414.084385\n","BR       179250.252900\n","AY            0.601997\n","AF        18720.829600\n","EU         1177.805376\n","DL          205.544600\n","CS          267.942823\n","BN           28.248000\n","GF       119212.643900\n","CF           41.460994\n","CC            2.084044\n","BP         1858.538682\n","BD         9306.496320\n","DF           16.155828\n","DE         1965.033190\n","Class         1.000000\n","dtype: float64\n","theoretical min= 0\n","theoretical max= 1\n"]}],"source":["#Verifying the observed min and max per phase data\n","# for u in targetVars:\n","for i in range(nDataSubsets):\n","    print('**************  train', i, '**************')\n","    print('observed min=', t_[i].min())    \n","    print('observed max=', t_[i].max())\n","    print('theoretical min=', 0)    \n","    print('theoretical max=', 1)\n","    # print('logp1 theoretical max=', ltheoreticalMax)\n","    # print('**************  validation **************')\n","    # print('observed min=', v_.min())    \n","    # print('observed max=', v_.max())\n"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.269475Z","iopub.status.busy":"2023-05-05T21:25:02.268190Z","iopub.status.idle":"2023-05-05T21:25:02.294829Z","shell.execute_reply":"2023-05-05T21:25:02.293228Z","shell.execute_reply.started":"2023-05-05T21:25:02.269416Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EJ</th>\n","      <th>DU</th>\n","      <th>FD</th>\n","      <th>CH</th>\n","      <th>FI</th>\n","      <th>AB</th>\n","      <th>DI</th>\n","      <th>BQ</th>\n","      <th>EP</th>\n","      <th>DN</th>\n","      <th>...</th>\n","      <th>CS</th>\n","      <th>BN</th>\n","      <th>GF</th>\n","      <th>CF</th>\n","      <th>CC</th>\n","      <th>BP</th>\n","      <th>BD</th>\n","      <th>DF</th>\n","      <th>DE</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2.655345</td>\n","      <td>7.884336</td>\n","      <td>0.029054</td>\n","      <td>14.852022</td>\n","      <td>0.252107</td>\n","      <td>139.824570</td>\n","      <td>11.050410</td>\n","      <td>78.526968</td>\n","      <td>24.354856</td>\n","      <td>...</td>\n","      <td>41.116960</td>\n","      <td>23.6577</td>\n","      <td>2094.262452</td>\n","      <td>2.347652</td>\n","      <td>0.717882</td>\n","      <td>237.282264</td>\n","      <td>4169.67738</td>\n","      <td>0.238680</td>\n","      <td>196.607985</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0.005518</td>\n","      <td>0.296850</td>\n","      <td>0.016716</td>\n","      <td>10.981896</td>\n","      <td>0.209377</td>\n","      <td>135.317865</td>\n","      <td>16.526120</td>\n","      <td>78.526968</td>\n","      <td>31.731600</td>\n","      <td>...</td>\n","      <td>32.456996</td>\n","      <td>10.2399</td>\n","      <td>24177.595550</td>\n","      <td>14.688030</td>\n","      <td>0.639460</td>\n","      <td>148.487931</td>\n","      <td>5237.54088</td>\n","      <td>0.238680</td>\n","      <td>135.489250</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>0.613833</td>\n","      <td>1.389258</td>\n","      <td>0.033830</td>\n","      <td>11.450501</td>\n","      <td>0.346113</td>\n","      <td>131.349555</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>29.466032</td>\n","      <td>...</td>\n","      <td>29.914973</td>\n","      <td>20.4798</td>\n","      <td>4589.611956</td>\n","      <td>14.566390</td>\n","      <td>0.855496</td>\n","      <td>135.881145</td>\n","      <td>6569.37001</td>\n","      <td>0.238680</td>\n","      <td>231.134460</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1</td>\n","      <td>0.386232</td>\n","      <td>3.217854</td>\n","      <td>0.041392</td>\n","      <td>12.950037</td>\n","      <td>0.491395</td>\n","      <td>94.173945</td>\n","      <td>101.589790</td>\n","      <td>88.268687</td>\n","      <td>20.431056</td>\n","      <td>...</td>\n","      <td>47.227928</td>\n","      <td>23.6577</td>\n","      <td>25583.307300</td>\n","      <td>5.726203</td>\n","      <td>0.329736</td>\n","      <td>338.094162</td>\n","      <td>5688.40060</td>\n","      <td>0.238680</td>\n","      <td>353.447325</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1</td>\n","      <td>0.648318</td>\n","      <td>4.262766</td>\n","      <td>0.038606</td>\n","      <td>9.669802</td>\n","      <td>0.448665</td>\n","      <td>62.030257</td>\n","      <td>344.644105</td>\n","      <td>125.687640</td>\n","      <td>30.632936</td>\n","      <td>...</td>\n","      <td>34.761903</td>\n","      <td>22.9515</td>\n","      <td>49250.995060</td>\n","      <td>9.601957</td>\n","      <td>0.830530</td>\n","      <td>185.011155</td>\n","      <td>4892.32494</td>\n","      <td>0.238680</td>\n","      <td>232.402870</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>599</th>\n","      <td>1</td>\n","      <td>0.075867</td>\n","      <td>0.949920</td>\n","      <td>0.038606</td>\n","      <td>16.682338</td>\n","      <td>1.106707</td>\n","      <td>86.830313</td>\n","      <td>18.935745</td>\n","      <td>78.526968</td>\n","      <td>38.391824</td>\n","      <td>...</td>\n","      <td>29.397154</td>\n","      <td>24.0108</td>\n","      <td>13738.933020</td>\n","      <td>15.433075</td>\n","      <td>0.871047</td>\n","      <td>189.665577</td>\n","      <td>6704.19327</td>\n","      <td>0.238680</td>\n","      <td>974.892830</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>602</th>\n","      <td>1</td>\n","      <td>0.931095</td>\n","      <td>4.001538</td>\n","      <td>0.018706</td>\n","      <td>9.162606</td>\n","      <td>0.350386</td>\n","      <td>127.985528</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>12.883712</td>\n","      <td>...</td>\n","      <td>26.370438</td>\n","      <td>17.6550</td>\n","      <td>9146.473587</td>\n","      <td>8.092101</td>\n","      <td>0.651957</td>\n","      <td>146.917382</td>\n","      <td>6276.34475</td>\n","      <td>0.238680</td>\n","      <td>150.224537</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>610</th>\n","      <td>0</td>\n","      <td>0.005518</td>\n","      <td>0.296850</td>\n","      <td>0.050546</td>\n","      <td>3.583450</td>\n","      <td>0.581128</td>\n","      <td>219.902355</td>\n","      <td>99.000420</td>\n","      <td>78.526968</td>\n","      <td>26.381584</td>\n","      <td>...</td>\n","      <td>39.389152</td>\n","      <td>27.8949</td>\n","      <td>38475.318010</td>\n","      <td>34.323767</td>\n","      <td>0.488119</td>\n","      <td>246.205359</td>\n","      <td>5719.34587</td>\n","      <td>1.061424</td>\n","      <td>502.246010</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>1</td>\n","      <td>0.648318</td>\n","      <td>6.067614</td>\n","      <td>0.038208</td>\n","      <td>10.910227</td>\n","      <td>0.435846</td>\n","      <td>192.598575</td>\n","      <td>344.644105</td>\n","      <td>114.801199</td>\n","      <td>26.750080</td>\n","      <td>...</td>\n","      <td>39.852923</td>\n","      <td>27.1887</td>\n","      <td>3085.308063</td>\n","      <td>6.682597</td>\n","      <td>0.772304</td>\n","      <td>285.628059</td>\n","      <td>5654.07556</td>\n","      <td>0.238680</td>\n","      <td>157.393715</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>1</td>\n","      <td>0.510378</td>\n","      <td>6.192291</td>\n","      <td>0.022288</td>\n","      <td>8.026928</td>\n","      <td>0.363205</td>\n","      <td>113.526045</td>\n","      <td>NaN</td>\n","      <td>99.706633</td>\n","      <td>27.104928</td>\n","      <td>...</td>\n","      <td>34.367872</td>\n","      <td>19.0674</td>\n","      <td>1965.343176</td>\n","      <td>2.964975</td>\n","      <td>0.602254</td>\n","      <td>119.162529</td>\n","      <td>4517.86560</td>\n","      <td>0.532818</td>\n","      <td>112.196630</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 57 columns</p>\n","</div>"],"text/plain":["     EJ        DU        FD        CH         FI        AB          DI   \n","3     1  2.655345  7.884336  0.029054  14.852022  0.252107  139.824570  \\\n","5     0  0.005518  0.296850  0.016716  10.981896  0.209377  135.317865   \n","8     1  0.613833  1.389258  0.033830  11.450501  0.346113  131.349555   \n","12    1  0.386232  3.217854  0.041392  12.950037  0.491395   94.173945   \n","17    1  0.648318  4.262766  0.038606   9.669802  0.448665   62.030257   \n","..   ..       ...       ...       ...        ...       ...         ...   \n","599   1  0.075867  0.949920  0.038606  16.682338  1.106707   86.830313   \n","602   1  0.931095  4.001538  0.018706   9.162606  0.350386  127.985528   \n","610   0  0.005518  0.296850  0.050546   3.583450  0.581128  219.902355   \n","613   1  0.648318  6.067614  0.038208  10.910227  0.435846  192.598575   \n","615   1  0.510378  6.192291  0.022288   8.026928  0.363205  113.526045   \n","\n","             BQ          EP         DN  ...         CS       BN            GF   \n","3     11.050410   78.526968  24.354856  ...  41.116960  23.6577   2094.262452  \\\n","5     16.526120   78.526968  31.731600  ...  32.456996  10.2399  24177.595550   \n","8           NaN   78.526968  29.466032  ...  29.914973  20.4798   4589.611956   \n","12   101.589790   88.268687  20.431056  ...  47.227928  23.6577  25583.307300   \n","17   344.644105  125.687640  30.632936  ...  34.761903  22.9515  49250.995060   \n","..          ...         ...        ...  ...        ...      ...           ...   \n","599   18.935745   78.526968  38.391824  ...  29.397154  24.0108  13738.933020   \n","602         NaN   78.526968  12.883712  ...  26.370438  17.6550   9146.473587   \n","610   99.000420   78.526968  26.381584  ...  39.389152  27.8949  38475.318010   \n","613  344.644105  114.801199  26.750080  ...  39.852923  27.1887   3085.308063   \n","615         NaN   99.706633  27.104928  ...  34.367872  19.0674   1965.343176   \n","\n","            CF        CC          BP          BD        DF          DE  Class  \n","3     2.347652  0.717882  237.282264  4169.67738  0.238680  196.607985      0  \n","5    14.688030  0.639460  148.487931  5237.54088  0.238680  135.489250      0  \n","8    14.566390  0.855496  135.881145  6569.37001  0.238680  231.134460      0  \n","12    5.726203  0.329736  338.094162  5688.40060  0.238680  353.447325      0  \n","17    9.601957  0.830530  185.011155  4892.32494  0.238680  232.402870      0  \n","..         ...       ...         ...         ...       ...         ...    ...  \n","599  15.433075  0.871047  189.665577  6704.19327  0.238680  974.892830      0  \n","602   8.092101  0.651957  146.917382  6276.34475  0.238680  150.224537      0  \n","610  34.323767  0.488119  246.205359  5719.34587  1.061424  502.246010      0  \n","613   6.682597  0.772304  285.628059  5654.07556  0.238680  157.393715      0  \n","615   2.964975  0.602254  119.162529  4517.86560  0.532818  112.196630      0  \n","\n","[154 rows x 57 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(t_[3])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Pipelines for aggregating inputation, standasdization, one-hot enconding, and PCA"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.297567Z","iopub.status.busy":"2023-05-05T21:25:02.296449Z","iopub.status.idle":"2023-05-05T21:25:02.302203Z","shell.execute_reply":"2023-05-05T21:25:02.301101Z","shell.execute_reply.started":"2023-05-05T21:25:02.297526Z"},"trusted":true},"outputs":[],"source":["#!pip install --upgrade scikit-learn"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.304954Z","iopub.status.busy":"2023-05-05T21:25:02.304316Z","iopub.status.idle":"2023-05-05T21:25:02.349053Z","shell.execute_reply":"2023-05-05T21:25:02.347590Z","shell.execute_reply.started":"2023-05-05T21:25:02.304903Z"},"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;qt&#x27;,\n","                                 Pipeline(steps=[(&#x27;Imputer&#x27;, SimpleImputer()),\n","                                                 (&#x27;Log1p&#x27;,\n","                                                  FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n","                                                                      validate=True)),\n","                                                 (&#x27;Std_scaler_1&#x27;,\n","                                                  StandardScaler())]),\n","                                 [&#x27;EJ&#x27;, &#x27;DU&#x27;, &#x27;FD&#x27;, &#x27;CH&#x27;, &#x27;FI&#x27;, &#x27;AB&#x27;, &#x27;DI&#x27;,\n","                                  &#x27;BQ&#x27;, &#x27;EP&#x27;, &#x27;DN&#x27;, &#x27;DY&#x27;, &#x27;CW&#x27;, &#x27;FL&#x27;, &#x27;AX&#x27;,\n","                                  &#x27;EE&#x27;, &#x27;AZ&#x27;, &#x27;CD&#x27;, &#x27;GB&#x27;, &#x27;EB&#x27;, &#x27;DA&#x27;, &#x27;BC&#x27;,\n","                                  &#x27;AR&#x27;, &#x27;DH&#x27;, &#x27;GH&#x27;, &#x27;CU&#x27;, &#x27;GL&#x27;, &#x27;GE&#x27;, &#x27;FR&#x27;,\n","                                  &#x27;CB&#x27;, &#x27;FC&#x27;, ...])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;qt&#x27;,\n","                                 Pipeline(steps=[(&#x27;Imputer&#x27;, SimpleImputer()),\n","                                                 (&#x27;Log1p&#x27;,\n","                                                  FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n","                                                                      validate=True)),\n","                                                 (&#x27;Std_scaler_1&#x27;,\n","                                                  StandardScaler())]),\n","                                 [&#x27;EJ&#x27;, &#x27;DU&#x27;, &#x27;FD&#x27;, &#x27;CH&#x27;, &#x27;FI&#x27;, &#x27;AB&#x27;, &#x27;DI&#x27;,\n","                                  &#x27;BQ&#x27;, &#x27;EP&#x27;, &#x27;DN&#x27;, &#x27;DY&#x27;, &#x27;CW&#x27;, &#x27;FL&#x27;, &#x27;AX&#x27;,\n","                                  &#x27;EE&#x27;, &#x27;AZ&#x27;, &#x27;CD&#x27;, &#x27;GB&#x27;, &#x27;EB&#x27;, &#x27;DA&#x27;, &#x27;BC&#x27;,\n","                                  &#x27;AR&#x27;, &#x27;DH&#x27;, &#x27;GH&#x27;, &#x27;CU&#x27;, &#x27;GL&#x27;, &#x27;GE&#x27;, &#x27;FR&#x27;,\n","                                  &#x27;CB&#x27;, &#x27;FC&#x27;, ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">qt</label><div class=\"sk-toggleable__content\"><pre>[&#x27;EJ&#x27;, &#x27;DU&#x27;, &#x27;FD&#x27;, &#x27;CH&#x27;, &#x27;FI&#x27;, &#x27;AB&#x27;, &#x27;DI&#x27;, &#x27;BQ&#x27;, &#x27;EP&#x27;, &#x27;DN&#x27;, &#x27;DY&#x27;, &#x27;CW&#x27;, &#x27;FL&#x27;, &#x27;AX&#x27;, &#x27;EE&#x27;, &#x27;AZ&#x27;, &#x27;CD&#x27;, &#x27;GB&#x27;, &#x27;EB&#x27;, &#x27;DA&#x27;, &#x27;BC&#x27;, &#x27;AR&#x27;, &#x27;DH&#x27;, &#x27;GH&#x27;, &#x27;CU&#x27;, &#x27;GL&#x27;, &#x27;GE&#x27;, &#x27;FR&#x27;, &#x27;CB&#x27;, &#x27;FC&#x27;, &#x27;FE&#x27;, &#x27;CL&#x27;, &#x27;EH&#x27;, &#x27;FS&#x27;, &#x27;CR&#x27;, &#x27;AH&#x27;, &#x27;DV&#x27;, &#x27;GI&#x27;, &#x27;EG&#x27;, &#x27;EL&#x27;, &#x27;BZ&#x27;, &#x27;AM&#x27;, &#x27;BR&#x27;, &#x27;AY&#x27;, &#x27;AF&#x27;, &#x27;EU&#x27;, &#x27;DL&#x27;, &#x27;CS&#x27;, &#x27;BN&#x27;, &#x27;GF&#x27;, &#x27;CF&#x27;, &#x27;CC&#x27;, &#x27;BP&#x27;, &#x27;BD&#x27;, &#x27;DF&#x27;, &#x27;DE&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;, validate=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["ColumnTransformer(transformers=[('qt',\n","                                 Pipeline(steps=[('Imputer', SimpleImputer()),\n","                                                 ('Log1p',\n","                                                  FunctionTransformer(func=<ufunc 'log1p'>,\n","                                                                      validate=True)),\n","                                                 ('Std_scaler_1',\n","                                                  StandardScaler())]),\n","                                 ['EJ', 'DU', 'FD', 'CH', 'FI', 'AB', 'DI',\n","                                  'BQ', 'EP', 'DN', 'DY', 'CW', 'FL', 'AX',\n","                                  'EE', 'AZ', 'CD', 'GB', 'EB', 'DA', 'BC',\n","                                  'AR', 'DH', 'GH', 'CU', 'GL', 'GE', 'FR',\n","                                  'CB', 'FC', ...])])"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler  # , MinMaxScaler\n","# from sklearn.preprocessing import OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.decomposition import PCA\n","\n","from scipy.stats import norm\n","from sklearn.compose import ColumnTransformer\n","class OutlierComputation (BaseEstimator, TransformerMixin): #inspired on Geron \n","    def __init__(self, z = None, outProb = None):\n","        self.z = z\n","        self.outProb = outProb\n","        if outProb is None:\n","            if z is not None:\n","                self.qLower = -np.abs(z)\n","                self.qUpper = -self.qLower#dist.ppf(1-prLower)\n","            else:\n","                self.qLower = None\n","                self.qUpper = None\n","        else:\n","            dist = norm(loc = 0, scale = 1)#Omega_X = {x\\in R}\n","            prLower = outProb if outProb <= .5 else 1 - outProb \n","            prLower = prLower/2\n","            self.qLower = dist.ppf(prLower)\n","            self.qUpper = -self.qLower#dist.ppf(1-prLower)\n","\n","    def fit(self, X, y = None): \n","        return self \n","    def transform(self, X):  \n","        ret = None\n","        if self.qUpper is not None:\n","            isUpperOutlier =  (X > self.qUpper).astype(int)      \n","            isLowerOutlier =  (X < self.qLower).astype(int)\n","            ret = np.concatenate((X, isLowerOutlier, isUpperOutlier), axis=1)    \n","        else:\n","            ret = X  \n","        return ret\n","\n","pipelineList = [('Imputer', SimpleImputer(strategy=\"mean\", add_indicator=False)),\n","                ('Log1p', FunctionTransformer(func=np.log1p, validate=True)),\n","                ('Std_scaler_1', StandardScaler())]\n","if isWithPCA:\n","    pipelineList.append(('PCA', PCA(n_components=nPcaComponents)))\n","    pipelineList.append(('Std_scaler_2', StandardScaler()))\n","if outlierProbability is not None:\n","    pipelineList.append(('Outliers', OutlierComputation(outProb=outlierProbability)))\n","    pipelineList.append(('Std_scaler_3', StandardScaler()))\n","# for u in targetVars:\n","# if isWithPCA:\n","#     quantiPipeline = Pipeline([('Imputer', SimpleImputer(strategy=\"mean\", add_indicator=False)),\n","#                         ('Log1p', FunctionTransformer(func=np.log1p, validate=True)),\n","#                         ('Std_scaler_1', StandardScaler()),\n","#                         ('PCA', PCA(n_components=nPcaComponents)),\n","#                         ('Std_scaler_2', StandardScaler()),\n","#                         ('Outliers', OutlierComputation(outProb=outlierProbability)),\n","#                         ('Std_scaler_3', StandardScaler()),\n","#                         ])\n","# else:\n","#     quantiPipeline = Pipeline([('Imputer', SimpleImputer(strategy=\"constant\", fill_value=0, add_indicator=False)),\n","#                     ('Log1p', FunctionTransformer(func=np.log1p, validate=True)),\n","#                     ('Std_scaler_1', StandardScaler()),\n","#                     ('Outliers', OutlierComputation(outProb=outlierProbability)),\n","#                     ('Std_scaler_2', StandardScaler()),#undo the comment\n","#                     ])\n","quantiPipeline = Pipeline(pipelineList)\n","# print('********************** Transformer **********************')\n","fullPipeline = ColumnTransformer([(\"qt\", quantiPipeline, quantiVars)]) \n","fullPipeline                       \n"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.350795Z","iopub.status.busy":"2023-05-05T21:25:02.350453Z","iopub.status.idle":"2023-05-05T21:25:02.444226Z","shell.execute_reply":"2023-05-05T21:25:02.442798Z","shell.execute_reply.started":"2023-05-05T21:25:02.350763Z"},"trusted":true},"outputs":[],"source":["x_tTransf = {}\n","# for u in targetVars:\n","x_tTransf = {}\n","colNames = x_t[0].columns if not isWithPCA else ['C'+str(i) for i in range(nPcaComponents)]  \n","colNames = list(colNames)\n","colNames_outliers = '' if outlierProbability is None else [x+'_isLowerOutlier' for x in colNames] + [x+'_isUpperOutlier' for x in colNames] \n","colNames += colNames_outliers\n","x_tTransf[0] = pd.DataFrame(fullPipeline.fit_transform(x_t[0]), columns = colNames, index = x_t[0].index)\n","for i in range(1, nDataSubsets):\n","    # print('********************** partition', str(i), 'fit_transform **********************')\n","    x_tTransf[i] = pd.DataFrame(fullPipeline.transform(x_t[i]), columns = colNames, index = x_t[i].index)"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.446104Z","iopub.status.busy":"2023-05-05T21:25:02.445681Z","iopub.status.idle":"2023-05-05T21:25:02.469075Z","shell.execute_reply":"2023-05-05T21:25:02.467557Z","shell.execute_reply.started":"2023-05-05T21:25:02.446058Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EJ</th>\n","      <th>DU</th>\n","      <th>FD</th>\n","      <th>CH</th>\n","      <th>FI</th>\n","      <th>AB</th>\n","      <th>DI</th>\n","      <th>BQ</th>\n","      <th>EP</th>\n","      <th>DN</th>\n","      <th>...</th>\n","      <th>DL</th>\n","      <th>CS</th>\n","      <th>BN</th>\n","      <th>GF</th>\n","      <th>CF</th>\n","      <th>CC</th>\n","      <th>BP</th>\n","      <th>BD</th>\n","      <th>DF</th>\n","      <th>DE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>-1.442221</td>\n","      <td>-0.822980</td>\n","      <td>-1.091158</td>\n","      <td>0.026388</td>\n","      <td>0.251312</td>\n","      <td>-1.268844</td>\n","      <td>-0.433119</td>\n","      <td>-1.415791</td>\n","      <td>-0.031759</td>\n","      <td>1.151910</td>\n","      <td>...</td>\n","      <td>-0.626053</td>\n","      <td>-0.714224</td>\n","      <td>-0.734225</td>\n","      <td>1.036784</td>\n","      <td>-0.543932</td>\n","      <td>-0.852052</td>\n","      <td>-0.491684</td>\n","      <td>0.231833</td>\n","      <td>-0.490496</td>\n","      <td>-0.768063</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.693375</td>\n","      <td>0.409874</td>\n","      <td>2.062416</td>\n","      <td>0.818238</td>\n","      <td>1.277883</td>\n","      <td>1.073178</td>\n","      <td>-0.877634</td>\n","      <td>-0.816297</td>\n","      <td>-0.724220</td>\n","      <td>-0.049168</td>\n","      <td>...</td>\n","      <td>-0.153605</td>\n","      <td>0.795285</td>\n","      <td>1.201561</td>\n","      <td>0.138185</td>\n","      <td>-1.044788</td>\n","      <td>-0.059908</td>\n","      <td>1.595447</td>\n","      <td>2.589321</td>\n","      <td>-0.490496</td>\n","      <td>-0.580746</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>-1.442221</td>\n","      <td>-0.822980</td>\n","      <td>-1.091158</td>\n","      <td>1.529208</td>\n","      <td>-0.236077</td>\n","      <td>0.323236</td>\n","      <td>0.070420</td>\n","      <td>1.466354</td>\n","      <td>1.271110</td>\n","      <td>0.581167</td>\n","      <td>...</td>\n","      <td>0.520298</td>\n","      <td>-0.178488</td>\n","      <td>0.768812</td>\n","      <td>-1.480605</td>\n","      <td>-0.009595</td>\n","      <td>-1.051451</td>\n","      <td>1.485750</td>\n","      <td>0.252569</td>\n","      <td>-0.490496</td>\n","      <td>-0.529042</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>-1.442221</td>\n","      <td>-0.822980</td>\n","      <td>-1.091158</td>\n","      <td>1.005836</td>\n","      <td>-3.146481</td>\n","      <td>0.231445</td>\n","      <td>0.738919</td>\n","      <td>0.030967</td>\n","      <td>4.187356</td>\n","      <td>0.341954</td>\n","      <td>...</td>\n","      <td>-0.269040</td>\n","      <td>2.336655</td>\n","      <td>1.201561</td>\n","      <td>0.403683</td>\n","      <td>0.794398</td>\n","      <td>-0.760597</td>\n","      <td>1.248803</td>\n","      <td>2.186898</td>\n","      <td>1.452675</td>\n","      <td>-0.582476</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>-1.442221</td>\n","      <td>-0.822980</td>\n","      <td>-1.091158</td>\n","      <td>-0.695596</td>\n","      <td>-0.185709</td>\n","      <td>-0.783137</td>\n","      <td>0.425802</td>\n","      <td>0.404194</td>\n","      <td>-0.058477</td>\n","      <td>0.173209</td>\n","      <td>...</td>\n","      <td>0.688422</td>\n","      <td>0.275282</td>\n","      <td>-0.963611</td>\n","      <td>1.246603</td>\n","      <td>-2.208455</td>\n","      <td>-0.540400</td>\n","      <td>0.237772</td>\n","      <td>0.466264</td>\n","      <td>0.826960</td>\n","      <td>0.568307</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>581</th>\n","      <td>0.693375</td>\n","      <td>0.401228</td>\n","      <td>0.115570</td>\n","      <td>4.250162</td>\n","      <td>-0.470964</td>\n","      <td>2.023010</td>\n","      <td>0.513333</td>\n","      <td>0.990062</td>\n","      <td>1.640130</td>\n","      <td>1.064865</td>\n","      <td>...</td>\n","      <td>-0.097479</td>\n","      <td>0.058911</td>\n","      <td>0.010453</td>\n","      <td>-0.828547</td>\n","      <td>0.525211</td>\n","      <td>-0.844530</td>\n","      <td>-0.409133</td>\n","      <td>0.112414</td>\n","      <td>-0.490496</td>\n","      <td>1.338258</td>\n","    </tr>\n","    <tr>\n","      <th>597</th>\n","      <td>-1.442221</td>\n","      <td>-0.822980</td>\n","      <td>-1.091158</td>\n","      <td>0.102079</td>\n","      <td>0.614683</td>\n","      <td>0.122363</td>\n","      <td>0.395452</td>\n","      <td>-0.023646</td>\n","      <td>0.903820</td>\n","      <td>0.970494</td>\n","      <td>...</td>\n","      <td>0.580951</td>\n","      <td>-0.071488</td>\n","      <td>1.031893</td>\n","      <td>0.748889</td>\n","      <td>1.303709</td>\n","      <td>0.758072</td>\n","      <td>0.066496</td>\n","      <td>-0.398644</td>\n","      <td>-0.490496</td>\n","      <td>0.975856</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>0.693375</td>\n","      <td>2.515057</td>\n","      <td>1.868770</td>\n","      <td>-0.238988</td>\n","      <td>0.198242</td>\n","      <td>0.675670</td>\n","      <td>2.816287</td>\n","      <td>-0.322128</td>\n","      <td>-0.724220</td>\n","      <td>-1.330938</td>\n","      <td>...</td>\n","      <td>-1.929053</td>\n","      <td>-0.719735</td>\n","      <td>-0.512638</td>\n","      <td>0.037037</td>\n","      <td>-0.178480</td>\n","      <td>-0.120813</td>\n","      <td>-1.496010</td>\n","      <td>0.588061</td>\n","      <td>1.068178</td>\n","      <td>0.053970</td>\n","    </tr>\n","    <tr>\n","      <th>609</th>\n","      <td>0.693375</td>\n","      <td>-0.208652</td>\n","      <td>0.314210</td>\n","      <td>-0.486054</td>\n","      <td>-0.202081</td>\n","      <td>-0.303075</td>\n","      <td>-0.651869</td>\n","      <td>0.336846</td>\n","      <td>0.624905</td>\n","      <td>1.262931</td>\n","      <td>...</td>\n","      <td>0.822915</td>\n","      <td>0.061840</td>\n","      <td>-1.448123</td>\n","      <td>0.034812</td>\n","      <td>0.370025</td>\n","      <td>-0.652799</td>\n","      <td>0.175826</td>\n","      <td>-0.257255</td>\n","      <td>-0.490496</td>\n","      <td>0.714834</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>-1.442221</td>\n","      <td>-0.822980</td>\n","      <td>-1.091158</td>\n","      <td>4.177606</td>\n","      <td>-0.727475</td>\n","      <td>0.138080</td>\n","      <td>0.288310</td>\n","      <td>-2.160888</td>\n","      <td>2.257219</td>\n","      <td>-0.710241</td>\n","      <td>...</td>\n","      <td>-0.352854</td>\n","      <td>0.663016</td>\n","      <td>-0.193773</td>\n","      <td>0.007303</td>\n","      <td>0.177172</td>\n","      <td>-0.124367</td>\n","      <td>1.032379</td>\n","      <td>-1.767764</td>\n","      <td>-0.490496</td>\n","      <td>1.479566</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 56 columns</p>\n","</div>"],"text/plain":["           EJ        DU        FD        CH        FI        AB        DI   \n","1   -1.442221 -0.822980 -1.091158  0.026388  0.251312 -1.268844 -0.433119  \\\n","11   0.693375  0.409874  2.062416  0.818238  1.277883  1.073178 -0.877634   \n","13  -1.442221 -0.822980 -1.091158  1.529208 -0.236077  0.323236  0.070420   \n","14  -1.442221 -0.822980 -1.091158  1.005836 -3.146481  0.231445  0.738919   \n","16  -1.442221 -0.822980 -1.091158 -0.695596 -0.185709 -0.783137  0.425802   \n","..        ...       ...       ...       ...       ...       ...       ...   \n","581  0.693375  0.401228  0.115570  4.250162 -0.470964  2.023010  0.513333   \n","597 -1.442221 -0.822980 -1.091158  0.102079  0.614683  0.122363  0.395452   \n","608  0.693375  2.515057  1.868770 -0.238988  0.198242  0.675670  2.816287   \n","609  0.693375 -0.208652  0.314210 -0.486054 -0.202081 -0.303075 -0.651869   \n","616 -1.442221 -0.822980 -1.091158  4.177606 -0.727475  0.138080  0.288310   \n","\n","           BQ        EP        DN  ...        DL        CS        BN   \n","1   -1.415791 -0.031759  1.151910  ... -0.626053 -0.714224 -0.734225  \\\n","11  -0.816297 -0.724220 -0.049168  ... -0.153605  0.795285  1.201561   \n","13   1.466354  1.271110  0.581167  ...  0.520298 -0.178488  0.768812   \n","14   0.030967  4.187356  0.341954  ... -0.269040  2.336655  1.201561   \n","16   0.404194 -0.058477  0.173209  ...  0.688422  0.275282 -0.963611   \n","..        ...       ...       ...  ...       ...       ...       ...   \n","581  0.990062  1.640130  1.064865  ... -0.097479  0.058911  0.010453   \n","597 -0.023646  0.903820  0.970494  ...  0.580951 -0.071488  1.031893   \n","608 -0.322128 -0.724220 -1.330938  ... -1.929053 -0.719735 -0.512638   \n","609  0.336846  0.624905  1.262931  ...  0.822915  0.061840 -1.448123   \n","616 -2.160888  2.257219 -0.710241  ... -0.352854  0.663016 -0.193773   \n","\n","           GF        CF        CC        BP        BD        DF        DE  \n","1    1.036784 -0.543932 -0.852052 -0.491684  0.231833 -0.490496 -0.768063  \n","11   0.138185 -1.044788 -0.059908  1.595447  2.589321 -0.490496 -0.580746  \n","13  -1.480605 -0.009595 -1.051451  1.485750  0.252569 -0.490496 -0.529042  \n","14   0.403683  0.794398 -0.760597  1.248803  2.186898  1.452675 -0.582476  \n","16   1.246603 -2.208455 -0.540400  0.237772  0.466264  0.826960  0.568307  \n","..        ...       ...       ...       ...       ...       ...       ...  \n","581 -0.828547  0.525211 -0.844530 -0.409133  0.112414 -0.490496  1.338258  \n","597  0.748889  1.303709  0.758072  0.066496 -0.398644 -0.490496  0.975856  \n","608  0.037037 -0.178480 -0.120813 -1.496010  0.588061  1.068178  0.053970  \n","609  0.034812  0.370025 -0.652799  0.175826 -0.257255 -0.490496  0.714834  \n","616  0.007303  0.177172 -0.124367  1.032379 -1.767764 -0.490496  1.479566  \n","\n","[154 rows x 56 columns]"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["x_tTransf[0]#.describe()"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.471093Z","iopub.status.busy":"2023-05-05T21:25:02.470713Z","iopub.status.idle":"2023-05-05T21:25:02.695196Z","shell.execute_reply":"2023-05-05T21:25:02.693806Z","shell.execute_reply.started":"2023-05-05T21:25:02.471021Z"},"trusted":true},"outputs":[],"source":["#PCA\n","#from https://medium.com/@andymdc31/using-pca-in-a-machine-learning-pipeline-b6fe3492b1b9\n","def performPCAstudy():#just for nPcaComponents = None\n","    # for u in targetVars:\n","    if isWithPCA:\n","        print('************** PCA', '************')#, pd.DataFrame(X_pca, columns = ['C_'+str(i) for i in range(X_pca.shape[1])]))\n","        pca = fullPipeline.transformers_[0][1].steps[3][1]\n","        # X_pca = pca.fit_transform(x_tTransf)\n","        total_explained_variance = pca.explained_variance_ratio_.cumsum()\n","        # n_over_95 = len(total_explained_variance[total_explained_variance >= .95])\n","        # n_to_reach_95 = len(total_explained_variance) - n_over_95 + 1\n","        print('Number features: {}\\tTotal Variance Explained: {}'.format(nPcaComponents, total_explained_variance))\n","\n","        n_pcs= pca.components_.shape[0]\n","        initial_feature_names = x_t[0].columns\n","        most_important = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]\n","        most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n","        # zipped_feats = zip(most_important_names, pipe.steps[2][1].feature_importances_)\n","        # zipped_feats = sorted(zipped_feats, key=lambda x: x[1], reverse=True)\n","        # features, importances = zip(*zipped_feats)\n","        top_features = most_important_names[:np.min([n_pcs, 5])]\n","        top_importances = most_important[:np.min([n_pcs, 5])]\n","        plt.title('Feature Importance')\n","        plt.barh(range(len(top_importances)), top_importances, color='b', align='center')\n","        plt.yticks(range(len(top_importances)), top_features)\n","        plt.xlabel('Relative Importance')\n","        plt.show()    \n","performPCAstudy()"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/plain":["['Class']"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["targetVars"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.698056Z","iopub.status.busy":"2023-05-05T21:25:02.696949Z","iopub.status.idle":"2023-05-05T21:25:02.718224Z","shell.execute_reply":"2023-05-05T21:25:02.716736Z","shell.execute_reply.started":"2023-05-05T21:25:02.697972Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EJ</th>\n","      <th>DU</th>\n","      <th>FD</th>\n","      <th>CH</th>\n","      <th>FI</th>\n","      <th>AB</th>\n","      <th>DI</th>\n","      <th>BQ</th>\n","      <th>EP</th>\n","      <th>DN</th>\n","      <th>...</th>\n","      <th>DL</th>\n","      <th>CS</th>\n","      <th>BN</th>\n","      <th>GF</th>\n","      <th>CF</th>\n","      <th>CC</th>\n","      <th>BP</th>\n","      <th>BD</th>\n","      <th>DF</th>\n","      <th>DE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2.655345</td>\n","      <td>7.884336</td>\n","      <td>0.029054</td>\n","      <td>14.852022</td>\n","      <td>0.252107</td>\n","      <td>139.824570</td>\n","      <td>11.050410</td>\n","      <td>78.526968</td>\n","      <td>24.354856</td>\n","      <td>...</td>\n","      <td>71.57120</td>\n","      <td>41.116960</td>\n","      <td>23.6577</td>\n","      <td>2094.262452</td>\n","      <td>2.347652</td>\n","      <td>0.717882</td>\n","      <td>237.282264</td>\n","      <td>4169.67738</td>\n","      <td>0.238680</td>\n","      <td>196.607985</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0.005518</td>\n","      <td>0.296850</td>\n","      <td>0.016716</td>\n","      <td>10.981896</td>\n","      <td>0.209377</td>\n","      <td>135.317865</td>\n","      <td>16.526120</td>\n","      <td>78.526968</td>\n","      <td>31.731600</td>\n","      <td>...</td>\n","      <td>81.46312</td>\n","      <td>32.456996</td>\n","      <td>10.2399</td>\n","      <td>24177.595550</td>\n","      <td>14.688030</td>\n","      <td>0.639460</td>\n","      <td>148.487931</td>\n","      <td>5237.54088</td>\n","      <td>0.238680</td>\n","      <td>135.489250</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>0.613833</td>\n","      <td>1.389258</td>\n","      <td>0.033830</td>\n","      <td>11.450501</td>\n","      <td>0.346113</td>\n","      <td>131.349555</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>29.466032</td>\n","      <td>...</td>\n","      <td>98.16872</td>\n","      <td>29.914973</td>\n","      <td>20.4798</td>\n","      <td>4589.611956</td>\n","      <td>14.566390</td>\n","      <td>0.855496</td>\n","      <td>135.881145</td>\n","      <td>6569.37001</td>\n","      <td>0.238680</td>\n","      <td>231.134460</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1</td>\n","      <td>0.386232</td>\n","      <td>3.217854</td>\n","      <td>0.041392</td>\n","      <td>12.950037</td>\n","      <td>0.491395</td>\n","      <td>94.173945</td>\n","      <td>101.589790</td>\n","      <td>88.268687</td>\n","      <td>20.431056</td>\n","      <td>...</td>\n","      <td>76.69736</td>\n","      <td>47.227928</td>\n","      <td>23.6577</td>\n","      <td>25583.307300</td>\n","      <td>5.726203</td>\n","      <td>0.329736</td>\n","      <td>338.094162</td>\n","      <td>5688.40060</td>\n","      <td>0.238680</td>\n","      <td>353.447325</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1</td>\n","      <td>0.648318</td>\n","      <td>4.262766</td>\n","      <td>0.038606</td>\n","      <td>9.669802</td>\n","      <td>0.448665</td>\n","      <td>62.030257</td>\n","      <td>344.644105</td>\n","      <td>125.687640</td>\n","      <td>30.632936</td>\n","      <td>...</td>\n","      <td>64.19148</td>\n","      <td>34.761903</td>\n","      <td>22.9515</td>\n","      <td>49250.995060</td>\n","      <td>9.601957</td>\n","      <td>0.830530</td>\n","      <td>185.011155</td>\n","      <td>4892.32494</td>\n","      <td>0.238680</td>\n","      <td>232.402870</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>599</th>\n","      <td>1</td>\n","      <td>0.075867</td>\n","      <td>0.949920</td>\n","      <td>0.038606</td>\n","      <td>16.682338</td>\n","      <td>1.106707</td>\n","      <td>86.830313</td>\n","      <td>18.935745</td>\n","      <td>78.526968</td>\n","      <td>38.391824</td>\n","      <td>...</td>\n","      <td>66.45352</td>\n","      <td>29.397154</td>\n","      <td>24.0108</td>\n","      <td>13738.933020</td>\n","      <td>15.433075</td>\n","      <td>0.871047</td>\n","      <td>189.665577</td>\n","      <td>6704.19327</td>\n","      <td>0.238680</td>\n","      <td>974.892830</td>\n","    </tr>\n","    <tr>\n","      <th>602</th>\n","      <td>1</td>\n","      <td>0.931095</td>\n","      <td>4.001538</td>\n","      <td>0.018706</td>\n","      <td>9.162606</td>\n","      <td>0.350386</td>\n","      <td>127.985528</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>12.883712</td>\n","      <td>...</td>\n","      <td>99.96224</td>\n","      <td>26.370438</td>\n","      <td>17.6550</td>\n","      <td>9146.473587</td>\n","      <td>8.092101</td>\n","      <td>0.651957</td>\n","      <td>146.917382</td>\n","      <td>6276.34475</td>\n","      <td>0.238680</td>\n","      <td>150.224537</td>\n","    </tr>\n","    <tr>\n","      <th>610</th>\n","      <td>0</td>\n","      <td>0.005518</td>\n","      <td>0.296850</td>\n","      <td>0.050546</td>\n","      <td>3.583450</td>\n","      <td>0.581128</td>\n","      <td>219.902355</td>\n","      <td>99.000420</td>\n","      <td>78.526968</td>\n","      <td>26.381584</td>\n","      <td>...</td>\n","      <td>118.23452</td>\n","      <td>39.389152</td>\n","      <td>27.8949</td>\n","      <td>38475.318010</td>\n","      <td>34.323767</td>\n","      <td>0.488119</td>\n","      <td>246.205359</td>\n","      <td>5719.34587</td>\n","      <td>1.061424</td>\n","      <td>502.246010</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>1</td>\n","      <td>0.648318</td>\n","      <td>6.067614</td>\n","      <td>0.038208</td>\n","      <td>10.910227</td>\n","      <td>0.435846</td>\n","      <td>192.598575</td>\n","      <td>344.644105</td>\n","      <td>114.801199</td>\n","      <td>26.750080</td>\n","      <td>...</td>\n","      <td>123.17624</td>\n","      <td>39.852923</td>\n","      <td>27.1887</td>\n","      <td>3085.308063</td>\n","      <td>6.682597</td>\n","      <td>0.772304</td>\n","      <td>285.628059</td>\n","      <td>5654.07556</td>\n","      <td>0.238680</td>\n","      <td>157.393715</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>1</td>\n","      <td>0.510378</td>\n","      <td>6.192291</td>\n","      <td>0.022288</td>\n","      <td>8.026928</td>\n","      <td>0.363205</td>\n","      <td>113.526045</td>\n","      <td>NaN</td>\n","      <td>99.706633</td>\n","      <td>27.104928</td>\n","      <td>...</td>\n","      <td>96.97092</td>\n","      <td>34.367872</td>\n","      <td>19.0674</td>\n","      <td>1965.343176</td>\n","      <td>2.964975</td>\n","      <td>0.602254</td>\n","      <td>119.162529</td>\n","      <td>4517.86560</td>\n","      <td>0.532818</td>\n","      <td>112.196630</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 56 columns</p>\n","</div>"],"text/plain":["     EJ        DU        FD        CH         FI        AB          DI   \n","3     1  2.655345  7.884336  0.029054  14.852022  0.252107  139.824570  \\\n","5     0  0.005518  0.296850  0.016716  10.981896  0.209377  135.317865   \n","8     1  0.613833  1.389258  0.033830  11.450501  0.346113  131.349555   \n","12    1  0.386232  3.217854  0.041392  12.950037  0.491395   94.173945   \n","17    1  0.648318  4.262766  0.038606   9.669802  0.448665   62.030257   \n","..   ..       ...       ...       ...        ...       ...         ...   \n","599   1  0.075867  0.949920  0.038606  16.682338  1.106707   86.830313   \n","602   1  0.931095  4.001538  0.018706   9.162606  0.350386  127.985528   \n","610   0  0.005518  0.296850  0.050546   3.583450  0.581128  219.902355   \n","613   1  0.648318  6.067614  0.038208  10.910227  0.435846  192.598575   \n","615   1  0.510378  6.192291  0.022288   8.026928  0.363205  113.526045   \n","\n","             BQ          EP         DN  ...         DL         CS       BN   \n","3     11.050410   78.526968  24.354856  ...   71.57120  41.116960  23.6577  \\\n","5     16.526120   78.526968  31.731600  ...   81.46312  32.456996  10.2399   \n","8           NaN   78.526968  29.466032  ...   98.16872  29.914973  20.4798   \n","12   101.589790   88.268687  20.431056  ...   76.69736  47.227928  23.6577   \n","17   344.644105  125.687640  30.632936  ...   64.19148  34.761903  22.9515   \n","..          ...         ...        ...  ...        ...        ...      ...   \n","599   18.935745   78.526968  38.391824  ...   66.45352  29.397154  24.0108   \n","602         NaN   78.526968  12.883712  ...   99.96224  26.370438  17.6550   \n","610   99.000420   78.526968  26.381584  ...  118.23452  39.389152  27.8949   \n","613  344.644105  114.801199  26.750080  ...  123.17624  39.852923  27.1887   \n","615         NaN   99.706633  27.104928  ...   96.97092  34.367872  19.0674   \n","\n","               GF         CF        CC          BP          BD        DF   \n","3     2094.262452   2.347652  0.717882  237.282264  4169.67738  0.238680  \\\n","5    24177.595550  14.688030  0.639460  148.487931  5237.54088  0.238680   \n","8     4589.611956  14.566390  0.855496  135.881145  6569.37001  0.238680   \n","12   25583.307300   5.726203  0.329736  338.094162  5688.40060  0.238680   \n","17   49250.995060   9.601957  0.830530  185.011155  4892.32494  0.238680   \n","..            ...        ...       ...         ...         ...       ...   \n","599  13738.933020  15.433075  0.871047  189.665577  6704.19327  0.238680   \n","602   9146.473587   8.092101  0.651957  146.917382  6276.34475  0.238680   \n","610  38475.318010  34.323767  0.488119  246.205359  5719.34587  1.061424   \n","613   3085.308063   6.682597  0.772304  285.628059  5654.07556  0.238680   \n","615   1965.343176   2.964975  0.602254  119.162529  4517.86560  0.532818   \n","\n","             DE  \n","3    196.607985  \n","5    135.489250  \n","8    231.134460  \n","12   353.447325  \n","17   232.402870  \n","..          ...  \n","599  974.892830  \n","602  150.224537  \n","610  502.246010  \n","613  157.393715  \n","615  112.196630  \n","\n","[154 rows x 56 columns]"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["# print(fullPipeline[targetVars[0]].get_feature_names_out()[:10])\n","x_t[3]"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.720202Z","iopub.status.busy":"2023-05-05T21:25:02.719772Z","iopub.status.idle":"2023-05-05T21:25:02.756095Z","shell.execute_reply":"2023-05-05T21:25:02.754627Z","shell.execute_reply.started":"2023-05-05T21:25:02.720164Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EJ</th>\n","      <th>DU</th>\n","      <th>FD</th>\n","      <th>CH</th>\n","      <th>FI</th>\n","      <th>AB</th>\n","      <th>DI</th>\n","      <th>BQ</th>\n","      <th>EP</th>\n","      <th>DN</th>\n","      <th>...</th>\n","      <th>DL</th>\n","      <th>CS</th>\n","      <th>BN</th>\n","      <th>GF</th>\n","      <th>CF</th>\n","      <th>CC</th>\n","      <th>BP</th>\n","      <th>BD</th>\n","      <th>DF</th>\n","      <th>DE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0.693375</td>\n","      <td>1.062808</td>\n","      <td>1.183007</td>\n","      <td>-0.201033</td>\n","      <td>1.499132</td>\n","      <td>-0.783137</td>\n","      <td>0.055461</td>\n","      <td>-1.665942</td>\n","      <td>-0.724220</td>\n","      <td>-0.248436</td>\n","      <td>...</td>\n","      <td>-0.806162</td>\n","      <td>0.528706</td>\n","      <td>0.494663</td>\n","      <td>-0.859516</td>\n","      <td>-1.664274</td>\n","      <td>0.184343</td>\n","      <td>0.456634</td>\n","      <td>-0.595245</td>\n","      <td>-0.490496</td>\n","      <td>-0.633576</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>-1.442221</td>\n","      <td>-0.822980</td>\n","      <td>-1.091158</td>\n","      <td>-1.384517</td>\n","      <td>0.451211</td>\n","      <td>-0.972255</td>\n","      <td>-0.012813</td>\n","      <td>-1.316350</td>\n","      <td>-0.724220</td>\n","      <td>0.606023</td>\n","      <td>...</td>\n","      <td>-0.394640</td>\n","      <td>-0.260585</td>\n","      <td>-4.625667</td>\n","      <td>0.929884</td>\n","      <td>0.643933</td>\n","      <td>-0.147629</td>\n","      <td>-0.600998</td>\n","      <td>0.087163</td>\n","      <td>-0.490496</td>\n","      <td>-1.152971</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.693375</td>\n","      <td>-0.131733</td>\n","      <td>-0.369036</td>\n","      <td>0.253284</td>\n","      <td>0.594842</td>\n","      <td>-0.388842</td>\n","      <td>-0.074827</td>\n","      <td>0.428961</td>\n","      <td>-0.724220</td>\n","      <td>0.366023</td>\n","      <td>...</td>\n","      <td>0.199445</td>\n","      <td>-0.531536</td>\n","      <td>-0.404607</td>\n","      <td>-0.285678</td>\n","      <td>0.632301</td>\n","      <td>0.731839</td>\n","      <td>-0.800852</td>\n","      <td>0.765269</td>\n","      <td>-0.490496</td>\n","      <td>-0.407549</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.693375</td>\n","      <td>-0.353849</td>\n","      <td>0.302623</td>\n","      <td>0.968345</td>\n","      <td>1.020604</td>\n","      <td>0.169380</td>\n","      <td>-0.766984</td>\n","      <td>0.332755</td>\n","      <td>-0.308691</td>\n","      <td>-0.810988</td>\n","      <td>...</td>\n","      <td>-0.586354</td>\n","      <td>0.993276</td>\n","      <td>0.494663</td>\n","      <td>0.971229</td>\n","      <td>-0.621600</td>\n","      <td>-1.635276</td>\n","      <td>1.256984</td>\n","      <td>0.334311</td>\n","      <td>-0.490496</td>\n","      <td>0.186524</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.693375</td>\n","      <td>-0.100841</td>\n","      <td>0.564187</td>\n","      <td>0.705507</td>\n","      <td>0.016994</td>\n","      <td>0.011051</td>\n","      <td>-1.632004</td>\n","      <td>1.466354</td>\n","      <td>0.950159</td>\n","      <td>0.491785</td>\n","      <td>...</td>\n","      <td>-1.151523</td>\n","      <td>-0.032146</td>\n","      <td>0.305274</td>\n","      <td>1.450422</td>\n","      <td>0.058364</td>\n","      <td>0.635592</td>\n","      <td>-0.105140</td>\n","      <td>-0.116906</td>\n","      <td>-0.490496</td>\n","      <td>-0.399900</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>599</th>\n","      <td>0.693375</td>\n","      <td>-0.724176</td>\n","      <td>-0.609168</td>\n","      <td>0.705507</td>\n","      <td>1.908226</td>\n","      <td>2.050698</td>\n","      <td>-0.935541</td>\n","      <td>-1.196126</td>\n","      <td>-0.724220</td>\n","      <td>1.225752</td>\n","      <td>...</td>\n","      <td>-1.041673</td>\n","      <td>-0.589455</td>\n","      <td>0.587333</td>\n","      <td>0.516398</td>\n","      <td>0.713267</td>\n","      <td>0.791136</td>\n","      <td>-0.049078</td>\n","      <td>0.826073</td>\n","      <td>-0.490496</td>\n","      <td>1.608100</td>\n","    </tr>\n","    <tr>\n","      <th>602</th>\n","      <td>0.693375</td>\n","      <td>0.130493</td>\n","      <td>0.504021</td>\n","      <td>-1.192664</td>\n","      <td>-0.165344</td>\n","      <td>-0.371580</td>\n","      <td>-0.128871</td>\n","      <td>0.428961</td>\n","      <td>-0.724220</td>\n","      <td>-2.263550</td>\n","      <td>...</td>\n","      <td>0.257168</td>\n","      <td>-0.949094</td>\n","      <td>-1.323577</td>\n","      <td>0.218752</td>\n","      <td>-0.171215</td>\n","      <td>-0.093677</td>\n","      <td>-0.624957</td>\n","      <td>0.628697</td>\n","      <td>-0.490496</td>\n","      <td>-1.009072</td>\n","    </tr>\n","    <tr>\n","      <th>610</th>\n","      <td>-1.442221</td>\n","      <td>-0.822980</td>\n","      <td>-1.091158</td>\n","      <td>1.827030</td>\n","      <td>-3.146481</td>\n","      <td>0.487604</td>\n","      <td>1.000487</td>\n","      <td>0.308897</td>\n","      <td>-0.724220</td>\n","      <td>0.008870</td>\n","      <td>...</td>\n","      <td>0.792880</td>\n","      <td>0.385073</td>\n","      <td>1.528193</td>\n","      <td>1.269779</td>\n","      <td>1.856821</td>\n","      <td>-0.835759</td>\n","      <td>0.540029</td>\n","      <td>0.350549</td>\n","      <td>0.982771</td>\n","      <td>0.678520</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>0.693375</td>\n","      <td>-0.100841</td>\n","      <td>0.912655</td>\n","      <td>0.667902</td>\n","      <td>0.428749</td>\n","      <td>-0.037359</td>\n","      <td>0.723545</td>\n","      <td>1.466354</td>\n","      <td>0.627064</td>\n","      <td>0.053598</td>\n","      <td>...</td>\n","      <td>0.923661</td>\n","      <td>0.424221</td>\n","      <td>1.366923</td>\n","      <td>-0.576160</td>\n","      <td>-0.422933</td>\n","      <td>0.405930</td>\n","      <td>0.875679</td>\n","      <td>0.316196</td>\n","      <td>-0.490496</td>\n","      <td>-0.944059</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>0.693375</td>\n","      <td>-0.228532</td>\n","      <td>0.933320</td>\n","      <td>-0.848272</td>\n","      <td>-0.609008</td>\n","      <td>-0.320121</td>\n","      <td>-0.378449</td>\n","      <td>0.428961</td>\n","      <td>0.124841</td>\n","      <td>0.096113</td>\n","      <td>...</td>\n","      <td>0.160310</td>\n","      <td>-0.070136</td>\n","      <td>-0.847909</td>\n","      <td>-0.905977</td>\n","      <td>-1.411373</td>\n","      <td>-0.310725</td>\n","      <td>-1.096355</td>\n","      <td>-0.355220</td>\n","      <td>0.125772</td>\n","      <td>-1.415615</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 56 columns</p>\n","</div>"],"text/plain":["           EJ        DU        FD        CH        FI        AB        DI   \n","3    0.693375  1.062808  1.183007 -0.201033  1.499132 -0.783137  0.055461  \\\n","5   -1.442221 -0.822980 -1.091158 -1.384517  0.451211 -0.972255 -0.012813   \n","8    0.693375 -0.131733 -0.369036  0.253284  0.594842 -0.388842 -0.074827   \n","12   0.693375 -0.353849  0.302623  0.968345  1.020604  0.169380 -0.766984   \n","17   0.693375 -0.100841  0.564187  0.705507  0.016994  0.011051 -1.632004   \n","..        ...       ...       ...       ...       ...       ...       ...   \n","599  0.693375 -0.724176 -0.609168  0.705507  1.908226  2.050698 -0.935541   \n","602  0.693375  0.130493  0.504021 -1.192664 -0.165344 -0.371580 -0.128871   \n","610 -1.442221 -0.822980 -1.091158  1.827030 -3.146481  0.487604  1.000487   \n","613  0.693375 -0.100841  0.912655  0.667902  0.428749 -0.037359  0.723545   \n","615  0.693375 -0.228532  0.933320 -0.848272 -0.609008 -0.320121 -0.378449   \n","\n","           BQ        EP        DN  ...        DL        CS        BN   \n","3   -1.665942 -0.724220 -0.248436  ... -0.806162  0.528706  0.494663  \\\n","5   -1.316350 -0.724220  0.606023  ... -0.394640 -0.260585 -4.625667   \n","8    0.428961 -0.724220  0.366023  ...  0.199445 -0.531536 -0.404607   \n","12   0.332755 -0.308691 -0.810988  ... -0.586354  0.993276  0.494663   \n","17   1.466354  0.950159  0.491785  ... -1.151523 -0.032146  0.305274   \n","..        ...       ...       ...  ...       ...       ...       ...   \n","599 -1.196126 -0.724220  1.225752  ... -1.041673 -0.589455  0.587333   \n","602  0.428961 -0.724220 -2.263550  ...  0.257168 -0.949094 -1.323577   \n","610  0.308897 -0.724220  0.008870  ...  0.792880  0.385073  1.528193   \n","613  1.466354  0.627064  0.053598  ...  0.923661  0.424221  1.366923   \n","615  0.428961  0.124841  0.096113  ...  0.160310 -0.070136 -0.847909   \n","\n","           GF        CF        CC        BP        BD        DF        DE  \n","3   -0.859516 -1.664274  0.184343  0.456634 -0.595245 -0.490496 -0.633576  \n","5    0.929884  0.643933 -0.147629 -0.600998  0.087163 -0.490496 -1.152971  \n","8   -0.285678  0.632301  0.731839 -0.800852  0.765269 -0.490496 -0.407549  \n","12   0.971229 -0.621600 -1.635276  1.256984  0.334311 -0.490496  0.186524  \n","17   1.450422  0.058364  0.635592 -0.105140 -0.116906 -0.490496 -0.399900  \n","..        ...       ...       ...       ...       ...       ...       ...  \n","599  0.516398  0.713267  0.791136 -0.049078  0.826073 -0.490496  1.608100  \n","602  0.218752 -0.171215 -0.093677 -0.624957  0.628697 -0.490496 -1.009072  \n","610  1.269779  1.856821 -0.835759  0.540029  0.350549  0.982771  0.678520  \n","613 -0.576160 -0.422933  0.405930  0.875679  0.316196 -0.490496 -0.944059  \n","615 -0.905977 -1.411373 -0.310725 -1.096355 -0.355220  0.125772 -1.415615  \n","\n","[154 rows x 56 columns]"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["x_tTransf[3]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Prelminaries"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.758392Z","iopub.status.busy":"2023-05-05T21:25:02.757892Z","iopub.status.idle":"2023-05-05T21:25:02.789697Z","shell.execute_reply":"2023-05-05T21:25:02.788262Z","shell.execute_reply.started":"2023-05-05T21:25:02.758353Z"},"trusted":true},"outputs":[],"source":["# from functools import reduce\n","# import operator\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, \\\n","     r2_score#, accuracy_score\n","\n","#predictions\n","def getPrediction(yModel, x, eModel = None):\n","    x_initialModels = None\n","    try:\n","        x_initialModels = x if 'Comb' in type(yModel).__name__ else x#[[quantiVars[0]]] \n","    except:\n","        x_initialModels = x\n","    y_pred = yModel.predict(x_initialModels) #if type(yModel).__name__ != 'MyTfMLPClassifier' else yModel.predict(x, verbose=False)   \n","    if eModel is not None:\n","        nPreds = len(y_pred)\n","        e_pred = eModel.predict(x)\n","        for i in range(nPreds):\n","            y_pred[i] += e_pred[i]\n","    \n","    try:\n","        ret = np.concatenate(y_pred)\n","    except:\n","        ret = y_pred\n","        \n","    return pd.Series(ret, index=x.index).clip(lower=0, upper=1)\n","def getPrediction2(targetVar, y_Predictions):\n","    nPreds = len(y_Predictions)\n","    y_pred = [0]*nPreds\n","    for i in range(nPreds):\n","        y_pred[i] = np.expm1(y_Predictions[i]*ltheoreticalMax)\n","        y_pred[i] = np.round(y_pred[i])\n","        if y_pred[i] > theoreticalMax[targetVar]:\n","           y_pred[i] = theoreticalMax[targetVar]\n","        elif y_pred[i] < 0:\n","            y_pred[i] = 0\n","    return y_pred\n","\n","# models performance\n","def LOG_LOSS(target, prediction):\n","    N_c = np.bincount(target)\n","    N = np.sum(N_c)\n","    w = [1/(N_c[0]/N), 1/(N_c[1]/N)]\n","    # prediction = np.clip(prediction, 1e-15, 1-1e-15)\n","    ret = 0\n","    for i in [0,1]:\n","        trues =(target==i)\n","        preds = prediction[trues]**i\n","        preds *= (1-prediction[trues])**(1-i)\n","        preds = np.clip(preds, 1e-15, 1-1e-15)\n","        sum_ = np.sum(np.log(preds))\n","        ret -= (w[i]/N_c[i])*sum_\n","    ret /= np.sum(w)\n","    return ret\n","\n","# models_target = []; \n","models_label = []\n","models_r2_t = []; models_r2_v = []\n","models_rmse_t = []; models_rmse_v = []\n","models_rmsle_t = []; models_rmsle_v = []\n","models_mae_t = []; models_mae_v = []\n","models_mape_t = []; models_mape_v = []\n","models_smape_t = []; models_smape_v = []; models_smape_dif_vt = []\n","models_logLoss_t = []; models_logLoss_v = []; models_logLoss_dif_vt = []\n","# best_yModels = {}\n","yPredictions = {}; e_yPredictions = {}; singleModelsObjs = {}\n","# ySingleModelsNms = {}\n","# for u in targetVars:\n","best_yModels = {'yModelObj':None, 'eModelObj':None, 'modelNm':'??', \n","                    'logLoss_t':10**10, 'logLoss_v':10**10, 'logLoss_dif_vt': None, 'logLoss_vPdiff': 10**10}\n","# yPredictions = {}; e_yPredictions = {}; \n","# singleModelsObjs = {}\n","for i in range(nDataSubsets):\n","    yPredictions[i] = pd.DataFrame(y_t[i])#{'df_t': pd.DataFrame(y_t), 'df_v': pd.DataFrame(y_v)}\n","    e_yPredictions[i] = pd.DataFrame(index = y_t[i].index)#{'df_t': pd.DataFrame(index = y_t.index), 'df_v': pd.DataFrame(index = y_v.index)}\n","    # display(e_yPredictions['df_t'])\n"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.792354Z","iopub.status.busy":"2023-05-05T21:25:02.791825Z","iopub.status.idle":"2023-05-05T21:25:02.824967Z","shell.execute_reply":"2023-05-05T21:25:02.822837Z","shell.execute_reply.started":"2023-05-05T21:25:02.792300Z"},"trusted":true},"outputs":[],"source":["def computePerformanceMeasures(yModel, phase, x_t, y_t, eModel = None, nDigits = 3, printResults = True):\n","    global u# = targetVars[0]\n","    global best_yModels\n","    # print('************************ ************************')\n","    formalism = getModelName(yModel, eModel, targetVar=\"\")\n","    # type_yModel = type(yModel)\n","    # formalism = 'y'+type_yModel.__name__.replace('Classifier', '').replace('Classification', '')# if type_yModel != str else yModel\n","    # if eModel is not None:\n","    #     formalism += '_e'+type(eModel).__name__.replace('Classifier', '').replace('Classification', '')\n","\n","    y_tPred = getPrediction(yModel = yModel, x = x_t[phase], eModel=eModel)# if type_yModel != str else yPredictions[phase][yModel].values\n","    y_vPred = getPrediction(yModel = yModel, x = x_t[3], eModel=eModel)# if type_yModel =! str else yPredictions[3][yModel].values\n","    e_y_tPred = y_t[phase][u] - y_tPred\n","    e_y_vPred = y_t[3][u] - y_vPred\n","    e_yPredictions[phase][formalism] = e_y_tPred\n","    e_yPredictions[3][formalism] = e_y_vPred\n","    # if type_yModel != str:\n","    yPredictions[phase][formalism] = y_tPred\n","    yPredictions[3][formalism] = y_vPred\n","    if phase < 2:\n","        yPredictions[phase+1][formalism] = getPrediction(yModel = yModel, x = x_t[phase+1], eModel=eModel)\n","        e_yPredictions[phase+1][formalism] = y_t[phase+1][u] - getPrediction(yModel = yModel, x = x_t[phase+1], eModel=eModel)\n","    # formalism += ('_'+u)\n","    singleModelsObjs[formalism] = {'yModel':yModel, 'eModel':eModel}\n","    # models_target.append(u)\n","    models_label.append(formalism)\n","    # y_tPred = getPrediction(targetVar = u, y_Predictions = y_tPred)\n","    # y_vPred = getPrediction(targetVar = u, y_Predictions = y_vPred)\n","    y_tTrue = y_t[phase][u]\n","    y_vTrue = y_t[3][u]\n","    models_r2_t.append(round(r2_score(y_true=y_tTrue, y_pred=y_tPred), nDigits))\n","    models_r2_v.append(round(r2_score(y_true=y_vTrue, y_pred=y_vPred),  nDigits))\n","    models_rmse_t.append(round(mean_squared_error(y_true=y_tTrue, y_pred=y_tPred, squared=False), nDigits))\n","    models_rmse_v.append(round(mean_squared_error(y_true=y_vTrue, y_pred=y_vPred, squared=False), nDigits))\n","    # models_rmsle_t.append(float(format(\n","    #     mean_squared_log_error(y_true=y_train_origin, y_pred=y_train_predict, squared=False), '.2g')))\n","    # models_rmsle_v.append(float(format(\n","    #     mean_squared_log_error(y_true=y_valid_origin, y_pred=y_valid_predict, squared=False), '.2g')))\n","    models_mae_t.append(round(mean_absolute_error(y_true=y_tTrue, y_pred=y_tPred), nDigits))\n","    mae_v = round(mean_absolute_error(y_true=y_vTrue, y_pred=y_vPred), nDigits)\n","    models_mae_v.append(mae_v)\n","    # models_mape_t.append(round(mean_absolute_percentage_error(y_true=y_tTrue, y_pred=y_tPred), nDigits))\n","    # models_mape_v.append(round(mean_absolute_percentage_error(y_true=y_vTrue, y_pred=y_vPred), nDigits))\n","    # smape_t = round(SMAPE(y_tTrue, y_tPred), nDigits)\n","    # smape_v = round(SMAPE(y_vTrue, y_vPred), nDigits)\n","    # smape_dif_vt = round(smape_v - smape_t, nDigits)\n","    # smape_vPdiff = smape_v + smape_dif_vt\n","    # if(formalism == 'yMyXGB_eMyLGBM'):\n","    #     g=1\n","    logLoss_t = round(LOG_LOSS(y_tTrue, y_tPred), nDigits)\n","    logLoss_v = round(LOG_LOSS(y_vTrue, y_vPred), nDigits)\n","    logLoss_dif_vt = round(logLoss_v - logLoss_t, nDigits)\n","    logLoss_vPdiff = logLoss_v + logLoss_dif_vt\n","    models_logLoss_t.append(logLoss_t)\n","    models_logLoss_v.append(logLoss_v)\n","    models_logLoss_dif_vt.append(logLoss_dif_vt)\n","    if logLoss_t + logLoss_v < best_yModels['logLoss_t']+ best_yModels['logLoss_v']:\n","        best_yModels = {'yModelObj':yModel, 'eModelObj': eModel, \n","                            'modelNm':formalism, 'logLoss_t':logLoss_t, \n","                            'logLoss_v':logLoss_v, 'logLoss_dif_vt': logLoss_dif_vt, \n","                            'logLoss_vPdiff': logLoss_vPdiff}\n","    if printResults:    \n","        df = pd.DataFrame({#'target':models_target,\n","                            'model': models_label,\n","                        #    'mape-t': models_mape_t,\n","                        #    'mape-v': models_mape_v,\n","                        'logLoss_t': models_logLoss_t,\n","                        'logLoss_v': models_logLoss_v,#}\n","                        #    'rmsle-t': models_rmsle_t,\n","                        #    'rmsle-v': models_rmsle_v,\n","                        #    'r2-t': models_r2_t,\n","                        #    'r2-v': models_r2_v}  # ,\n","                        #    'rmse-t': models_rmse_t,\n","                        #    'rmse-v': models_rmse_v,\n","                            # 'mae-t': models_mae_t,\n","                            # 'mae-v': models_mae_v\n","                        \n","                        'logLoss_dif_vt':models_logLoss_dif_vt}\n","                        )\n","        print(\" *********** Best models via SMAPE in the validation set *********** \")\n","        lbestModel = []; llogLoss_t = []; llogLoss_v = []; llogLoss_dif_vt = []\n","        for u in targetVars:\n","            lbestModel.append(best_yModels['modelNm'])\n","            llogLoss_t.append(best_yModels['logLoss_t'])\n","            llogLoss_v.append(best_yModels['logLoss_v'])\n","            llogLoss_dif_vt.append(best_yModels['logLoss_dif_vt'])\n","            # print('bestModel:', best_yModels['modelNm'], ', smape_t:', best_yModels['smape_t']\n","            #       , ', smape_v:', best_yModels['smape_v']\n","            #       , ', smape_dif_vt:', best_yModels['smape_dif_vt'])\n","        dfOpt = pd.DataFrame.from_dict({'bestModel': lbestModel, 'logLoss_t':llogLoss_t,\n","                'logLoss_v': llogLoss_v, 'logLoss_dif_vt':llogLoss_dif_vt})\n","        dfOpt = dfOpt.sort_values(by=[\"logLoss_v\", 'logLoss_dif_vt', 'logLoss_t'], \n","                                  ascending=True)\n","        display(dfOpt)\n","        print(\" *********** Rank via logLoss in the validation set *********** \")\n","        df = df.sort_values(by=[\"logLoss_v\", 'logLoss_dif_vt', 'logLoss_t'], \n","                            ascending=True)\n","        display(df)\n","        bestModelsPerformanceFN = 'bestModelsPerformance.csv'\n","        modelsPerformanceFN = 'modelsPerformance.csv'\n","        dfOpt.to_csv(PERFORMANCE_ROOT+bestModelsPerformanceFN, sep='\\t', index=False)\n","        df.to_csv(PERFORMANCE_ROOT+modelsPerformanceFN, sep='\\t', index=False)\n","    # return(df.sort_values(by=[\"mae-v\", 'mae-t'], ascending=True))\n"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.828184Z","iopub.status.busy":"2023-05-05T21:25:02.827011Z","iopub.status.idle":"2023-05-05T21:25:02.845499Z","shell.execute_reply":"2023-05-05T21:25:02.844330Z","shell.execute_reply.started":"2023-05-05T21:25:02.828127Z"},"trusted":true},"outputs":[],"source":["# probabilistic optimization via BayesSearchCV and GridSearchCV\n","#https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f\n","# %pip install scikit-optimize\n","from skopt import BayesSearchCV\n","from sklearn.model_selection import GridSearchCV \n","# import tensorflow as tf \n","from tensorflow import keras \n","# from skopt.plots import plot_objective\n","# from skopt.space import Real, Categorical, Integer\n","\n","def getOptimalModel(modelObj, parsInfo, x_train, y_train, verbose=False, \n","                                    epochs=500, batch_size=50,validation_split=.2, \n","                                    method = optMethod, modelName = None):\n","    # log-uniform: understand as search over p = exp(x) by varying x\n","    opt = None; scoring = 'neg_root_mean_squared_error'#'neg_log_loss'; #'neg_root_mean_squared_error',#'neg_mean_absolute_percentage_error', #'neg_root_mean_squared_error'\n","    modelNm = modelName if modelName is not None else getModelName(yModel=modelObj)\n","    path = MODELS_ROOT+modelNm+modelObj.saveExtension\n","    start = time.time()\n","    try:\n","        model =  modelObj.loadModel(path)\n","        print('==**** load_model', modelNm, '****==')\n","    except:\n","        print('==**** fit', modelNm, '****==')\n","        if method == 'GridSearchCV':\n","            opt = GridSearchCV(modelObj, parsInfo, cv = myCv, \n","                        scoring = scoring, return_train_score = True, verbose=verbose)\n","        else:\n","            opt = BayesSearchCV(modelObj, parsInfo, cv = myCv, \n","                                n_iter = 50 if isInKaggle else 10,\n","                        scoring = scoring, return_train_score = True, verbose=verbose) \n","        modelClass = type(modelObj).__name__\n","        print('**', modelClass, '**')\n","        opt.fit(X = x_train, y = y_train)#.values.ravel())\n","        print('best_params = ', opt.best_params_)\n","        print('best_score (RMSE)= ', -opt.best_score_)\n","        model = opt.best_estimator_\n","        model.saveModel(path)\n","    print('>>> elapsed time:', str(time.time() - start), 'seconds!')\n","    return (model)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Initial Models"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Class Classification"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:02.847741Z","iopub.status.busy":"2023-05-05T21:25:02.847126Z","iopub.status.idle":"2023-05-05T21:25:11.460771Z","shell.execute_reply":"2023-05-05T21:25:11.459619Z","shell.execute_reply.started":"2023-05-05T21:25:02.847703Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," ************ yModels ************\n","==**** load_model yMyLinear ****==\n",">>> elapsed time: 0.006987094879150391 seconds!\n","==**** load_model yMyLogistic ****==\n",">>> elapsed time: 0.004323720932006836 seconds!\n","==**** load_model yMySVC ****==\n",">>> elapsed time: 0.0050127506256103516 seconds!\n","==**** load_model yMyLGBM ****==\n",">>> elapsed time: 0.029328584671020508 seconds!\n","==**** load_model yMyDecisionTree ****==\n",">>> elapsed time: 0.00781393051147461 seconds!\n","==**** load_model yMyRandomForest ****==\n",">>> elapsed time: 0.03400564193725586 seconds!\n","==**** load_model yMyXGB ****==\n",">>> elapsed time: 0.008998870849609375 seconds!\n"]}],"source":["# modeling each target and transformed features\n","# from https://www.kaggle.com/code/renataghisloti/linearregression-simple-70-smape?scriptVersionId=120868178&cellId=6\n","# from sklearn.model_selection import cross_val_score\n","\n","yModels = {}\n","e_yModels = {}\n","xModels = {}\n","predVars = {}\n","gridLinear = {'fit_intercept': [True, False]}\n","gridLogistic = {'tol': [0.00005, 0.0001, 0.0002],\n","                'C': [.5, 1, 2],\n","                'fit_intercept': [True, False],\n","                'intercept_scaling': [.5, 1, 2], }\n","parsDistsLogistic = {'tol': (1e-6, 5e-1),\n","                     'C': (.1, 2),\n","                     'fit_intercept': [True, False],\n","                     'intercept_scaling': (.5, 1), }\n","manualGamma = 1/(nImportantFeatures*4)\n","gridSVC = {'kernel': ['poly', 'rbf', 'sigmoid'],  # 'linear',\n","           'C': [.05, 1, 1.2],\n","           'gamma': ['scale', 'auto', manualGamma]}\n","parsDistsSVC = {'kernel': ['poly', 'rbf', 'sigmoid'],  # 'linear',\n","                'degree': (2, 5),  # integer valued parameter (1, 5)\n","                'gamma': (1e-5, 1, 'uniform'),\n","                'coef0': (-2, 2, 'uniform'),\n","                'C': (.05, 1.5, 'log-uniform'),\n","                # 'epsilon': (.05, .2, 'log-uniform')\n","                }\n","gridTree = {\n","    'min_samples_leaf': [2, 5, 50, 80, 100, 150],\n","    'min_samples_split': [20, 50, 500, 1000],\n","}\n","parsDistsTree = {\n","    'min_samples_leaf': (2, 150),\n","    'min_samples_split': (20, 1000),\n","}\n","gridLg = {'max_depth': [-1, 1, 10, 50],\n","          # 'learning_rate':(.1, 2, 'uniform'),\n","          'n_estimators': [2, 5, 50, 100]}\n","parsDistsLg = {'max_depth': (-1, 50),\n","               'learning_rate': (.1, 1, 'uniform'),\n","               'n_estimators': (2, 200)}\n","\n","gridForest = {'n_estimators': [5, 10, 100, 200],\n","              'min_samples_split': [2, 40, 50, 500],\n","              }\n","parsDistsForest = {\n","    'n_estimators': (5, 200),\n","    'min_samples_split': (2, 500),\n","}\n","gridXg = {'max_depth': [1, 5, 6, 10],  # integer valued parameter\n","          #   'n_estimators': (3, 10, 20)\n","          'eta': [.1, 0.3, .6],\n","          # 'gamma': [0, 1, 2],\n","          }\n","gridMLP = {'activation': ['relu', 'identity', 'logistic', 'tanh']}\n","parsDistsXgb = {  # 'splitter': [\"best\", \"random\"],  # categorical parameter\n","    'max_depth': (1, 10),  # integer valued parameter\n","    'n_estimators': (2, 100),\n","    'eta': (.01, .6, 'log-uniform'),\n","    'colsample_bytree': (.2, 1, 'log-uniform')\n","}\n","parsDistsMyTfMLP = {\n","    'learningRate': (1e-4, 1e-1, 'uniform'),\n","    'inpute_layer_dropout_rate': (0, .5, 'uniform')\n","}\n","parsDistsMyTfRNN = {\n","    'learningRate': (1e-4, 1e-1, 'uniform'),\n","    'inpute_layer_dropout_rate': (0, .5, 'uniform')\n","}\n","gridMyTfMLP = {\n","    'learningRate': [1e-4, 1e-2, 1e-1],\n","    'inpute_layer_dropout_rate': [0, .1, .5]\n","}\n","gridMyTfRNN = {\n","    'learningRate': [1e-4, 1e-2, 1e-1],\n","    'inpute_layer_dropout_rate': [0, .1, .5]\n","}\n","\n","# for u in targetVars:\n","e_yModels = {}  # 'yLinear': None, 'ySVC': None, 'yDecisionTree':None}\n","predVars = list(x_t[0].columns).copy()\n","# if 'visit_month' in predVars:\n","#     predVars.remove('visit_month')\n","print('\\n ************ yModels ************')\n","x = x_tTransf[0] if isWithPCA else x_tTransf[0]  # [[quantiVars[0]]];\n","y = y_t[0]\n","min_samples_split = round(.15*len(x))\n","# print('min_samples_split=', min_samples_split)\n","# yModels = {}\n","if isToRunInitialModels['MyLinearRegressor']:\n","    yModels['yMyLinear'] = initialModelsObjs['MyLinearRegressor'].fit(x, y) if not isWithOptimization else getOptimalModel(\n","        MyLinearRegressor(), gridLinear, x, y, False, method='GridSearchCV')\n","if isToRunInitialModels['MyLogisticRegression']:\n","    yModels['yMyLogistic'] = initialModelsObjs['MyLogisticRegression'].fit(x, y) if not isWithOptimization else getOptimalModel(\n","        MyLogisticRegression(), gridLogistic, x, y, False, method='GridSearchCV')\n","if isToRunInitialModels['MySVC']:\n","    yModels['yMySVC'] = initialModelsObjs['MySVC'].fit(x, y) if not isWithOptimization else getOptimalModel(\n","        MySVC(u), gridSVC, x, y, False, method='GridSearchCV')\n","if isToRunInitialModels['MyLGBMClassifier']:\n","    yModels['yMyLGBM'] = initialModelsObjs['MyLGBMClassifier'].fit(x, y) if not isWithOptimization else getOptimalModel(\n","        MyLGBMClassifier(u, random_state=0), gridLg, x, y, False, method='GridSearchCV')\n","if isToRunInitialModels['MyDecisionTreeClassifier']:\n","    yModels['yMyDecisionTree'] = initialModelsObjs['MyDecisionTreeClassifier'].fit(\n","        x, y) if not isWithOptimization else getOptimalModel(MyDecisionTreeClassifier(u), gridTree, x, y, False, method='GridSearchCV')\n","if isToRunInitialModels['MyRandomForestClassifier']:\n","    yModels['yMyRandomForest'] = initialModelsObjs['MyRandomForestClassifier'].fit(\n","        x, y) if not isWithOptimization else getOptimalModel(MyRandomForestClassifier(u), gridForest, x, y, False, method='GridSearchCV')\n","if isToRunInitialModels['MyXGBClassifier']:\n","    yModels['yMyXGB'] = initialModelsObjs['MyXGBClassifier'].fit(x, y) if not isWithOptimization else getOptimalModel(\n","        MyXGBClassifier(u, objective='reg:squarederror', seed=0), gridXg, x, y, False, method='GridSearchCV')\n","if isToRunInitialModels['MyMLPClassifier']:\n","    yModels['yMyMLP'] = initialModelsObjs['MyMLPClassifier'].fit(x, y) if not isWithOptimization else getOptimalModel(\n","        MyMLPClassifier(u), gridMLP, x, y, False, method='GridSearchCV')\n","if isToRunInitialModels['MyTfMLPClassifier']:\n","    yModels['yMyTfMLP'] = initialModelsObjs['MyTfMLPClassifier'].fit(x, y) if not isWithOptimization else getOptimalModel(\n","        MyTfMLPClassifier(u, 'initialModel'), gridMyTfMLP, x, y, False, method='GridSearchCV')\n","if isToRunInitialModels['MyTfRNNClassifier']:\n","    yModels['yMyTfRNN'] = initialModelsObjs['MyTfRNNClassifier'].fit(x, y) if not isWithOptimization else getOptimalModel(\n","        MyTfRNNClassifier(u, 'initialModel'), gridMyTfRNN, x, y, False, method='GridSearchCV')\n","\n","for yModel in yModels:\n","    e_yModels[yModel] = None\n","# print('************ xModels ************')\n","# x = x_t[0]['visit_month']; y = x_tTransf[0]#x_t[predVars]\n","# if not isWithPCA: x = x_tTransf[0]['visit_month']; y = x_tTransf[0][predVars]\n","# xModels = {}\n","# if isToRunXModels['xTransfLinear']: xModels['xTransfLinear']= MyLinearRegressor().fit(X=x.values.reshape(-1, 1), y=y)\n","# if isToRunXModels['xTransfXg']: xModels['xTransfXg']= xg.XGBClassifier(objective='reg:squarederror', seed=0).fit(X=x, y=y)\n","# if isToRunXModels['xTransfSVC']: xModels['xTransfSVC']= MultiOutputClassifier(SVC(verbose=False)).fit(X = x.values.reshape(-1, 1), y = y)\n","\n","#     xTransfXg = getOptimalModelViaBayesSearchCv(MyXGBClassifier(objective ='reg:squarederror', seed=0), parsDistsXgb,\n","#                                                     x_tTransf['visit_month'],\n","#                                                     x_tTransf[predVars], False)"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:11.462663Z","iopub.status.busy":"2023-05-05T21:25:11.462213Z","iopub.status.idle":"2023-05-05T21:25:11.468355Z","shell.execute_reply":"2023-05-05T21:25:11.466817Z","shell.execute_reply.started":"2023-05-05T21:25:11.462629Z"},"trusted":true},"outputs":[],"source":["# initialModelsObjs['MyXGBClassifier']"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:11.469975Z","iopub.status.busy":"2023-05-05T21:25:11.469622Z","iopub.status.idle":"2023-05-05T21:25:11.535395Z","shell.execute_reply":"2023-05-05T21:25:11.533876Z","shell.execute_reply.started":"2023-05-05T21:25:11.469941Z"},"trusted":true},"outputs":[],"source":["#rankPeptidesModels\n","best_xModels = {}\n","def rankPeptidesModels():\n","    dic = {'target':[], 'xModel':[], 'MAPE_t':[], 'MAPE_v':[], 'MAPE_v - MAPE_t':[]}\n","    for u in targetVars:\n","        best_xModels = {'xModelObj':None, 'eModelObj':None, 'modelNm':'??', \n","                           'MAPE_t':10**10, 'MAPE_v':10**10, 'MAPE_v - MAPE_t':10**10}\n","        for xModel in xModels:\n","            # print('***********', type(xModels[xModel]).__name__, u, end='\\n ')\n","            formalism = xModel#type(xModels[xModel]).__name__.replace('Classifier', '').replace('Classification', '')\n","            formalism += ('_'+u)\n","            # if eModel is not None:\n","            #     formalism += '_e'+type(eModel).__name__\n","            #     formalism = formalism.replace('Classifier', '')\n","            xTarget_t = x_t[0]['visit_month']; yTarget_t = x_tTransf[0]\n","            xTarget_v = x_t[3]['visit_month']; yTarget_v = x_tTransf[3]\n","            if not isWithPCA:\n","                xTarget_t = x_tTransf[0]['visit_month']; yTarget_t = x_tTransf[0][predVars]\n","                xTarget_v = x_tTransf[3]['visit_month']; yTarget_v = x_tTransf[3][predVars]\n","            yPred_t = xModels[xModel].predict(xTarget_t.values.reshape(-1, 1))\n","            yPred_v = xModels[xModel].predict(xTarget_v.values.reshape(-1, 1))\n","            MAPE_t = round(mean_absolute_percentage_error(y_true=yTarget_t, y_pred=yPred_t), 3)\n","            MAPE_v = round(mean_absolute_percentage_error(y_true=yTarget_v, y_pred=yPred_v), 3)\n","            dic['target'].append(u)\n","            dic['xModel'].append(formalism)\n","            dic['MAPE_t'].append(MAPE_t)\n","            dic['MAPE_v'].append(MAPE_v)\n","            diff = MAPE_v - MAPE_t\n","            dic['MAPE_v - MAPE_t'].append(diff)\n","            MAPE_vPlusDiff = MAPE_v + diff\n","            if MAPE_vPlusDiff < (best_xModels['MAPE_v'] + best_xModels['MAPE_v - MAPE_t']):\n","                best_xModels['modelNm'] = formalism\n","                best_xModels['xModelObj'] = xModels[xModel]\n","                best_xModels['MAPE_t'] = MAPE_t\n","                best_xModels['MAPE_v'] = MAPE_v\n","                best_xModels['MAPE_v - MAPE_t'] = diff\n","                # best_xModels['eModelObj'] = None\n","    print(\" *********** Best models via R2 in the validation set *********** \")\n","    lmodelNm = []; lMAPE_t = []; lMAPE_v = []; lMAPE_v_MAPE_t = []; \n","    for u in targetVars:\n","        lmodelNm.append(best_xModels['modelNm']); \n","        # lxModelObj.append(best_xModels['xModelObj']); \n","        lMAPE_t.append(best_xModels['MAPE_t']); \n","        lMAPE_v.append(best_xModels['MAPE_v']); \n","        lMAPE_v_MAPE_t.append(best_xModels['MAPE_v - MAPE_t']); \n","\n","    dfBest = pd.DataFrame({'modelNm': lmodelNm, 'MAPE_t':lMAPE_t, \n","                           'MAPE_v':lMAPE_v, 'MAPE_v - MAPE_t':lMAPE_v_MAPE_t}).sort_values(by=[\"MAPE_v\", 'MAPE_t', 'MAPE_v - MAPE_t'], ascending=False)\n","    display(dfBest)\n","    print(\" *********** All models via R2 in the validation set *********** \")\n","    dfAll = pd.DataFrame(dic).sort_values(by=[\"target\", \"MAPE_v\", 'MAPE_t', 'MAPE_v - MAPE_t'], ascending=True)\n","    display(dfAll)\n","\n","# rankPeptidesModels()"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"data":{"text/plain":["'6.23.1'"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["# %pip install -U ipykernel\n","import ipykernel\n","ipykernel.__version__"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:11.537356Z","iopub.status.busy":"2023-05-05T21:25:11.536959Z","iopub.status.idle":"2023-05-05T21:25:25.044207Z","shell.execute_reply":"2023-05-05T21:25:25.042287Z","shell.execute_reply.started":"2023-05-05T21:25:11.537323Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["*********** MyLinearRegressor: logLoss= 2.5711467767843095\n","*********** MyLogisticRegression: logLoss= 0.5501782681028398\n","*********** MySVC: logLoss= 0.6854392220344381\n","*********** MyLGBMClassifier: logLoss= 0.6548297738175496\n","*********** MyDecisionTreeClassifier: logLoss= 2.5437962170232455\n","*********** MyRandomForestClassifier: logLoss= 0.9098159258773078\n","*********** MyXGBClassifier: "]},{"name":"stdout","output_type":"stream","text":["logLoss= 0.6931471805599451\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAtAAAADlCAYAAAB6f8CrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+/0lEQVR4nO3dd1hU19o28HtmgKEoiEGaoiAY0YCiqNgJEUEsgSjGchKUKDmvXcAeFTVGEgv2cmKimJhEI1FyXguCRCwRNErssQbEBohBkCJl2N8ffuzXkVHZCA7K/buuuWDWfvaaZ+MID4u11pYJgiCAiIiIiIgqRa7tBIiIiIiIXicsoImIiIiIJGABTUREREQkAQtoIiIiIiIJWEATEREREUnAApqIiIiISAIW0EREREREErCAJiIiIiKSgAU0EREREZEELKCJiDSQyWSYN2+ettN44yUkJEAmkyEhIeG5cfPmzYNMJkNWVtarSawSKps7Eb15WEAT0SsVGRkJmUym9jA3N4eHhwf27dun7fRe2sWLFzFv3jykpqZqOxV6Cbt27YKPjw/MzMygp6cHa2trfPjhh/jtt9+0nRoR1QI62k6AiOqmBQsWwM7ODoIgICMjA5GRkejbty/+93//F/3799d2elV28eJFzJ8/H++++y5sbW21nQ5JJAgCPvnkE0RGRqJdu3YICQmBpaUl7t69i127dqFXr174/fff0bVrV22nSkRaxAKaiLTCx8cHHTp0EJ+PGjUKFhYW+Omnn17rAvpVKi0tRVlZGfT09LSdyhtj2bJliIyMxOTJkxEREQGZTCYe++yzz/D9999DR4c/OonqOk7hIKJaoUGDBjAwMKhQnOTn5yM0NBQ2NjZQKpVo2bIlli5dCkEQAACFhYVwdHSEo6MjCgsLxfP++ecfWFlZoWvXrlCpVACAkSNHol69evj777/h7e0NIyMjWFtbY8GCBWJ/z/Pnn3/Cx8cHxsbGqFevHnr16oWkpCTxeGRkJAYPHgwA8PDwEKeovGiO7I4dO9C6dWvo6+vDyckJu3btwsiRI9VGsFNTUyGTybB06VKsWLEC9vb2UCqVuHjxIgDgt99+Q48ePWBkZIQGDRrA19cXf/31l9rrPN1nufL5xU+SyWQYP348fvjhB7Rs2RL6+vpwdXXF4cOHK5x/+/ZtfPLJJ7CwsIBSqcQ777yDTZs2VYi7desW/Pz8YGRkBHNzcwQHB6OoqOi5X5unZWVl4cMPP4SxsTHeeustTJo0CY8ePRKPu7u7o23bthrPbdmyJby9vZ/Zd2FhIcLDw+Ho6IilS5dW+JoAwMcff4xOnTo9s48jR45g8ODBaNq0KZRKJWxsbBAcHKz23gSA9PR0BAYGokmTJlAqlbCysoKvr6/a1J+TJ0/C29sbZmZmMDAwgJ2dHT755JNnvjYRvTr8NZqItCInJwdZWVkQBAGZmZlYvXo18vLy8NFHH4kxgiDg/fffx8GDBzFq1Ci4uLhg//79mDp1Km7fvo3ly5fDwMAAW7ZsQbdu3fDZZ58hIiICADBu3Djk5OQgMjISCoVC7FOlUqFPnz7o3LkzFi9ejJiYGISFhaG0tBQLFix4Zr4XLlxAjx49YGxsjGnTpkFXVxf/+c9/8O677+LQoUNwc3NDz549MXHiRKxatQqzZs1Cq1atAED8qMmePXswZMgQODs7Izw8HNnZ2Rg1ahQaN26sMX7z5s149OgRPv30UyiVSjRs2BAHDhyAj48Pmjdvjnnz5qGwsBCrV69Gt27dkJycXOWpJIcOHcL27dsxceJEKJVKrFu3Dn369MGJEyfg5OQEAMjIyEDnzp3FgrtRo0bYt28fRo0ahdzcXEyePBnA4+K0V69eSEtLw8SJE2FtbY3vv/9e8pziDz/8ELa2tggPD0dSUhJWrVqF7OxsfPfddwAeF7hBQUE4f/68mCMA/PHHH7hy5Qpmz579zL6PHj2Kf/75B5MnT1Z7z0ixY8cOFBQUYMyYMXjrrbdw4sQJrF69Grdu3cKOHTvEuEGDBuHChQuYMGECbG1tkZmZibi4OKSlpYnPvby80KhRI8yYMQMNGjRAamoqdu7cWaW8iKiaCUREr9DmzZsFABUeSqVSiIyMVIuNjo4WAAgLFy5Ua/f39xdkMplw7do1sW3mzJmCXC4XDh8+LOzYsUMAIKxYsULtvBEjRggAhAkTJohtZWVlQr9+/QQ9PT3h3r17YjsAISwsTHzu5+cn6OnpCdevXxfb7ty5I9SvX1/o2bOn2Fb+2gcPHqzU18PZ2Vlo0qSJ8PDhQ7EtISFBACA0a9ZMbEtJSREACMbGxkJmZqZaHy4uLoK5ublw//59se3MmTOCXC4XAgIC1K7/yT7LhYWFCU//OCj/dzl58qTYduPGDUFfX1/44IMPxLZRo0YJVlZWQlZWltr5Q4cOFUxMTISCggJBEARhxYoVAgDh559/FmPy8/MFBweHSn29ynN8//331drHjh0rABDOnDkjCIIgPHjwQNDX1xemT5+uFjdx4kTByMhIyMvLe+ZrrFy5UgAg7Nq167m5lDt48GCF3Muv90nh4eGCTCYTbty4IQiCIGRnZwsAhCVLljyz7127dgkAhD/++KNSuRDRq8UpHESkFWvXrkVcXBzi4uKwdetWeHh4YPTo0WojbHv37oVCocDEiRPVzg0NDYUgCGq7dsybNw/vvPMORowYgbFjx8Ld3b3CeeXGjx8vfl4+clpcXIwDBw5ojFepVIiNjYWfnx+aN28utltZWWH48OE4evQocnNzJX8N7ty5g3PnziEgIAD16tUT293d3eHs7KzxnEGDBqFRo0bi87t37+L06dMYOXIkGjZsKLa3adMGvXv3xt69eyXnVa5Lly5wdXUVnzdt2hS+vr7Yv38/VCoVBEHAL7/8ggEDBkAQBGRlZYkPb29v5OTkIDk5GcDjf0srKyv4+/uL/RkaGuLTTz+VlNO4cePUnk+YMEHsHwBMTEzg6+uLn376SZyWo1KpsH37dnH6yLOU/xvWr19fUk5PMjAwED/Pz89HVlYWunbtCkEQ8Oeff4oxenp6SEhIQHZ2tsZ+GjRoAADYvXs3SkpKqpwPEdUMFtBEpBWdOnWCp6cnPD098a9//Qt79uxB69atxWIWAG7cuAFra+sKBU35lIgbN26IbXp6eti0aRNSUlLw8OFDbN68WeMcVrlcrlYEA8Dbb78NAM/ceu7evXsoKChAy5YtKxxr1aoVysrKcPPmzcpf/P9Xnr+Dg0OFY5raAMDOzk5jH8/KLSsrC/n5+ZJzA4AWLVpUaHv77bdRUFCAe/fu4d69e3jw4AG+/vprNGrUSO0RGBgIAMjMzBTzdHBwqPBvoilvKTnZ29tDLper/dsFBAQgLS0NR44cAQAcOHAAGRkZ+Pjjj5/bt7GxMQDg4cOHknJ6UlpamvjLTL169dCoUSO4u7sDeDxtCQCUSiW++uor7Nu3DxYWFujZsycWL16M9PR0sR93d3cMGjQI8+fPh5mZGXx9fbF582bJc8aJqGawgCaiWkEul8PDwwN3797F1atXq9TH/v37AQCPHj2qch+13ZMjnFJp+oUCgLjIUqqysjIAwEcffST+NeHpR7du3aqcb2VouiZvb29YWFhg69atAICtW7fC0tISnp6ez+3L0dERAHDu3Lkq5aJSqdC7d2/s2bMH06dPR3R0NOLi4hAZGQng/75eADB58mRcuXIF4eHh0NfXx5w5c9CqVStxlFomkyEqKgqJiYkYP368uFDT1dUVeXl5VcqPiKoPC2giqjVKS0sBQCwQmjVrhjt37lQYEbx06ZJ4vNzZs2exYMECBAYGol27dhg9erQ44veksrIy/P3332ptV65cAYBnLrZr1KgRDA0Ncfny5QrHLl26BLlcDhsbGwDPLlI1Kc//2rVrFY5panteH8/KzczMTJy2YGpqigcPHlSIe3Ik/0mafgm5cuUKDA0NxZHm+vXrQ6VSiX9NePphbm4u5nn9+vUKu51oyvt5ns7p2rVrKCsrU/u3UygUGD58OKKiopCdnY3o6GgMGzbshQsDu3fvDlNTU/z0009V+qXi3LlzuHLlCpYtW4bp06fD19cXnp6esLa21hhvb2+P0NBQxMbG4vz58yguLsayZcvUYjp37owvvvgCJ0+exA8//IALFy5g27ZtknMjourFApqIaoWSkhLExsZCT09PnKLRt29fqFQqrFmzRi12+fLlkMlk8PHxEc8dOXIkrK2tsXLlSkRGRiIjIwPBwcEaX+vJ/gRBwJo1a6Crq4tevXppjFcoFPDy8sKvv/6qNlUgIyMDP/74I7p37y7++b+8WNVUqD7N2toaTk5O+O6779RGFQ8dOlTpUVArKyu4uLhgy5Ytaq95/vx5xMbGom/fvmKbvb09cnJycPbsWbGt/AYhmiQmJopzmAHg5s2b+PXXX+Hl5QWFQgGFQoFBgwbhl19+wfnz5yucf+/ePfHzvn374s6dO4iKihLbCgoK8PXXX1fqOsutXbtW7fnq1asBQHwvlPv444+RnZ2Nf//73xV2d3kWQ0NDTJ8+HX/99RemT5+ucWvDrVu34sSJExrPLy/QnzxPEASsXLlSLa6goEBt6z3g8b9N/fr1xSka2dnZFV7fxcUFADiNg6gW4DZ2RKQV+/btE0eSMzMz8eOPP+Lq1auYMWOGWIwOGDAAHh4e+Oyzz5Camoq2bdsiNjYWv/76KyZPngx7e3sAwMKFC3H69GnEx8ejfv36aNOmDebOnYvZs2fD399frYjU19dHTEwMRowYATc3N+zbtw979uzBrFmz1BbnPW3hwoWIi4tD9+7dMXbsWOjo6OA///kPioqKsHjxYjHOxcUFCoUCX331FXJycqBUKvHee++JI7FPW7RoEXx9fdGtWzcEBgYiOzsba9asgZOTU6X/VL9kyRL4+PigS5cuGDVqlLiNnYmJCebNmyfGDR06FNOnT8cHH3yAiRMnoqCgAOvXr8fbb7+tViiXc3Jygre3t9o2dgAwf/58MebLL7/EwYMH4ebmhqCgILRu3Rr//PMPkpOTceDAAfzzzz8AgKCgIKxZswYBAQE4deoUrKys8P3338PQ0LBS11guJSUF77//Pvr06YPExERs3boVw4cPr7D3c7t27eDk5IQdO3agVatWaN++faX6nzp1Ki5cuIBly5bh4MGD8Pf3h6WlJdLT0xEdHY0TJ07g2LFjGs91dHSEvb09pkyZgtu3b8PY2Bi//PJLhYWCV65cQa9evfDhhx+idevW0NHRwa5du5CRkYGhQ4cCALZs2YJ169bhgw8+gL29PR4+fIiNGzfC2NhY7f1MRFqipd0/iKiO0rSNnb6+vuDi4iKsX79eKCsrU4t/+PChEBwcLFhbWwu6urpCixYthCVLlohxp06dEnR0dNS2phMEQSgtLRU6duwoWFtbC9nZ2YIgPN7GzcjISLh+/brg5eUlGBoaChYWFkJYWJigUqnUzsdT29gJgiAkJycL3t7eQr169QRDQ0PBw8NDOHbsWIVr3Lhxo9C8eXNBoVBUaou2bdu2CY6OjoJSqRScnJyE//73v8KgQYMER0dHMaZ8G7tnbX124MABoVu3boKBgYFgbGwsDBgwQLh48WKFuNjYWMHJyUnQ09MTWrZsKWzduvWZ29iNGzdO2Lp1q9CiRQtBqVQK7dq103gtGRkZwrhx4wQbGxtBV1dXsLS0FHr16iV8/fXXanE3btwQ3n//fcHQ0FAwMzMTJk2aJMTExEjaxu7ixYuCv7+/UL9+fcHU1FQYP368UFhYqPGcxYsXCwCERYsWPbdvTaKiogQvLy+hYcOGgo6OjmBlZSUMGTJESEhIEGM0bWN38eJFwdPTU6hXr55gZmYmBAUFCWfOnBEACJs3bxYEQRCysrKEcePGCY6OjoKRkZFgYmIiuLm5qW3xl5ycLAwbNkxo2rSpoFQqBXNzc6F///5q2woSkfbIBKESt98iInoDjBw5ElFRUa/FIiwXFxc0atQIcXFxWnl9mUyGcePGVZg+8zpZuXIlgoODkZqaiqZNm2o7HSJ6g3AKhwZlZWW4c+cO6tevL2lBEBHVbuX76VZlz+aaUlJSAplMpnYL8yNHjuDMmTOYPXu2VnMtLi6uVV8rKQRBwMaNG9G9e3c0aNDgtb0OInp1BEHAw4cPYW1tDbn8+csEOQKtwa1bt8QV9URERERUd9y8eRNNmjR5bgxHoDUov2nDzZs3xcVMRK9K+W4UXl5e0NXV1XY6b5QxY8bg119/xZ07d7SdiignJweTJk3C8ePHkZWVBUNDQ7i7u2PevHkVbvjyKpmYmCAoKAhLly7VWg5VcePGDbRp0wYmJiYYPXo05s6dq+2USAJ+/yNtys3NhY2NTaXuRqrVAvrw4cNYsmQJTp06JW6l5Ofn99xzEhISEBISggsXLsDGxgazZ8/GyJEj1WLWrl2LJUuWID09HW3btsXq1avRqVOnSudVPm3D2NiYBTS9ciUlJTA0NISxsTF/gFSzH374QdspVGBsbKx2+/La4nX946Szs/Nrmzvx+x/VDpWZvqvVfaDz8/PRtm3bCvt6PktKSgr69esHDw8PnD59GpMnT8bo0aPFu48BwPbt2xESEoKwsDAkJyejbdu28Pb2Fm8nS0RERET0MrQ6Au3j41Nh8/vn2bBhA+zs7MQ7NbVq1QpHjx7F8uXL4e3tDQCIiIhAUFAQAgMDxXP27NmDTZs2YcaMGdV/EURERERUp7xWdyJMTEyEp6enWpu3tzcSExMBPF4xfurUKbUYuVwOT09PMYaIiIiI6GW8VosI09PTYWFhodZmYWGB3NxcFBYWIjs7GyqVSmNM+R3PNCkqKlK7NWr5dkclJSXitldEr0r5e47vPSJ63RUUFODy5cuVjs8rLMKxc9dRv0ES6hkoK31ey5YtJd/VkuhpUn7uvlYFdE0JDw9XuzVtudjYWP6HJK3R1g00iIiqy/Xr1xEaGir5vMUS45ctWwZ7e3vJr0P0pIKCgkrHvlYFtKWlJTIyMtTaMjIyYGxsDAMDAygUCigUCo0xlpaWz+x35syZCAkJEZ+Xb2Pi5eXFXTjolSspKUFcXBx69+7NVehE9ForKChA9+7dKx1/5W4Opu66iCUftMbbViaVPo8j0FQdpNxw6bUqoLt06YK9e/eqtcXFxaFLly4AAD09Pbi6uiI+Pl7cDq+srAzx8fEYP378M/tVKpVQKiv+qUhXV5cFDGkN339E9LozMTGRtI2s3o37UCYWw8mlPVyavVWDmRFVJOVnrlYXEebl5eH06dM4ffo0gMfb1J0+fRppaWkAHo8MBwQEiPH/8z//g7///hvTpk3DpUuXsG7dOvz8888IDg4WY0JCQrBx40Zs2bIFf/31F8aMGYP8/HxxVw4iIiIiopeh1RHokydPwsPDQ3xePo1ixIgRiIyMxN27d8ViGgDs7OywZ88eBAcHY+XKlWjSpAm++eYbcQs7ABgyZAju3buHuXPnIj09HS4uLoiJiamwsJCIiIiIqCq0WkC/++67z71jVGRkpMZz/vzzz+f2O378+OdO2SAiIiIiqqrXah9oIiIiIiJtYwFNRERERCQBC2giIiIiIglYQBMRERERScACmoiIiIhIAhbQREREREQSsIAmIiIiIpKABTQRERERkQQsoImIiIiIJGABTVSLqFQqHDp0CIcPH8ahQ4egUqm0nRIRERE9hQU0US2xc+dOODg4oHfv3oiIiEDv3r3h4OCAnTt3ajs1IiIiegILaKJaYOfOnfD394ezszOOHDmCn376CUeOHIGzszP8/f1ZRBMREdUiLKCJtEylUiE0NBT9+/dHdHQ03NzcYGBgADc3N0RHR6N///6YMmUKp3MQERHVEiygibTsyJEjSE1NxaxZsyCXq/+XlMvlmDlzJlJSUnDkyBEtZUhERERPYgFNpGV3794FADg5OWk8Xt5eHkdERETaxQKaSMusrKwAAOfPn9d4vLy9PI6IiIi0iwU0kZb16NEDtra2WLRoEcrKytSOlZWVITw8HHZ2dujRo4eWMiQiIqInsYAm0jKFQoFly5Zh9+7d8PPzQ1JSEgoLC5GUlAQ/Pz/s3r0bS5cuhUKh0HaqREREBEBH2wkQETBw4EBERUUhNDQUPXv2FNvt7OwQFRWFgQMHajE7IiIiehILaKJaYuDAgfD19cXBgwexb98++Pj4wMPDgyPPREREtQwLaKJaRKFQwN3dHfn5+XB3d2fxTEREVAtxDjQRERERkQQsoImIiIiIJKgVBfTatWtha2sLfX19uLm54cSJE8+MfffddyGTySo8+vXrJ8aMHDmywvE+ffq8ikshIiIiojec1udAb9++HSEhIdiwYQPc3NywYsUKeHt74/LlyzA3N68Qv3PnThQXF4vP79+/j7Zt22Lw4MFqcX369MHmzZvF50qlsuYugoiIiIjqDK2PQEdERCAoKAiBgYFo3bo1NmzYAENDQ2zatEljfMOGDWFpaSk+4uLiYGhoWKGAViqVanGmpqav4nKIiIiI6A2n1QK6uLgYp06dgqenp9gml8vh6emJxMTESvXx7bffYujQoTAyMlJrT0hIgLm5OVq2bIkxY8bg/v371Zo7EREREdVNWp3CkZWVBZVKBQsLC7V2CwsLXLp06YXnnzhxAufPn8e3336r1t6nTx8MHDgQdnZ2uH79OmbNmgUfHx8kJiZq3BasqKgIRUVF4vPc3FwAQElJCUpKSqpyaURVVv6e43uPiOqa0tJS8SO/B9KrJuU9J6mALikpQZ8+fbBhwwa0aNFCcmLV7dtvv4WzszM6deqk1j506FDxc2dnZ7Rp0wb29vZISEhAr169KvQTHh6O+fPnV2iPjY2FoaFh9SdOVAlxcXHaToGI6JW6mQcAOkhKSsLt89rOhuqagoKCSsdKKqB1dXVx9uxZyQk9i5mZGRQKBTIyMtTaMzIyYGlp+dxz8/PzsW3bNixYsOCFr9O8eXOYmZnh2rVrGgvomTNnIiQkRHyem5sLGxsbeHl5wdjYuJJXQ1Q9SkpKEBcXh969e0NXV1fb6RARvTJn0v4Bzp1E586d0bZpQ22nQ3VM+QyEypA8heOjjz7Ct99+iy+//FLqqRXo6enB1dUV8fHx8PPzAwCUlZUhPj4e48ePf+65O3bsQFFRET766KMXvs6tW7dw//59WFlZaTyuVCo17tKhq6vLAoa0hu8/IqprdHR0xI/8/kevmpT3nOQCurS0FJs2bcKBAwfg6upaYfFeRESEpP5CQkIwYsQIdOjQAZ06dcKKFSuQn5+PwMBAAEBAQAAaN26M8PBwtfO+/fZb+Pn54a233lJrz8vLw/z58zFo0CBYWlri+vXrmDZtGhwcHODt7S31comIiIiI1EguoM+fP4/27dsDAK5cuaJ2TCaTSU5gyJAhuHfvHubOnYv09HS4uLggJiZGXFiYlpYGuVx9s5DLly/j6NGjiI2NrdCfQqHA2bNnsWXLFjx48ADW1tbw8vLC559/zr2giYiIiOilSS6gDx48WO1JjB8//plTNhISEiq0tWzZEoIgaIw3MDDA/v37qzM9IiIiIiKR1u9ESERERK+PlKx85BeV1kjf1+/lix/L50NXNyOlDuzMjF4cSPQcVXp3njx5Ej///DPS0tLUbqsNPL7VNhEREb15UrLy4bE0ocZfJzTqXI32f3DKuyyi6aVILqC3bduGgIAAeHt7IzY2Fl5eXrhy5QoyMjLwwQcf1ESOREREVAuUjzyvGOICB/N61d9/YRF2JySi/7tdYGRQ/euWrmXmYfL20zU2gk51h+QCetGiRVi+fDnGjRuH+vXrY+XKlbCzs8O///3vZ24TR0RERG8OB/N6cGpsUu39lpSUIL0R0L6ZKbexo1pN/uIQddevX0e/fv0APN7HOT8/HzKZDMHBwfj666+rPUEiIiIiotpEcgFtamqKhw8fAgAaN26M8+cf32vzwYMHkm6BSEQVqVQqHDp0CIcPH8ahQ4egUqm0nRIRERE9RXIB3bNnT8TFxQEABg8ejEmTJiEoKAjDhg3TeJtsIqqcnTt3wsHBAb1790ZERAR69+4NBwcHLswlIiKqZSTPgV6zZg0ePXoEAPjss8+gq6uLY8eOYdCgQZg9e3a1J0hUF+zcuRP+/v7o378/vv/+e9y6dQtNmjTB4sWL4e/vj6ioKAwcOFDbaRIRERGqUEA3bNhQ/Fwul2PGjBnVmhBRXaNSqRAaGor+/fsjOjoaKpUK9+/fh5ubG6Kjo+Hn54cpU6bA19cXCoVC2+kSERHVeZKncACPFxLOnj0bw4YNQ2ZmJgBg3759uHDhQrUmR1QXHDlyBKmpqZg1a1aF29bL5XLMnDkTKSkpOHLkiJYyJCIioidJLqAPHToEZ2dnHD9+HDt37kReXh4A4MyZMwgLC6v2BInedHfv3gUAODk5aTxe3l4eR0RERNoluYCeMWMGFi5ciLi4OOjp6Ynt7733HpKSkqo1OaK6oHz/9PIdbZ5W3s591omIiGoHyQX0uXPnNN5x0NzcHFlZWdWSFFFd0qNHD9ja2mLRokUoKytTO1ZWVobw8HDY2dmhR48eWsqQiIiIniS5gG7QoIHGPyX/+eefaNy4cbUkRVSXKBQKLFu2DLt374afnx+SkpJQWFiIpKQk+Pn5Yffu3Vi6dCkXEBIREdUSknfhGDp0KKZPn44dO3ZAJpOhrKwMv//+O6ZMmYKAgICayJHojTdw4EBERUUhNDQUPXv2FNvt7Oy4hR0REVEtI7mAXrRoEcaNGwcbGxuoVCq0bt0aKpUKw4cP5z7QRC9h4MCB8PX1xcGDB7Fv3z74+PjAw8ODI89ERES1jOQCWk9PDxs3bsScOXNw/vx55OXloV27dmjRokVN5EdUpygUCri7uyM/Px/u7u4snomIiGohyQV0uaZNm6Jp06bVmQsRERERUa0nuYBWqVSIjIxEfHw8MjMzK+wa8Ntvv1VbckR1jUqlwqFDh3D48GEYGRlxCgcREVEtJLmAnjRpEiIjI9GvXz84OTlBJpPVRF5Edc7OnTsRGhqK1NRUAEBERARsbW2xbNkyLiIkIiKqRSQX0Nu2bcPPP/+Mvn371kQ+RHXSzp074e/vj/79++P777/HrVu30KRJEyxevBj+/v7ciYOIiKgWkbwPtJ6eHhwcHGoiF6I6SaVSITQ0FP3790d0dDTc3NxgYGAANzc3REdHo3///pgyZQpUKpW2UyUiIiJUoYAODQ3FypUrIQhCTeRDVOccOXIEqampmDVrFuRy9f+ScrkcM2fOREpKCo4cOaKlDImIiOhJkgvoo0eP4ocffoC9vT0GDBiAgQMHqj2qYu3atbC1tYW+vj7c3Nxw4sSJZ8ZGRkZCJpOpPfT19dViBEHA3LlzYWVlBQMDA3h6euLq1atVyo2oppXf2dPJyUnj8fJ2TXcAJSIiolevSrfy/uCDD+Du7g4zMzOYmJioPaTavn07QkJCEBYWhuTkZLRt2xbe3t7IzMx85jnGxsa4e/eu+Lhx44ba8cWLF2PVqlXYsGEDjh8/DiMjI3h7e+PRo0eS8yOqaVZWVgCA8+fPq+3CcejQIahUKpw/f14tjoiIiLRL8iLCzZs3V2sCERERCAoKQmBgIABgw4YN2LNnDzZt2oQZM2ZoPEcmk8HS0lLjMUEQsGLFCsyePRu+vr4AgO+++w4WFhaIjo7G0KFDqzV/opfVo0cP2NraYsKECcjKyqqwC4eZmRns7OzQo0cP7SZKREREAKowAl2diouLcerUKXh6eoptcrkcnp6eSExMfOZ5eXl5aNasGWxsbODr64sLFy6Ix1JSUpCenq7Wp4mJCdzc3J7bJ5G2KBQKDB48GCdPnkRhYSHWr1+PzZs3Y/369SgsLMTJkyfh7+/P/aCJiIhqiUqNQLdv3x7x8fEwNTVFu3btnrv3c3JycqVfPCsrCyqVChYWFmrtFhYWuHTpksZzWrZsiU2bNqFNmzbIycnB0qVL0bVrV1y4cAFNmjRBenq62MfTfZYfe1pRURGKiorE57m5uQCAkpISlJSUVPp6iKpCpVJhx44dcHV1RVZWFsaMGSMes7W1haurK6KiorBgwQIW0USkVaWlpeLHmvj5WN5nTf3sren86fUm5T1RqQLa19cXSqUSAODn51elpKpLly5d0KVLF/F5165d0apVK/znP//B559/XqU+w8PDMX/+/ArtsbGxMDQ0rHKuRJVx7tw5pKamYsyYMXBwcMDFixeRnZ0NU1NTtG7dGlevXsWMGTOwdOlSODs7aztdIqrDbuYBgA6OHj2KG/Vq7nXi4uJqpN9XlT+9ngoKCiodW6kCOiwsTOPnTyotLX3uwj9NzMzMoFAokJGRodaekZHxzDnOT9PV1UW7du1w7do1ABDPy8jIUFt0lZGRARcXF419zJw5EyEhIeLz3Nxc2NjYwMvLC8bGxlIuiUiy8r94BAUFoV69eujTpw/i4uLQu3dv6Orq4uHDh5gxYwaaNWvGGxgRkVYl38yE/OoeNGnrDLtGRtXef2lpKY4nHYdbZzfo6EhepvVCwr18yK+eQ8cu/dDexrza+6fXW/nP48qotnfnhQsX0L59e0k3e9DT04Orqyvi4+PFke2ysjLEx8dj/PjxlepDpVLh3LlzYmFhZ2cHS0tLxMfHiwVzbm4ujh8/rvan8ScplUpxhP1Jurq60NXVrfT1EFWFjY0NAODy5cvo3Lmz2F7+/rt8+bIYx/cjEWlTZtFtGNmtxpxTNfs66w6sq7G+jeyAzCIX6Oo2rrHXoNeTlJ+x1f/rnUQhISEYMWIEOnTogE6dOmHFihXIz88Xd+UICAhA48aNER4eDgBYsGABOnfuDAcHBzx48ABLlizBjRs3MHr0aACPd+iYPHkyFi5ciBYtWsDOzg5z5syBtbW11qefEGlSvgvHokWLEB0drXasrKwM4eHh3IWDiGoFa6NmyE+ZgJVDXGBvXv1zIEpLS/H70d/RrXu3GhmBvp6Zh0nbT8Pao1m19011i9YL6CFDhuDevXuYO3cu0tPT4eLigpiYGHERYFpamtrd2bKzsxEUFIT09HSYmprC1dUVx44dQ+vWrcWYadOmIT8/H59++ikePHiA7t27IyYmpsINV4hqA4VCgWXLlsHf3x9+fn6YOnUqCgsLkZSUhCVLlmD37t2IioriAkIi0jqlQh9ljxrDzrglWr8l/d4PL1JSUoIUnRS0atiqRv7iVvYoB2WP7kGpYD1AL0cmVNM9uc+cOSN5CkdtlZubCxMTE+Tk5HAONL0yO3fuRHBwMNLS0sS2Zs2aISIiosp3+SQiqk7nb+eg/+qj2D2hO5wa10wBvXfvXvTt27dGCuiazp9eb1Lqv0qPQJ89e/a5x8vnaRJR1SQlJeHOnTtqbbdv30ZSUhILaCIiolqk0gW0i4sLZDIZNA1Yl7c/b39oInq2adOmYcmSJbCwsMD8+fOhVCpRVFSEsLAwLFmyBMDjW9QTERGR9lW6gE5JSanJPIjqrOLiYixfvhwWFha4desWBEEQ/4Q5atQoNGnSBMuXL8fChQuhp6en7XSJiIjqvEoX0M2accUqUU1Yt24dSktLsXDhQujo6KjdCUlHRwcLFizAv//9b6xbtw6TJ0/WXqJEREQEAJC/OESdra0tFixYoLbQiYiq7vr16wCA/v37o7i4GKtWrcLXX3+NVatWobi4GP3791eLIyIiIu2SXEBPnjwZO3fuRPPmzdG7d29s27YNRUVFNZEbUZ1gb28PABg5ciSMjIwwZcoU7N27F1OmTIGRkRFGjhypFkdERETaVaUC+vTp0zhx4gRatWqFCRMmwMrKCuPHj0dycnJN5Ej0Rhs7dixkMhn279+Phg0bYsOGDdi8eTM2bNiAhg0bIi4uDjKZDGPHjtV2qkRERIQqFNDl2rdvj1WrVuHOnTsICwvDN998g44dO8LFxQWbNm3SuFsHEb1YWVkZBEFAWVmZtlMhIiIiDap8J8KSkhLs2rULmzdvRlxcHDp37oxRo0bh1q1bmDVrFg4cOIAff/yxOnMleiOtW7cOgiDA29sb8fHxaiPNOjo68PLyQmxsLBcREhER1RKSC+jk5GRs3rwZP/30E+RyOQICArB8+XI4OjqKMR988AE6duxYrYkSvanKFwdGRkaiYcOGWL16NX777Te89957mDBhArKystC4cWMuIiQiIqolJBfQHTt2RO/evbF+/Xr4+flpvNWmnZ0dhg4dWi0JEr3pyhcH7t69G6NHj8bEiRPh4OAg3sp29+7danFERESkXZLnQP/999+IiYnB4MGDn3mfeiMjI2zevPmlkyOqC8aOHQsdHR3Mnj0bRUVFOHToEA4fPoxDhw6hqKgIc+fOhY6ODhcREhER1RKSR6B5QxWi6qWnp4fg4GAsWbIEhoaG4uLBiIgIyOVylJWVYerUqbwLIRFpXWGJCgBw/nZOjfSfX1iEk/cAyxvZMDJQVnv/1zLzqr1PqpsqXUA3b968UnF///13lZMhqqs6d+4MABV23ih/Xn6ciEibrv//AnTGznM1+Co6+P7aHzXYP2CkrPIeCkQAJBTQqampaNasGYYPHw5zc/OazImoTlGpVAgMDAQAyGQytS0gy58HBgbC19cXCoVCW2kSEcHrHUsAgL15PRjoVv/3o8t3cxAadQ7L/J3R0sqk2vsHHhfPdmZGNdI31R2VLqC3b9+OTZs2ISIiAj4+Pvjkk0/Qt29fyOVV3kqaiADEx8cjNzcXANCvXz9Mnz4dt27dQpMmTfDVV19h9+7dyM3NRXx8PLy8vLScLRHVZQ2N9DC0U9Ma67+0tBQAYN/ICE6Na6aAJqoOla5+Bw8ejH379uHatWtwdXVFcHAwbGxsMGPGDFy9erUmcyR6o23ZsgUA4OTkhF9//RVubm4wMDCAm5sbfv31Vzg5OanFERERkXZJHj5u3LgxPvvsM1y9ehU//vgjjh8/DkdHR2RnZ9dEfkRvvBs3bgAARo4cCUEQ1HbhEAQBH3/8sVocERERaVeVZtE/evQIUVFR2LRpE44fP47BgwfD0NCwunMjqhNsbW3x+++/Y+XKlVizZg1SU1MBPN6Fw9bWFiqVSowjIiIi7ZNUQB8/fhzffvstfv75ZzRv3hyffPIJfvnlF5iamtZUfkRvvBEjRuCHH37AzZs30ahRI6xfvx76+vp49OgR5s6di3v37olxREREpH2VLqDfeecdZGZmYvjw4Th06BDatm1bk3kR1Rnu7u7ibhtZWVkYM2aMeEwmk4kf3d3dtZUiERERPaHSc6D/+usvPHr0CN999x08PDzQsGFDjQ8ikubYsWPi1nVPbmH3JEEQcOzYsVeZFhERET1DpUegeWtuoppx9+5dAMCkSZOwZs0acc4zAMjlcowfPx4rV64U44iIiEi7Kl1Al8+/HDFiBEaNGoWePXvWWFJEdYmVlRUAYNWqVejXrx+8vLxw5coVvP3224iNjcWqVavU4oiIiEi7JG9jl5OTA09PT7Ro0QKLFi3CnTt3XjqJtWvXwtbWFvr6+nBzc8OJEyeeGbtx40b06NEDpqamMDU1haenZ4X4kSNHQiaTqT369Onz0nkS1YSuXbtCR0cH5ubmiIqKQqtWraCnp4dWrVohKioK5ubm0NHRQdeuXbWdKhEREaEKBXR0dDRu376NMWPGYPv27WjWrBl8fHywY8cOlJSUSE5g+/btCAkJQVhYGJKTk9G2bVt4e3sjMzNTY3xCQgKGDRuGgwcPIjExETY2NvDy8sLt27fV4vr06YO7d++Kj59++klybkSvwrFjx1BaWoqMjAyYmpqid+/eiIiIQO/evWFqaoqMjAyUlpZyDjQREVEtUaX7cDdq1AghISE4c+YMjh8/DgcHBwQEBMDa2hrBwcGS7kwYERGBoKAgBAYGonXr1tiwYQMMDQ2xadMmjfE//PADxo4dCxcXFzg6OuKbb75BWVkZ4uPj1eKUSiUsLS3FB7fao9rqybnNhYWFaseefM450ERERLVDlW6kUu7u3buIi4tDXFwcFAoF+vbti3PnzqF169ZYvHgxgoODn3t+cXExTp06hZkzZ4ptcrkcnp6eSExMrFQOBQUFKCkpqbADSEJCAszNzWFqaor33nsPCxcuxFtvvaWxj6KiIhQVFYnPc3NzAQAlJSVVGlUnkqKyu9c0bNiQ70cieqOVlpaKH/n9jl41Ke85yQV0SUkJ/vvf/2Lz5s2IjY1FmzZtMHnyZAwfPhzGxsYAgF27duGTTz55YQGdlZUFlUoFCwsLtXYLCwtcunSpUvlMnz4d1tbW8PT0FNv69OmDgQMHws7ODtevX8esWbPg4+ODxMREKBSKCn2Eh4dj/vz5FdpjY2N5h0WqcSdPnhQ/L98PWtPzo0eP4tGjR688PyKiV+VmHgDoICkpCbfPazsbqmsKCgoqHSu5gLayskJZWRmGDRuGEydOwMXFpUKMh4cHGjRoILVryb788kts27YNCQkJ0NfXF9uHDh0qfu7s7Iw2bdrA3t4eCQkJ6NWrV4V+Zs6ciZCQEPF5bm6uOLe6/JcCopqycuXKSsX9/vvvmDt3bg1nQ0SkPWfS/gHOnUTnzp3RtinvLUGvVvkMhMqQXEAvX74cgwcPVitYn9agQQOkpKS8sC8zMzMoFApkZGSotWdkZMDS0vK55y5duhRffvklDhw4gDZt2jw3tnnz5jAzM8O1a9c0FtBKpRJKpbJCu66uLnR1dV94HUQv48k1A/r6+mrznp98fvXqVb4fieiNpqOjI37k9zt61aS85yQvIvz444+fWzxLoaenB1dXV7UFgOULArt06fLM8xYvXozPP/8cMTEx6NChwwtf59atW7h//z730aVaqXxakVKpRHZ2NuLi4hASEoK4uDhkZ2eLv9xpmn5EREREr16VduGoTiEhIdi4cSO2bNmCv/76C2PGjEF+fj4CAwMBAAEBAWqLDL/66ivMmTMHmzZtgq2tLdLT05Geno68vDwAQF5eHqZOnYqkpCSkpqYiPj4evr6+cHBwgLe3t1aukeh57O3tATxezDpo0CAolUp07NgRSqUSgwYNEhe4lscRERGRdr3ULhzVYciQIbh37x7mzp2L9PR0uLi4ICYmRlxYmJaWBrn8/+r89evXo7i4GP7+/mr9hIWFYd68eVAoFDh79iy2bNmCBw8ewNraGl5eXvj88881TtMgqmkFBQXPXRTbtGlT8fM9e/Zgz549z4xLTk5+Zj+Ojo5c9EpERPQKyIQnl/wTgMeTyE1MTJCTk8NFhPTSkpOT4erqWuOvc+rUKbRv377GX4eIqKacvnEffuuTED2mM1yaad56lqimSKn/tD4CTfSmc3R0xKlTp555XKVSwdvbG9nZ2c+MadiwIWJiYp47D9rR0fGl8iQiIqLKYQFNVMMMDQ1fODL8zTffwN/fH0qlUm2vZwMDAzx69AgbN25Ex44dazpVIiIiqgStLyIkImDgwIGIioqqsH2jpaUloqKiMHDgQC1lRkRERE9jAU1USwwcOBDXrl3Dxp+iYTZgKjb+FI2rV6+yeCYiIqplOIWDqBZRKBTo0KU7jE7roEOXztz7mYiIqBbiCDQRERERkQQsoImIiIiIJGABTUREREQkAQtoIiIiIiIJWEATEREREUnAApqIiIiISAIW0EREREREErCAJiIiIiKSgAU0EREREZEELKCJiIiIiCTgrbyJqiAlKx/5RaU10vf1e/niRx2dmvkvaqTUgZ2ZUY30TURE9KZjAU0kUUpWPjyWJtT464RGnavR/g9OeZdFNBERURWwgCaSqHzkecUQFziY16v+/guLsDshEf3f7QIjA2W1938tMw+Tt5+usRF0IiKiNx0LaKIqcjCvB6fGJtXeb0lJCdIbAe2bmUJXV7fa+yciIqKXw0WEREREREQSsIAmIiIiIpKABTQRERERkQQsoImIiIiIJKgVBfTatWtha2sLfX19uLm54cSJE8+N37FjBxwdHaGvrw9nZ2fs3btX7bggCJg7dy6srKxgYGAAT09PXL16tSYvgYiIiIjqCK0X0Nu3b0dISAjCwsKQnJyMtm3bwtvbG5mZmRrjjx07hmHDhmHUqFH4888/4efnBz8/P5w/f16MWbx4MVatWoUNGzbg+PHjMDIygre3Nx49evSqLouIiIiI3lBaL6AjIiIQFBSEwMBAtG7dGhs2bIChoSE2bdqkMX7lypXo06cPpk6dilatWuHzzz9H+/btsWbNGgCPR59XrFiB2bNnw9fXF23atMF3332HO3fuIDo6+hVeGRERERG9ibS6D3RxcTFOnTqFmTNnim1yuRyenp5ITEzUeE5iYiJCQkLU2ry9vcXiOCUlBenp6fD09BSPm5iYwM3NDYmJiRg6dGiFPouKilBUVCQ+z83NBfB4P96SkpIqXx+9mbLyciDXv439V/7AtewX38nvUdEj3L2VVun+VaVluHbtKq6W/gOFTuV/x7Vq0hT6Sv0Xxt3MLoRc/zbyi/JQUmJY6f6JiKQqKCjA5cuXKx1/5W4OitKv4fxpPRRnVH6f/ZYtW8LQkN/P6OVIqfm0WkBnZWVBpVLBwsJCrd3CwgKXLl3SeE56errG+PT0dPF4eduzYp4WHh6O+fPnV2iPjY3lf0iqICbzDozs1iEyDUDl62JpLIHf8ySe86DyoUZ2wIEkFdLPWUt8ESKiyrt+/TpCQ0Mln/fxFmnxy5Ytg729veTXIXpSQUFBpWN5J0IAM2fOVBvVzs3NhY2NDby8vGBsbKzFzKg2csnJRdS5Fmhsqg99HcUL46s6Au3g0KJGRqABQF9Pjq42rWCgY1Dp/omIpCooKED37t0rHZ9XWIT9R/6Ad4+OqGegrPR5HIGm6lA+A6EytFpAm5mZQaFQICMjQ609IyMDlpaWGs+xtLR8bnz5x4yMDFhZWanFuLi4aOxTqVRCqaz4H1VXV5e3UqYKmpm9hVAPzxcHPsm18qElJSXYu3cv+vbty/cfEb3WTExM0KlTp0rHl5SU4OGDf9Cja2d+/6NXTsp7TquLCPX09ODq6or4+HixraysDPHx8ejSpYvGc7p06aIWDwBxcXFivJ2dHSwtLdVicnNzcfz48Wf2SURERERUWVqfwhESEoIRI0agQ4cO6NSpE1asWIH8/HwEBgYCAAICAtC4cWOEh4cDACZNmgR3d3csW7YM/fr1w7Zt23Dy5El8/fXXAACZTIbJkydj4cKFaNGiBezs7DBnzhxYW1vDz89PW5dJRERERG8IrRfQQ4YMwb179zB37lykp6fDxcUFMTEx4iLAtLQ0yOX/N1DetWtX/Pjjj5g9ezZmzZqFFi1aIDo6Gk5OTmLMtGnTkJ+fj08//RQPHjxA9+7dERMTA339ys0PJSIiIiJ6FpkgCIK2k6htcnJy0KBBA9y8eZOLCOmVKykpQWxsLLy8vDgHkIjqFH7/I20q30TiwYMHMDF5/jaKWh+Bro0ePnwIALCxsdFyJkRERET0Kj18+PCFBTRHoDUoKyvDnTt3UL9+fchkMm2nQ3VM+W/A/AsIEdU1/P5H2iQIAh4+fAhra2u16cOacARaA7lcjiZNmmg7DarjjI2N+QOEiOokfv8jbXnRyHM5rW5jR0RERET0umEBTUREREQkAQtoolpGqVQiLCxM490xiYjeZPz+R68LLiIkIiIiIpKAI9BERERERBKwgCYiIiIikoAFNBERERGRBCygiYiIiIgkYAFNVMusXbsWtra20NfXh5ubG06cOKHtlIiIatThw4cxYMAAWFtbQyaTITo6WtspET0XC2iiWmT79u0ICQlBWFgYkpOT0bZtW3h7eyMzM1PbqRER1Zj8/Hy0bdsWa9eu1XYqRJXCbeyIahE3Nzd07NgRa9asAQCUlZXBxsYGEyZMwIwZM7ScHRFRzZPJZNi1axf8/Py0nQrRM3EEmqiWKC4uxqlTp+Dp6Sm2yeVyeHp6IjExUYuZERER0ZNYQBPVEllZWVCpVLCwsFBrt7CwQHp6upayIiIioqexgCYiIiIikoAFNFEtYWZmBoVCgYyMDLX2jIwMWFpaaikrIiIiehoLaKJaQk9PD66uroiPjxfbysrKEB8fjy5dumgxMyIiInqSjrYTIKL/ExISghEjRqBDhw7o1KkTVqxYgfz8fAQGBmo7NSKiGpOXl4dr166Jz1NSUnD69Gk0bNgQTZs21WJmRJpxGzuiWmbNmjVYsmQJ0tPT4eLiglWrVsHNzU3baRER1ZiEhAR4eHhUaB8xYgQiIyNffUJEL8ACmoiIiIhIAs6BJiIiIiKSgAU0EREREZEELKCJiIiIiCRgAU1EREREJAELaCIiIiIiCVhAExERERFJwAKaiIiIiEgCFtBERHWQTCZDdHS0ttMgInotsYAmInoDpaenY8KECWjevDmUSiVsbGwwYMAAxMfHazs1IqLXno62EyAiouqVmpqKbt26oUGDBliyZAmcnZ1RUlKC/fv3Y9y4cbh06ZK2UyQieq1xBJqI6A0zduxYyGQynDhxAoMGDcLbb7+Nd955ByEhIUhKStJ4zvTp0/H222/D0NAQzZs3x5w5c1BSUiIeP3PmDDw8PFC/fn0YGxvD1dUVJ0+eBADcuHEDAwYMgKmpKYyMjPDOO+9g7969r+RaiYi0gSPQRERvkH/++QcxMTH44osvYGRkVOF4gwYNNJ5Xv359REZGwtraGufOnUNQUBDq16+PadOmAQD+9a9/oV27dli/fj0UCgVOnz4NXV1dAMC4ceNQXFyMw4cPw8jICBcvXkS9evVq7BqJiLSNBTQR0Rvk2rVrEAQBjo6Oks6bPXu2+LmtrS2mTJmCbdu2iQV0Wloapk6dKvbbokULMT4tLQ2DBg2Cs7MzAKB58+YvexlERLUap3AQEb1BBEGo0nnbt29Ht27dYGlpiXr16mH27NlIS0sTj4eEhGD06NHw9PTEl19+ievXr4vHJk6ciIULF6Jbt24ICwvD2bNnX/o6iIhqMxbQRERvkBYtWkAmk0laKJiYmIh//etf6Nu3L3bv3o0///wTn332GYqLi8WYefPm4cKFC+jXrx9+++03tG7dGrt27QIAjB49Gn///Tc+/vhjnDt3Dh06dMDq1aur/dqIiGoLmVDV4QoiIqqVfHx8cO7cOVy+fLnCPOgHDx6gQYMGkMlk2LVrF/z8/LBs2TKsW7dObVR59OjRiIqKwoMHDzS+xrBhw5Cfn4///ve/FY7NnDkTe/bs4Ug0Eb2xOAJNRPSGWbt2LVQqFTp16oRffvkFV69exV9//YVVq1ahS5cuFeJbtGiBtLQ0bNu2DdevX8eqVavE0WUAKCwsxPjx45GQkIAbN27g999/xx9//IFWrVoBACZPnoz9+/cjJSUFycnJOHjwoHiMiOhNxEWERERvmObNmyM5ORlffPEFQkNDcffuXTRq1Aiurq5Yv359hfj3338fwcHBGD9+PIqKitCvXz/MmTMH8+bNAwAoFArcv38fAQEByMjIgJmZGQYOHIj58+cDAFQqFcaNG4dbt27B2NgYffr0wfLly1/lJRMRvVKcwkFEREREJAGncBARERERScACmoiIiIhIAhbQREREREQSsIAmIiIiIpKABTQRERERkQQsoImIiIiIJGABTUREREQkAQtoIiIiIiIJWEATEREREUnAApqIiIiISAIW0EREREREErCAJiIiIiKS4P8BkFbaowmnXW0AAAAASUVORK5CYII=","text/plain":["<Figure size 800x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 800x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAtAAAADlCAYAAAB6f8CrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA83UlEQVR4nO3dd1gU1/4/8PeywFIUUJGmqIAFO4qC2IkUISZiiyWxa35XxYZGxRhRYySxxxK9MVFMTJTYyL0WBFEsCWqEmGCNIIJKURRBirAs8/sjl/m6sphdZF3E9+t59oE5c+bsZ2DY/XD2nDMSQRAEEBERERGRWvR0HQARERER0euECTQRERERkQaYQBMRERERaYAJNBERERGRBphAExERERFpgAk0EREREZEGmEATEREREWmACTQRERERkQaYQBMRERERaYAJNBGRChKJBEuWLNF1GLVebGwsJBIJYmNjX1hvyZIlkEgkyM7OfjWBqUHd2Imo9mECTUSvVFhYGCQSidLDysoKnp6eOHr0qK7De2lXr17FkiVLcPv2bV2HQi/h4MGD8PPzg6WlJQwNDWFnZ4f33nsPJ06c0HVoRFQD6Os6ACJ6My1btgwODg4QBAFZWVkICwuDv78//vvf/2LAgAG6Dq/Krl69iqVLl6Jv375o1qyZrsMhDQmCgAkTJiAsLAydOnVCUFAQbGxskJGRgYMHD6Jfv3745Zdf0L17d12HSkQ6xASaiHTCz88PXbp0EbcnTpwIa2tr7N69+7VOoF+l0tJSlJWVwdDQUNeh1Bpr1qxBWFgYZs2ahbVr10IikYj7Pv74Y3z//ffQ1+dbJ9GbjkM4iKhGsLCwgLGxcYXkpKCgAHPmzIG9vT1kMhlatWqF1atXQxAEAEBRURGcnZ3h7OyMoqIi8bhHjx7B1tYW3bt3h0KhAACMGzcOderUwa1bt+Dr6wtTU1PY2dlh2bJlYnsv8vvvv8PPzw9mZmaoU6cO+vXrh3Pnzon7w8LCMGzYMACAp6enOETln8bI7t27F23atIGRkRHatWuHgwcPYty4cUo92Ldv34ZEIsHq1auxfv16ODk5QSaT4erVqwCAEydOoFevXjA1NYWFhQUGDhyIa9euKT3P822WKx9f/CyJRILAwED88MMPaNWqFYyMjODq6orTp09XOP7evXuYMGECrK2tIZPJ0LZtW2zfvr1Cvbt37yIgIACmpqawsrLC7NmzUVxc/MKfzfOys7Px3nvvwczMDA0aNMDMmTPx9OlTcX+fPn3QsWNHlce2atUKvr6+lbZdVFSE0NBQODs7Y/Xq1RV+JgAwevRouLm5VdrGmTNnMGzYMDRp0gQymQz29vaYPXu20rUJAJmZmRg/fjwaN24MmUwGW1tbDBw4UGnoz8WLF+Hr6wtLS0sYGxvDwcEBEyZMqPS5iejV4b/RRKQTubm5yM7OhiAIuH//PjZu3Ij8/Hx88MEHYh1BEPDuu+/i5MmTmDhxIlxcXHDs2DF89NFHuHfvHtatWwdjY2Ps3LkTPXr0wMcff4y1a9cCAKZNm4bc3FyEhYVBKpWKbSoUCvTv3x/dunXDypUrERkZiZCQEJSWlmLZsmWVxnvlyhX06tULZmZmmDdvHgwMDPDvf/8bffv2xalTp+Du7o7evXtjxowZ2LBhAxYuXIjWrVsDgPhVlcOHD2P48OFo3749QkNDkZOTg4kTJ6JRo0Yq6+/YsQNPnz7Fhx9+CJlMhvr16+P48ePw8/ODo6MjlixZgqKiImzcuBE9evRAQkJClYeSnDp1CuHh4ZgxYwZkMhm++uor9O/fHxcuXEC7du0AAFlZWejWrZuYcDds2BBHjx7FxIkTkZeXh1mzZgH4Oznt168f0tLSMGPGDNjZ2eH777/XeEzxe++9h2bNmiE0NBTnzp3Dhg0bkJOTg++++w7A3wnu5MmTcfnyZTFGAPjtt9/w119/YdGiRZW2ffbsWTx69AizZs1SumY0sXfvXhQWFmLKlClo0KABLly4gI0bN+Lu3bvYu3evWG/IkCG4cuUKpk+fjmbNmuH+/fuIjo5GWlqauO3j44OGDRtiwYIFsLCwwO3bt3HgwIEqxUVE1UwgInqFduzYIQCo8JDJZEJYWJhS3YiICAGAsHz5cqXyoUOHChKJREhKShLLgoODBT09PeH06dPC3r17BQDC+vXrlY4bO3asAECYPn26WFZWVia8/fbbgqGhofDgwQOxHIAQEhIibgcEBAiGhoZCcnKyWJaeni7UrVtX6N27t1hW/twnT55U6+fRvn17oXHjxsKTJ0/EstjYWAGA0LRpU7EsJSVFACCYmZkJ9+/fV2rDxcVFsLKyEh4+fCiW/fHHH4Kenp4wZswYpfN/ts1yISEhwvNvB+W/l4sXL4plqampgpGRkTBo0CCxbOLEiYKtra2QnZ2tdPyIESMEc3NzobCwUBAEQVi/fr0AQPjpp5/EOgUFBULz5s3V+nmVx/juu+8qlU+dOlUAIPzxxx+CIAjC48ePBSMjI2H+/PlK9WbMmCGYmpoK+fn5lT7Hl19+KQAQDh48+MJYyp08ebJC7OXn+6zQ0FBBIpEIqampgiAIQk5OjgBAWLVqVaVtHzx4UAAg/Pbbb2rFQkSvFodwEJFObN68GdHR0YiOjsauXbvg6emJSZMmKfWwHTlyBFKpFDNmzFA6ds6cORAEQWnVjiVLlqBt27YYO3Yspk6dij59+lQ4rlxgYKD4fXnPaUlJCY4fP66yvkKhQFRUFAICAuDo6CiW29raYtSoUTh79izy8vI0/hmkp6cjMTERY8aMQZ06dcTyPn36oH379iqPGTJkCBo2bChuZ2Rk4NKlSxg3bhzq168vlnfo0AHe3t44cuSIxnGV8/DwgKurq7jdpEkTDBw4EMeOHYNCoYAgCNi/fz/eeecdCIKA7Oxs8eHr64vc3FwkJCQA+Pt3aWtri6FDh4rtmZiY4MMPP9QopmnTpiltT58+XWwfAMzNzTFw4EDs3r1bHJajUCgQHh4uDh+pTPnvsG7duhrF9CxjY2Px+4KCAmRnZ6N79+4QBAG///67WMfQ0BCxsbHIyclR2Y6FhQUA4NChQ5DL5VWOh4i0gwk0EemEm5sbvLy84OXlhffffx+HDx9GmzZtxGQWAFJTU2FnZ1choSkfEpGamiqWGRoaYvv27UhJScGTJ0+wY8cOlWNY9fT0lJJgAGjZsiUAVLr03IMHD1BYWIhWrVpV2Ne6dWuUlZXhzp076p/8/5TH37x58wr7VJUBgIODg8o2KostOzsbBQUFGscGAC1atKhQ1rJlSxQWFuLBgwd48OABHj9+jK+//hoNGzZUeowfPx4AcP/+fTHO5s2bV/idqIpbk5icnJygp6en9LsbM2YM0tLScObMGQDA8ePHkZWVhdGjR7+wbTMzMwDAkydPNIrpWWlpaeI/M3Xq1EHDhg3Rp08fAH8PWwIAmUyGL774AkePHoW1tTV69+6NlStXIjMzU2ynT58+GDJkCJYuXQpLS0sMHDgQO3bs0HjMOBFpBxNoIqoR9PT04OnpiYyMDNy8ebNKbRw7dgwA8PTp0yq3UdM928OpKVX/UAAQJ1lqqqysDADwwQcfiJ8mPP/o0aNHleNVh6pz8vX1hbW1NXbt2gUA2LVrF2xsbODl5fXCtpydnQEAiYmJVYpFoVDA29sbhw8fxvz58xEREYHo6GiEhYUB+L+fFwDMmjULf/31F0JDQ2FkZIRPPvkErVu3FnupJRIJ9u3bh7i4OAQGBooTNV1dXZGfn1+l+Iio+jCBJqIao7S0FADEBKFp06ZIT0+v0CN4/fp1cX+5P//8E8uWLcP48ePRqVMnTJo0Sezxe1ZZWRlu3bqlVPbXX38BQKWT7Ro2bAgTExPcuHGjwr7r169DT08P9vb2ACpPUlUpjz8pKanCPlVlL2qjstgsLS3FYQv16tXD48ePK9R7tif/War+Cfnrr79gYmIi9jTXrVsXCoVC/DTh+YeVlZUYZ3JycoXVTlTF/SLPx5SUlISysjKl351UKsWoUaOwb98+5OTkICIiAiNHjvzHiYE9e/ZEvXr1sHv37ir9U5GYmIi//voLa9aswfz58zFw4EB4eXnBzs5OZX0nJyfMmTMHUVFRuHz5MkpKSrBmzRqlOt26dcNnn32Gixcv4ocffsCVK1ewZ88ejWMjourFBJqIagS5XI6oqCgYGhqKQzT8/f2hUCiwadMmpbrr1q2DRCKBn5+feOy4ceNgZ2eHL7/8EmFhYcjKysLs2bNVPtez7QmCgE2bNsHAwAD9+vVTWV8qlcLHxwc///yz0lCBrKws/Pjjj+jZs6f48X95sqoqUX2enZ0d2rVrh++++06pV/HUqVNq94La2trCxcUFO3fuVHrOy5cvIyoqCv7+/mKZk5MTcnNz8eeff4pl5TcIUSUuLk4cwwwAd+7cwc8//wwfHx9IpVJIpVIMGTIE+/fvx+XLlysc/+DBA/F7f39/pKenY9++fWJZYWEhvv76a7XOs9zmzZuVtjdu3AgA4rVQbvTo0cjJycH/+3//r8LqLpUxMTHB/Pnzce3aNcyfP1/l0oa7du3ChQsXVB5fnqA/e5wgCPjyyy+V6hUWFiotvQf8/bupW7euOEQjJyenwvO7uLgAAIdxENUAXMaOiHTi6NGjYk/y/fv38eOPP+LmzZtYsGCBmIy+88478PT0xMcff4zbt2+jY8eOiIqKws8//4xZs2bByckJALB8+XJcunQJMTExqFu3Ljp06IDFixdj0aJFGDp0qFISaWRkhMjISIwdOxbu7u44evQoDh8+jIULFypNznve8uXLER0djZ49e2Lq1KnQ19fHv//9bxQXF2PlypViPRcXF0ilUnzxxRfIzc2FTCbDW2+9JfbEPm/FihUYOHAgevTogfHjxyMnJwebNm1Cu3bt1P6oftWqVfDz84OHhwcmTpwoLmNnbm6OJUuWiPVGjBiB+fPnY9CgQZgxYwYKCwuxZcsWtGzZUilRLteuXTv4+voqLWMHAEuXLhXrfP755zh58iTc3d0xefJktGnTBo8ePUJCQgKOHz+OR48eAQAmT56MTZs2YcyYMYiPj4etrS2+//57mJiYqHWO5VJSUvDuu++if//+iIuLw65duzBq1KgKaz936tQJ7dq1w969e9G6dWt07txZrfY/+ugjXLlyBWvWrMHJkycxdOhQ2NjYIDMzExEREbhw4QJ+/fVXlcc6OzvDyckJc+fOxb1792BmZob9+/dXmCj4119/oV+/fnjvvffQpk0b6Ovr4+DBg8jKysKIESMAADt37sRXX32FQYMGwcnJCU+ePMG2bdtgZmamdD0TkY7oaPUPInpDqVrGzsjISHBxcRG2bNkilJWVKdV/8uSJMHv2bMHOzk4wMDAQWrRoIaxatUqsFx8fL+jr6ystTScIglBaWip07dpVsLOzE3JycgRB+HsZN1NTUyE5OVnw8fERTExMBGtrayEkJERQKBRKx+O5ZewEQRASEhIEX19foU6dOoKJiYng6ekp/PrrrxXOcdu2bYKjo6MglUrVWqJtz549grOzsyCTyYR27doJ//nPf4QhQ4YIzs7OYp3yZewqW/rs+PHjQo8ePQRjY2PBzMxMeOedd4SrV69WqBcVFSW0a9dOMDQ0FFq1aiXs2rWr0mXspk2bJuzatUto0aKFIJPJhE6dOqk8l6ysLGHatGmCvb29YGBgINjY2Aj9+vUTvv76a6V6qampwrvvviuYmJgIlpaWwsyZM4XIyEiNlrG7evWqMHToUKFu3bpCvXr1hMDAQKGoqEjlMStXrhQACCtWrHhh26rs27dP8PHxEerXry/o6+sLtra2wvDhw4XY2Fixjqpl7K5evSp4eXkJderUESwtLYXJkycLf/zxhwBA2LFjhyAIgpCdnS1MmzZNcHZ2FkxNTQVzc3PB3d1daYm/hIQEYeTIkUKTJk0EmUwmWFlZCQMGDFBaVpCIdEciCGrcfouIqBYYN24c9u3b91pMwnJxcUHDhg0RHR2tk+eXSCSYNm1aheEzr5Mvv/wSs2fPxu3bt9GkSRNdh0NEtQiHcKhQVlaG9PR01K1bV6MJQURUs5Wvp1uVNZu1RS6XQyKRKN3C/MyZM/jjjz+waNEincZaUlJSo35WmhAEAdu2bUPPnj1hYWHx2p4HEb06giDgyZMnsLOzg57ei6cJsgdahbt374oz6omIiIjozXHnzh00btz4hXV02gN9+vRprFq1CvHx8eJM8ICAgBceExsbi6CgIFy5cgX29vZYtGgRxo0bp1Rn8+bNWLVqFTIzM9GxY0ds3LgRbm5uasdVftOGO3fuiJOZiF6V8tUofHx8YGBgoOtwapUpU6bg559/Rnp6uq5DEeXm5mLmzJk4f/48srOzYWJigj59+mDJkiUVbvjyKpmbm2Py5MlYvXq1zmKoitTUVHTo0AHm5uaYNGkSFi9erOuQSAN8/SNdysvLg729vVp3I9VpAl1QUICOHTtiwoQJGDx48D/WT0lJwdtvv41//etf+OGHHxATE4NJkybB1tYWvr6+AIDw8HAEBQVh69atcHd3x/r16+Hr64sbN25UOgv+eeXDNszMzJhA0ysnl8thYmICMzMzvoFUsx9++EHXIVRgZmamdPvymuJ1/XCyffv2r23sxNc/qhnUGb6r0wTaz8+vwtqdL7J161Y4ODiIC823bt0aZ8+exbp168QEeu3atZg8ebJ4G9mtW7fi8OHD2L59OxYsWFD9J0FEREREb5TXahJhXFxchVux+vr6YtasWQD+nvASHx+P4OBgcb+enh68vLwQFxdXabvFxcVKC9OXTzaRy+XipCOiV6X8muO1R0RvGr7+kS5pct29Vgl0ZmYmrK2tlcqsra2Rl5eHoqIi5OTkQKFQqKxTfsMGVUJDQ5VuDFAuKipK40X+iaqLrpYvIyLSNb7+kS4UFhaqXfe1SqC1JTg4GEFBQeJ2+SByHx8fjoGmV04ulyM6Ohre3t4cA0hEr7XCwkLcuHFD7fr5RcU4duY3+PbqijrGMrWPa9WqFTu86KVpstzla5VA29jYICsrS6ksKysLZmZmMDY2hlQqhVQqVVnHxsam0nZlMhlksop/qAYGBkxgSGd4/RHR6y45ORnu7u4aH7dSw/rx8fFq366dqDKavOe+Vgm0h4cHjhw5olQWHR0NDw8PAIChoSFcXV0RExMjLodXVlaGmJgYBAYGvupwiYiI3mjOzs6Ij49Xu/6NjMcI2puItcPao5WthUbPQ/Qq6TSBzs/PR1JSkridkpKCS5cuoX79+mjSpAmCg4Nx7949fPfddwCAf/3rX9i0aRPmzZuHCRMm4MSJE/jpp59w+PBhsY2goCCMHTsWXbp0gZubG9avX4+CggJxVQ4iIiJ6NUxMTDTqGdZLfQjZmSK0btcRLk0baDEyopej0wT64sWL8PT0FLfLxyGPHTsWYWFhyMjIQFpamrjfwcEBhw8fxuzZs/Hll1+icePG+Oabb8Ql7ABg+PDhePDgARYvXozMzEy4uLggMjKywsRCIiIiIqKq0GkC3bdv3xcueB8WFqbymN9///2F7QYGBnLIBhERERFphZ6uAyAiIiIiep28VpMIiYiISLdSsgtQUFyqlbaTHxSIX/X1tZOimMr04WBpqpW26c3BBJqIiIjUkpJdAM/VsVp/njn7ErXa/sm5fZlE00thAk1ERERqKe95Xj/cBc2t6lR/+0XFOBQbhwF9PWCqwY1U1JV0Px+zwi9prQed3hxMoImIiEgjza3qoF0j82pvVy6XI7Mh0LlpPd5Iimo0TiIkIiIiItIAE2giIiIiIg0wgSYiIiIi0gATaCIiIiIiDTCBJiIiIiLSABNoIiIiIiINMIEmIiIiItIAE2giIiIiIg0wgSYiIiIi0gDvREhUg5SUlGDjxo04ceIEkpKSMH36dBgaGuo6LCIiInoGe6CJaoh58+bB1NQUc+fOxZEjRzB37lyYmppi3rx5ug6NiIiInsEeaKIaYN68eVi1ahWsra2xdOlSyGQyFBcXIyQkBKtWrQIArFy5UsdREhEREcAeaCKdKykpwbp162BtbY27d+9iwoQJqFevHiZMmIC7d+/C2toa69atQ0lJia5DJSIiIjCBJtK5r776CqWlpVi+fDn09ZU/FNLX18eyZctQWlqKr776SkcREhER0bOYQBPpWHJyMgBgwIABKveXl5fXIyIiIt1iAk2kY05OTgCAQ4cOqdxfXl5ej4iIiHSLCTSRjk2dOhX6+vpYtGgRSktLlfaVlpZi8eLF0NfXx9SpU3UUIRERET2LCTSRjhkaGmL27NnIyspC48aN8c033+DRo0f45ptv0LhxY2RlZWH27NlcD5qIiKiG4DJ2RDVA+RJ169atU+pp1tfXx0cffcQl7IiIiGqQGtEDvXnzZjRr1gxGRkZwd3fHhQsXKq3bt29fSCSSCo+3335brDNu3LgK+/v37/8qToWoylauXImCggKsXr0a/v7+WL16NQoKCpg8ExER1TA674EODw9HUFAQtm7dCnd3d6xfvx6+vr64ceMGrKysKtQ/cOCA0nq4Dx8+RMeOHTFs2DClev3798eOHTvEbZlMpr2TIKomhoaGmDFjBpo3bw5/f38YGBjoOiQiIiJ6js57oNeuXYvJkydj/PjxaNOmDbZu3QoTExNs375dZf369evDxsZGfERHR8PExKRCAi2TyZTq1atX71WcDhERERHVcjrtgS4pKUF8fDyCg4PFMj09PXh5eSEuLk6tNr799luMGDECpqamSuWxsbGwsrJCvXr18NZbb2H58uVo0KCByjaKi4tRXFwsbufl5QEA5HI55HK5pqdF9FLKrzlee0RU05SvFFRaWqqV1yhtv/5pO356vWlyTeg0gc7OzoZCoYC1tbVSubW1Na5fv/6Px1+4cAGXL1/Gt99+q1Tev39/DB48GA4ODkhOTsbChQvh5+eHuLg4SKXSCu2EhoZi6dKlFcqjoqJgYmKi4VkRVY/o6Ghdh0BEpOROPgDo4+zZs0ito73n0dbr36uKn15PhYWFatfV+Rjol/Htt9+iffv2cHNzUyofMWKE+H379u3RoUMHODk5ITY2Fv369avQTnBwMIKCgsTtvLw82Nvbw8fHB2ZmZto7ASIV5HI5oqOj4e3tzTHQRFSjXEnPw+rEc+jZsyfa2lX/+6O2X/+0HT+93spHIKhDpwm0paUlpFIpsrKylMqzsrJgY2PzwmMLCgqwZ88eLFu27B+fx9HREZaWlkhKSlKZQMtkMpWTDA0MDJjAkM7w+iOimkZfX1/8qs3XJ229/r2q+On1pMk1odNJhIaGhnB1dUVMTIxYVlZWhpiYGHh4eLzw2L1796K4uBgffPDBPz7P3bt38fDhQ9ja2r50zERERET0ZtP5EI6goCCMHTsWXbp0gZubG9avX4+CggKMHz8eADBmzBg0atQIoaGhSsd9++23CAgIqDAxMD8/H0uXLsWQIUNgY2OD5ORkzJs3D82bN4evr+8rOy8iIqLapljxFHpG95CSdwN6RtU/iLi0tBTppem49uia2FtcnVLy8qFndA/FiqcAzKu9fXpz6DyBHj58OB48eIDFixcjMzMTLi4uiIyMFCcWpqWlQU9PuaP8xo0bOHv2LKKioiq0J5VK8eeff2Lnzp14/Pgx7Ozs4OPjg08//ZRrQRMREb2E9IJUmDpsxMLK73dWLb6K/EprbZs6AOkFLnCF9T9XJqqEzhNoAAgMDERgYKDKfbGxsRXKWrVqBUEQVNY3NjbGsWPHqjM8IiIiAmBn2hQFKdPx5XAXOFlppwf6l7O/oEfPHlrpgU6+n4+Z4Zdg59m02tumN0uNSKCJiIio5pNJjVD2tBEczFqhTYPqHwIhl8uRop+C1vVba2WSX9nTXJQ9fQCZ1Kja26Y3i87vREhERERE9DpRO4G+efMmRo4cqXKNvNzcXIwaNQq3bt2q1uCIiIiIiGoatRPoVatWwd7eXuWNRczNzWFvb49Vq1ZVa3BERERERDWN2gn0qVOnMGzYsEr3v/feezhx4kS1BEVEREREVFOpnUCnpaXBysqq0v2Wlpa4c+dOtQRFRERERFRTqZ1Am5ubIzk5udL9SUlJKod3EJH6FAoFTp06hdOnT+PUqVNQKBS6DomIiIieo3YC3bt3b2zcuLHS/Rs2bECvXr2qJSiiN9GBAwfQvHlzeHt7Y+3atfD29kbz5s1x4MABXYdGREREz1A7gQ4ODsbRo0cxdOhQXLhwAbm5ucjNzcX58+cxZMgQHDt2DMHBwdqMlajWOnDgAIYOHYr27dvjzJkz2L17N86cOYP27dtj6NChTKKJiIhqELVvpNKpUyfs27cPEyZMwMGDB5X2NWjQAD/99BM6d+5c7QES1XYKhQJz5szBgAEDEBERAYVCgYcPH8Ld3R0REREICAjA3LlzMXDgQEilUl2HS0RE9MbT6E6EAwYMQGpqKiIjI5GUlARBENCyZUv4+PjAxMREWzES1WpnzpzB7du3sXv3bujp6SmNe9bT00NwcDC6d++OM2fOoG/fvroLlIiIiABokEBv2rQJo0ePhrm5OQYNGqTNmIjeKBkZGQCAdu3aqdxfXl5ej4iIiHRL7THQH3/8MWxtbTFq1Ciu90xUjWxtbQEAly9fVrm/vLy8HhEREemW2gl0ZmYmtm7dioyMDHh7e8PBwQGffvop134mekm9evVCs2bNsGLFCpSVlSntKysrQ2hoKBwcHLjKDRERUQ2hdgJtbGyMMWPG4OTJk7h58yZGjx6Nb7/9Fg4ODujfvz/27t0LuVyuzViJaiWpVIo1a9bg0KFDCAgIwLlz51BUVIRz584hICAAhw4dwurVqzmBkIiIqIZQO4F+lqOjI5YtW4aUlBQcPXoUDRo0wLhx49CoUaPqjo/ojTB48GDs27cPiYmJ6N27N0aOHInevXvj8uXL2LdvHwYPHqzrEImIiOh/NFqF43kSiQT6+vqQSCQQBIE90EQvYfDgwRg4cCBOnjyJo0ePws/PD56enux5JiIiqmGq1AN9584dLFu2DI6OjvD29kZ6ejq2bdvGVQKIXpJUKkWfPn3Qu3dv9OnTh8kzERFRDaR2D3RJSQkOHDiA7du348SJE7C1tcXYsWMxYcIEODo6ajNGIiIiIqIaQ+0E2sbGBoWFhRgwYAD++9//wtfXF3p6VerAJiIiIiJ6bamdQC9atAijR49Gw4YNtRkPEREREVGNpnYCHRQUVKHs6dOnCA8PR0FBAby9vdGiRYtqDY6IiIiIqKbRKIGWy+XYuHEjgL/HRHt4eODKlSswMTHBvHnzEB0dDQ8PD60FS0RERESka2oPYo6KioK3t7e4/cMPPyA1NRU3b95ETk4Ohg0bhuXLl1cpiM2bN6NZs2YwMjKCu7s7Lly4UGndsLAwSCQSpYeRkZFSHUEQsHjxYtja2sLY2BheXl64efNmlWIjIiIiInqW2gl0Wloa2rRpI25HRUVh6NChaNq0KSQSCWbOnInff/9d4wDCw8MRFBSEkJAQJCQkoGPHjvD19cX9+/crPcbMzAwZGRniIzU1VWn/ypUrsWHDBmzduhXnz5+HqakpfH198fTpU43jIyIiIiJ6ltoJtJ6eHgRBELfPnTuHbt26idsWFhbIycnROIC1a9di8uTJGD9+PNq0aYOtW7fCxMQE27dvr/QYiUQCGxsb8WFtbS3uEwQB69evx6JFizBw4EB06NAB3333HdLT0xEREaFxfEREREREz1J7DHTr1q3x3//+F0FBQbhy5QrS0tLg6ekp7k9NTVVKZNVRUlKC+Ph4BAcHi2V6enrw8vJCXFxcpcfl5+ejadOmKCsrQ+fOnbFixQq0bdsWAJCSkoLMzEx4eXmJ9c3NzeHu7o64uDiMGDGiQnvFxcUoLi4Wt/Py8gAAcrmcd1ekV678muO1R0Q1TWlpqfhVG69R2n7903b89HrT5JpQO4GeN28eRowYgcOHD+PKlSvw9/eHg4ODuP/IkSNwc3PTKNDs7GwoFIoKibe1tTWuX7+u8phWrVph+/bt6NChA3Jzc7F69Wp0794dV65cQePGjZGZmSm28Xyb5fueFxoaiqVLl1Yoj4qKgomJiUbnRPQyFAoFrl69ipycHCQmJqJNmza8GyER1Rh38gFAH2fPnkVqHe09T3R0tFbafVXx0+upsLBQ7bpqJ9CDBg3CkSNHcOjQIfj4+GD69OlK+01MTDB16lT1o6wiDw8PpZU+unfvjtatW+Pf//43Pv300yq1GRwcrLRMX15eHuzt7eHj4wMzM7OXjplIHQcPHsT8+fNx+/ZtsaxZs2b44osvMGjQIN0FRkT0P1fS87A68Rx69uyJtnbV//4ol8sRHR0Nb29vGBgYVHv72o6fXm/lIxDUoXYCDQD9+vVDv379VO4LCQnRpCkAgKWlJaRSKbKyspTKs7KyYGNjo1YbBgYG6NSpE5KSkgBAPC4rKwu2trZKbbq4uKhsQyaTQSaTqWxbG3/ARM87cOAARowYgQEDBuD777/H3bt30bhxY6xcuRIjRozAvn37MHjwYF2HSURvOH19ffGrNt8ftfX++6rip9eTJteExvfidnBwwLJly5CWlqbpoRUYGhrC1dUVMTExYllZWRliYmLUXk9aoVAgMTFRTJYdHBxgY2Oj1GZeXh7Onz/PNaqpRlIoFJgzZw4GDBiAiIgIuLu7w9jYGO7u7oiIiMCAAQMwd+5cKBQKXYdKREREqEICPXPmTBw4cACOjo7w9vbGnj17lCbgaSooKAjbtm3Dzp07ce3aNUyZMgUFBQUYP348AGDMmDFKkwyXLVuGqKgo3Lp1CwkJCfjggw+QmpqKSZMmAfh7hY5Zs2Zh+fLl+M9//oPExESMGTMGdnZ2CAgIqHKcRNpy5swZ3L59GwsXLoSenvKfpJ6eHoKDg5GSkoIzZ87oKEIiIiJ6lsYJ9KxZs3Dp0iVcuHABrVu3xvTp02Fra4vAwEAkJCRoHMDw4cOxevVqLF68GC4uLrh06RIiIyPFSYBpaWnIyMgQ6+fk5GDy5Mlo3bo1/P39kZeXh19//VVpjep58+Zh+vTp+PDDD9G1a1fk5+cjMjKywg1XiGqC8uu7Xbt2KveXlz/7d0BERES6o3ECXa5z587YsGED0tPTERISgm+++QZdu3aFi4sLtm/frrRm9D8JDAxEamoqiouLcf78ebi7u4v7YmNjERYWJm6vW7dOrJuZmYnDhw+jU6dOSu1JJBIsW7YMmZmZePr0KY4fP46WLVtW9VSJtKp8+NHly5dV7i8vf3ZMPxEREelOlRNouVyOn376Ce+++y7mzJmDLl264JtvvsGQIUOwcOFCvP/++9UZJ1Gt1atXLzRr1gwrVqyAXC7HqVOncPr0aZw6dQpyuRyhoaFwcHBAr169dB0qERERQcNVOAAgISEBO3bswO7du6Gnp4cxY8Zg3bp1cHZ2FusMGjQIXbt2rdZAiWorqVSKNWvWYMiQITA3N0dRURGAv+/SaWxsjKKiIuzfv5/rQRMREdUQGifQXbt2hbe3N7Zs2YKAgACVS344ODiovOMfEb3Y06dPX7hNREREuqdxAn3r1i00bdr0hXVMTU2xY8eOKgdF9CZRKBSYMmUKAMDPzw9OTk64ceMGWrVqheTkZBw5cgRTpkzBwIED2QtNRERUA2icQP9T8kxEmomNjcX9+/fh7OyMK1eu4MiRIwD+vpV806ZN4ezsjOvXryM2NrbSGxkRERHRq6N2Au3o6KhWvVu3blU5GKI3UWxsLADg+vXrMDY2Vtp3//59cUw0E2giIqKaQe0E+vbt22jatClGjRoFKysrbcZE9EYpKysTv+/Xrx/mz58v3sr7iy++wKFDhyrUIyIiIt1RO4EODw/H9u3bsXbtWvj5+WHChAnw9/evcOc0ItKMhYUFAKBu3bo4ePAgBEHAw4cP4e7ujoMHD6J+/fp48uSJWI+IiIh0S+3sd9iwYTh69CiSkpLg6uqK2bNnw97eHgsWLMDNmze1GSNRrfb48WMAwJMnTzBo0CCcO3cORUVFOHfuHAYNGoQnT54o1SMiIiLd0rj7uFGjRvj4449x8+ZN/Pjjjzh//jycnZ2Rk5OjjfiIar1nP8WJiYlB7969MXLkSPTu3RsnTpxQWY+IiIh0p0rvyE+fPsWuXbuwdOlSnD9/HsOGDYOJiUl1x0b0Rujbty8AwNnZucL8AisrK/EmReX1iIiISLc0Wsbu/Pnz+Pbbb/HTTz/B0dEREyZMwP79+1GvXj1txUf02issLMT169cr3W9mZoZ69erh+vXr6NmzJwIGD8GNlLto5dAY8b9dwNmzZ1G/fn2YmZkhISGh0nacnZ35jywREdEroHYC3bZtW9y/fx+jRo3CqVOn0LFjR23GRVRrXL9+Ha6urmrVPXv2LM6ePQsAiHym/NGjR3Bzc3vhsfHx8ejcuXNVwyQiIiI1qZ1AX7t2Daampvjuu+/w/fffV1rv0aNH1RIYUW3h7OyM+Pj4f6x34sQJrF27FhkZGWKZnZ0dZs+ejbfeekut5yEiIiLtUzuB5q25iarGxMRErZ7hzp07Y/bs2dix9xCCf/wFoaN6YPywAbx9NxERUQ2jdgI9duxY8evEiRPRu3dvrQVF9KaSSqXo4tETppf00cWjG5NnIiKiGkjjVThyc3Ph5eWFFi1aYMWKFUhPT9dGXERERERENZLGCXRERATu3buHKVOmIDw8HE2bNoWfnx/27t0LuVyujRiJiIiIiGqMKq0D3bBhQwQFBeGPP/7A+fPn0bx5c4wZM0ac8MQ7ExIRERFRbfVStzbLyMhAdHQ0oqOjIZVK4e/vj8TERLRp0wbr1q2rrhiJiIiIiGoMjRNouVyO/fv3Y8CAAWjatCn27t2LWbNmIT09HTt37sTx48fx008/YdmyZdqIl4iIiIhIpzS6EyEA2NraoqysDCNHjsSFCxfg4uJSoY6npycsLCyqITwiIiKqKYrkCgDA5Xu5Wmm/oKgYFx8ANqk5MDWWVXv7Sffzq71NejNpnECvW7cOw4YNg5GRUaV1LCwskJKS8lKBERERUc2S/L8EdMGBRC0+iz6+T/pNi+0DpjKN0x8iJRpfQaNHj9ZGHERERFTD+bS1AQA4WdWBsUH1r1N/IyMXc/YlYs3Q9mhla17t7QN/J88OlqZaaZveHDXiX7DNmzdj1apVyMzMRMeOHbFx40a4ubmprLtt2zZ89913uHz5MgDA1dUVK1asUKo/btw47Ny5U+k4X19fREZGau8kiIiIarn6poYY4dZEa+2XlpYCAJwamqJdI+0k0ETV4aVW4agO4eHhCAoKQkhICBISEtCxY0f4+vri/v37KuvHxsZi5MiROHnyJOLi4mBvbw8fHx/cu3dPqV7//v2RkZEhPnbv3v0qToeIiIiIajmdJ9Br167F5MmTMX78eLRp0wZbt26FiYkJtm/frrL+Dz/8gKlTp8LFxQXOzs745ptvUFZWhpiYGKV6MpkMNjY24qNevXqv4nSIiIiIqJbT6RCOkpISxMfHIzg4WCzT09ODl5cX4uLi1GqjsLAQcrkc9evXVyqPjY2FlZUV6tWrh7feegvLly9HgwYNVLZRXFyM4uJicTsvLw/A30v28e6K9KqVf4RZWlrK64+I3ih8/SNd0uSa02kCnZ2dDYVCAWtra6Vya2trXL9+Xa025s+fDzs7O3h5eYll/fv3x+DBg+Hg4IDk5GQsXLgQfn5+iIuLg1RacdJDaGgoli5dWqE8KioKJiYmGp4V0cu5kw8A+jh37hzuXdZ1NERErw5f/0iXCgsL1a5bIyYRVtXnn3+OPXv2IDY2VmlZvREjRojft2/fHh06dICTkxNiY2PRr1+/Cu0EBwcjKChI3M7LyxPHVpuZmWn3JIie80faIyDxIrp164aOTer/8wFERLUEX/9Il8pHIKhDpwm0paUlpFIpsrKylMqzsrJgY2PzwmNXr16Nzz//HMePH0eHDh1eWNfR0RGWlpZISkpSmUDLZDLIZBUXbDcwMICBgYEaZ0JUffT19cWvvP6I6E3C1z/SJU2uOZ1OIjQ0NISrq6vSBMDyCYEeHh6VHrdy5Up8+umniIyMRJcuXf7xee7evYuHDx/C1ta2WuImIiIiojeXzlfhCAoKwrZt27Bz505cu3YNU6ZMQUFBAcaPHw8AGDNmjNIkwy+++AKffPIJtm/fjmbNmiEzMxOZmZnIz//77kj5+fn46KOPcO7cOdy+fRsxMTEYOHAgmjdvDl9fX52cIxERERHVHjofAz18+HA8ePAAixcvRmZmJlxcXBAZGSlOLExLS4Oe3v/l+Vu2bEFJSQmGDh2q1E5ISAiWLFkCqVSKP//8Ezt37sTjx49hZ2cHHx8ffPrppyqHaRARERERaULnCTQABAYGIjAwUOW+2NhYpe3bt2+/sC1jY2McO3asmiIjIiIiIlKm8yEcRERERESvEybQREREREQaYAJNRERERKSBGjEGmuh1k5JdgILiUq20nfygQPxaviZqdTOV6cPB0lQrbRMREdV2TKCJNJSSXQDP1bFaf545+xK12v7JuX2ZRBMREVUBE2giDZX3PK8f7oLmVnWqv/2iYhyKjcOAvh4wNa7+pReT7udjVvglrfWgExER1XZMoImqqLlVHbRrZF7t7crlcmQ2BDo3rcdb2RIREdVAnERIRERERKQBJtBERERERBpgAk1EREREpAEm0EREREREGmACTURERESkASbQREREREQaYAJNRERERKQBJtBERERERBrgjVSINFSseAo9o3tIybsBPaPqvxNhaWkp0kvTce3RNejrV/+faEpePvSM7qFY8RRA9d8IhoiIqLZjAk2kofSCVJg6bMTCC9p9nq8iv9Ja26YOQHqBC1xhrbXnICIiqq2YQBNpyM60KQpSpuPL4S5wstJOD/QvZ39Bj549tNIDnXw/HzPDL8HOs2m1t01ERPQmYAJNpCGZ1AhlTxvBwawV2jSo/iEQcrkcKfopaF2/NQwMDKq9/bKnuSh7+gAyqVG1t01ERPQm4CRCIiIiIiINMIEmIiIiItIAE2giIiIiIg1wDDSRhorkCgDA5Xu5Wmm/oKgYFx8ANqk5MDWWVXv7Sffzq71NIiJVCgsLcf36dbXr38h4jOLMJFy7bIyyhxZqH+fs7AwTE5MqREhUNTUigd68eTNWrVqFzMxMdOzYERs3boSbm1ul9ffu3YtPPvkEt2/fRosWLfDFF1/A399f3C8IAkJCQrBt2zY8fvwYPXr0wJYtW9CiRYtXcTpUyyX/LwFdcCBRi8+ij++TftNi+4CprEb8+RNRLXb9+nW4urpqfNyonZrVj4+PR+fOnTV+HqKq0vk7aHh4OIKCgrB161a4u7tj/fr18PX1xY0bN2BlZVWh/q+//oqRI0ciNDQUAwYMwI8//oiAgAAkJCSgXbt2AICVK1diw4YN2LlzJxwcHPDJJ5/A19cXV69ehZERVx6gl+PT1gYA4GRVB8YG0mpv/0ZGLubsS8Saoe3RylY7NzoxlenDwdJUK20TEZVzdnZGfHy82vXzi4px+GQc3vb0QB0NPoFzdnauSnhEVSYRBEHQZQDu7u7o2rUrNm3aBAAoKyuDvb09pk+fjgULFlSoP3z4cBQUFODQoUNiWbdu3eDi4oKtW7dCEATY2dlhzpw5mDt3LgAgNzcX1tbWCAsLw4gRI/4xpry8PJibmyM3NxdmZmbVdKZE6rmU+hABW84hYko3uDRtoOtwiIheGblcjiNHjsDf318ry3gSvYgm+Z9Oe6BLSkoQHx+P4OBgsUxPTw9eXl6Ii4tTeUxcXByCgoKUynx9fREREQEASElJQWZmJry8vMT95ubmcHd3R1xcnMoEuri4GMXFxeJ2Xl4egL//kOVyeZXPjwj4ewzgjRs31K7/V0YuijOTcPmSIUqy1O+BbtWqFccAEtFrrfw9l++9pAuaXHc6TaCzs7OhUChgba18O2Fra+tKJx1kZmaqrJ+ZmSnuLy+rrM7zQkNDsXTp0grlUVFRTEjopSUnJ2POnDkaHzdawzGAa9asgZOTk8bPQ0RU00RHR+s6BHoDFRYWql1X52Oga4Lg4GClXu28vDzY29vDx8eHQzjopRUWFqJnz55q188vKsaxM7/Bt1dXjcYAsgeaiF53crkc0dHR8Pb25hAOeuXKRyCoQ6cJtKWlJaRSKbKyspTKs7KyYGNjo/IYGxubF9Yv/5qVlQVbW1ulOi4uLirblMlkkMkqJioGBgb8A6aXZm5u/sJVZZ4nl8vx5PEj9OrejdcfEb2R+P5LuqDJNafTG6kYGhrC1dUVMTExYllZWRliYmLg4eGh8hgPDw+l+sDfH/WU13dwcICNjY1Snby8PJw/f77SNomIiIiI1KXzIRxBQUEYO3YsunTpAjc3N6xfvx4FBQUYP348AGDMmDFo1KgRQkNDAQAzZ85Enz59sGbNGrz99tvYs2cPLl68iK+//hoAIJFIMGvWLCxfvhwtWrQQl7Gzs7NDQECArk6TiIiIiGoJnSfQw4cPx4MHD7B48WJkZmbCxcUFkZGR4iTAtLQ06On9X0d59+7d8eOPP2LRokVYuHAhWrRogYiICHENaACYN28eCgoK8OGHH+Lx48fo2bMnIiMjuQY0EREREb00na8DXRPl5ubCwsICd+7c4SRCeuXkcjmioqLg4+PDMYBE9Ebh6x/pUvkiEo8fP4a5+YuXkdV5D3RN9OTJEwCAvb29jiMhIiIiolfpyZMn/5hAswdahbKyMqSnp6Nu3bqQSCS6DofeMOX/AfMTECJ60/D1j3RJEAQ8efIEdnZ2SsOHVWEPtAp6enpo3LixrsOgN5yZmRnfQIjojcTXP9KVf+p5LqfTZeyIiIiIiF43TKCJiIiIiDTABJqohpHJZAgJCVF5d0wiotqMr3/0uuAkQiIiIiIiDbAHmoiIiIhIA0ygiYiIiIg0wASaiIiIiEgDTKCJiIiIiDTABJqohtm8eTOaNWsGIyMjuLu748KFC7oOiYhIq06fPo133nkHdnZ2kEgkiIiI0HVIRC/EBJqoBgkPD0dQUBBCQkKQkJCAjh07wtfXF/fv39d1aEREWlNQUICOHTti8+bNug6FSC1cxo6oBnF3d0fXrl2xadMmAEBZWRns7e0xffp0LFiwQMfRERFpn0QiwcGDBxEQEKDrUIgqxR5oohqipKQE8fHx8PLyEsv09PTg5eWFuLg4HUZGREREz2ICTVRDZGdnQ6FQwNraWqnc2toamZmZOoqKiIiInscEmoiIiIhIA0ygiWoIS0tLSKVSZGVlKZVnZWXBxsZGR1ERERHR85hAE9UQhoaGcHV1RUxMjFhWVlaGmJgYeHh46DAyIiIiepa+rgMgov8TFBSEsWPHokuXLnBzc8P69etRUFCA8ePH6zo0IiKtyc/PR1JSkridkpKCS5cuoX79+mjSpIkOIyNSjcvYEdUwmzZtwqpVq5CZmQkXFxds2LAB7u7uug6LiEhrYmNj4enpWaF87NixCAsLe/UBEf0DJtBERERERBrgGGgiIiIiIg0wgSYiIiIi0gATaCIiIiIiDTCBJiIiIiLSABNoIiIiIiINMIEmIiIiItIAE2giIiIiIg0wgSYiegNJJBJEREToOgwiotcSE2giolooMzMT06dPh6OjI2QyGezt7fHOO+8gJiZG16EREb329HUdABERVa/bt2+jR48esLCwwKpVq9C+fXvI5XIcO3YM06ZNw/Xr13UdIhHRa4090EREtczUqVMhkUhw4cIFDBkyBC1btkTbtm0RFBSEc+fOqTxm/vz5aNmyJUxMTODo6IhPPvkEcrlc3P/HH3/A09MTdevWhZmZGVxdXXHx4kUAQGpqKt555x3Uq1cPpqamaNu2LY4cOfJKzpWISBfYA01EVIs8evQIkZGR+Oyzz2Bqalphv4WFhcrj6tati7CwMNjZ2SExMRGTJ09G3bp1MW/ePADA+++/j06dOmHLli2QSqW4dOkSDAwMAADTpk1DSUkJTp8+DVNTU1y9ehV16tTR2jkSEekaE2giolokKSkJgiDA2dlZo+MWLVokft+sWTPMnTsXe/bsERPotLQ0fPTRR2K7LVq0EOunpaVhyJAhaN++PQDA0dHxZU+DiKhG4xAOIqJaRBCEKh0XHh6OHj16wMbGBnXq1MGiRYuQlpYm7g8KCsKkSZPg5eWFzz//HMnJyeK+GTNmYPny5ejRowdCQkLw559/vvR5EBHVZEygiYhqkRYtWkAikWg0UTAuLg7vv/8+/P39cejQIfz+++/4+OOPUVJSItZZsmQJrly5grfffhsnTpxAmzZtcPDgQQDApEmTcOvWLYwePRqJiYno0qULNm7cWO3nRkRUU0iEqnZXEBFRjeTn54fExETcuHGjwjjox48fw8LCAhKJBAcPHkRAQADWrFmDr776SqlXedKkSdi3bx8eP36s8jlGjhyJgoIC/Oc//6mwLzg4GIcPH2ZPNBHVWuyBJiKqZTZv3gyFQgE3Nzfs378fN2/exLVr17BhwwZ4eHhUqN+iRQukpaVhz549SE5OxoYNG8TeZQAoKipCYGAgYmNjkZqail9++QW//fYbWrduDQCYNWsWjh07hpSUFCQkJODkyZPiPiKi2oiTCImIahlHR0ckJCTgs88+w5w5c5CRkYGGDRvC1dUVW7ZsqVD/3XffxezZsxEYGIji4mK8/fbb+OSTT7BkyRIAgFQqxcOHDzFmzBhkZWXB0tISgwcPxtKlSwEACoUC06ZNw927d2FmZob+/ftj3bp1r/KUiYheKQ7hICIiIiLSAIdwEBERERFpgAk0EREREZEGmEATEREREWmACTQRERERkQaYQBMRERERaYAJNBERERGRBphAExERERFpgAk0EREREZEGmEATEREREWmACTQRERERkQaYQBMRERERaYAJNBERERGRBv4/hv34y5zLHLAAAAAASUVORK5CYII=","text/plain":["<Figure size 800x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 800x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 800x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 800x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 800x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#working with some UPDRS-towards data\n","def printTargetModelCase():\n","    global u\n","    # for u in targetVars:\n","    for yModel in yModels:\n","        formalism = type(yModels[yModel]).__name__\n","        print('***********', formalism, end=': ')\n","        if formalism=='MyXGBClassifier':\n","            g=2\n","            # print(y_pred)\n","        # myTarget = targetVars[0]\n","        some_data = x_t[3]#[: 50]\n","        some_labels = y_t[3][u].to_list()#[: 50]\n","        # display(some_labels)\n","        some_data_prepared = pd.DataFrame(fullPipeline.transform(some_data), \n","                                          columns=x_tTransf[0].columns)\n","        # display(some_data_prepared)\n","        y_pred = getPrediction(yModels[yModel], some_data_prepared) #[y_p for y_p in yModels[yModel].predict(some_data_prepared)]\n","        # y_pred = getPrediction(u, y_Pred) #np.round(np.expm1(y_pred))\n","\n","        #y_pred = sum(np.array(y_pred).tolist(), [])\n","        some_cases = pd.DataFrame({u: some_labels,#[myTarget], \n","                                yModel: y_pred.to_list()})\n","        #                           index = some_labels.index)\n","        # display(some_cases)\n","        myPlot = some_cases.boxplot(column=some_cases.columns[1],\n","                                    figsize=(8,2),\n","                                    vert=True, \n","                                    by=some_cases.columns[0]);\n","            # some_cases.plot(x=some_cases.columns[1], \n","            #                      y=some_cases.columns[0], \n","            #                      style='o', \n","            #                      figsize=(8,2));\n","        myPlot.set_ylabel(some_cases.columns[1])\n","        myPlot.set_xlabel(some_cases.columns[0])\n","        myPlot.set_title('')\n","        logLoss = LOG_LOSS(some_cases[u], some_cases[yModel])#some_cases.corr().iloc[0,1]\n","        print('logLoss=', logLoss)\n","        # if np.isnan(corr):\n","        #     print('very small std: ', pd.Series(y_pred).std())\n","        \n","        # display(some_cases.head())\n","        # residuals = some_cases[some_cases.columns[0]] - some_cases[some_cases.columns[1]]\n","        # print('residuals.describe() \\n', residuals.describe())\n","        # residuals.hist(bins = 5);    \n","printTargetModelCase()"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:25.047019Z","iopub.status.busy":"2023-05-05T21:25:25.046563Z","iopub.status.idle":"2023-05-05T21:25:47.050525Z","shell.execute_reply":"2023-05-05T21:25:47.049258Z","shell.execute_reply.started":"2023-05-05T21:25:25.046980Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" *********** Best models via SMAPE in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bestModel</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyLogistic</td>\n","      <td>0.108</td>\n","      <td>0.55</td>\n","      <td>0.442</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     bestModel  logLoss_t  logLoss_v  logLoss_dif_vt\n","0  yMyLogistic      0.108       0.55           0.442"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" *********** Rank via logLoss in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>yMyLogistic</td>\n","      <td>0.108</td>\n","      <td>0.550</td>\n","      <td>0.442</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yMyLGBM</td>\n","      <td>0.273</td>\n","      <td>0.655</td>\n","      <td>0.382</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yMySVC</td>\n","      <td>0.404</td>\n","      <td>0.685</td>\n","      <td>0.281</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>yMyXGB</td>\n","      <td>0.693</td>\n","      <td>0.693</td>\n","      <td>0.000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>yMyRandomForest</td>\n","      <td>0.777</td>\n","      <td>0.910</td>\n","      <td>0.133</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>yMyDecisionTree</td>\n","      <td>0.594</td>\n","      <td>2.544</td>\n","      <td>1.950</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyLinear</td>\n","      <td>0.508</td>\n","      <td>2.571</td>\n","      <td>2.063</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             model  logLoss_t  logLoss_v  logLoss_dif_vt\n","1      yMyLogistic      0.108      0.550           0.442\n","3          yMyLGBM      0.273      0.655           0.382\n","2           yMySVC      0.404      0.685           0.281\n","6           yMyXGB      0.693      0.693           0.000\n","5  yMyRandomForest      0.777      0.910           0.133\n","4  yMyDecisionTree      0.594      2.544           1.950\n","0        yMyLinear      0.508      2.571           2.063"]},"metadata":{},"output_type":"display_data"}],"source":["#evaluation measures for the log-UPDRS models\n","def getFormalismDictionary(models, formalismNm):\n","    # dic = []\n","    # for u in targetVars:\n","    for yModel in models:\n","        if yModel == formalismNm:\n","            return(models[yModel])\n","# for u in targetVars:\n","count = 0\n","for yModel in yModels:\n","    yModel_ = getFormalismDictionary(yModels, yModel)\n","    eModel_ = getFormalismDictionary(e_yModels, yModel)\n","    count +=1\n","    printResults = True if count == len(yModels) else False\n","    computePerformanceMeasures(yModel = yModel_, phase = 0, \n","                            x_t = x_tTransf, #x_v = x_vTransf, \n","                            y_t = y_t, #y_v = y_v, \n","                            eModel=eModel_, printResults=printResults)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:25:47.052764Z","iopub.status.busy":"2023-05-05T21:25:47.052400Z","iopub.status.idle":"2023-05-05T21:26:03.000589Z","shell.execute_reply":"2023-05-05T21:26:02.999460Z","shell.execute_reply.started":"2023-05-05T21:25:47.052730Z"},"trusted":true},"outputs":[],"source":["#printPredictorsCorrelation\n","#see https://seaborn.pydata.org/generated/seaborn.pairplot.html\n","import seaborn as sns\n","sns.set_theme(style=\"ticks\")\n","def printPredictorsCorrelation(predDfs, modelsNms = None):\n","    for u in targetVars:\n","        # print('*************** ***************')\n","        # display('y_t', y_t)\n","        # display('df_t', predDfs['df_t'])\n","        # display('y_v', y_v)\n","        # display('df_v', predDfs['df_v'])\n","        # nDecs = 5\n","        # corr_t = round(predDfs['df_t'].corr(), nDecs)\n","        # corr_v = round(predDfs['df_v'].corr(), nDecs)\n","        # corr_v_t = round(corr_v/corr_t, nDecs)\n","        # display('df_t corr:', corr_t)\n","        # display('df_v corr:',  corr_v)\n","        # display('df_v corr/df_t corr:',  corr_v_t)\n","        auxDf = predDfs[0].copy()\n","        auxDf['phase'] = [u+'(train)']*len(auxDf)\n","        for i in [1, 3]:#nDataSubsets):\n","            auxDf_v = predDfs[i].copy()\n","            auxDf_v['phase'] = [u+'(validation '+str(i)+')']*len(auxDf_v)\n","            auxDf = pd.concat([auxDf, auxDf_v]) \n","        if modelsNms is not None:\n","             auxDf = auxDf[modelsNms]\n","        sns.pairplot(auxDf, hue='phase', #kind=\"kde\",# diag_kind='hist',  \n","                    #  markers=[\"o\", \"D\"], \n","                      height=2.5, corner=True)        \n","if isInKaggle:# or not isInKaggle:\n","    printPredictorsCorrelation(predDfs=e_yPredictions)#e_yPredictions)#yPredictions)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Studying features importance"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"data":{"text/plain":["{'MyLinearRegressor': True,\n"," 'MyLogisticRegression': True,\n"," 'MySVC': True,\n"," 'MyLGBMClassifier': True,\n"," 'MyXGBClassifier': True,\n"," 'MyDecisionTreeClassifier': True,\n"," 'MyRandomForestClassifier': True,\n"," 'MyMLPClassifier': False,\n"," 'MyTfMLPClassifier': False,\n"," 'MyTfRNNClassifier': False}"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["isToRunInitialModels"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.003803Z","iopub.status.busy":"2023-05-05T21:26:03.002254Z","iopub.status.idle":"2023-05-05T21:26:03.033473Z","shell.execute_reply":"2023-05-05T21:26:03.032279Z","shell.execute_reply.started":"2023-05-05T21:26:03.003744Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["|| importantFeatures:  \n","     importance signal\n","EJ    0.245714    (-)\n","DU    0.151095    (+)\n","FD    0.118796    (+)\n","CH    0.112734    (-)\n","FI    0.101056    (-)\n","AB    0.100397    (+)\n","DI    0.080486    (+)\n","BQ    0.069323    (+)\n","EP    0.069039    (-)\n","DN    0.068217    (-)\n","DY    0.067625    (+)\n","CW    0.061188    (-)\n","FL    0.061078    (+)\n","AX    0.060082    (-)\n","EE    0.054560    (-)\n","AZ    0.052913    (+)\n","CD    0.051280    (+)\n","GB    0.050418    (+)\n","EB    0.046837    (+)\n","DA    0.045658    (-)\n","BC    0.045520    (+)\n","AR    0.035721    (-)\n","DH    0.035675    (-)\n","GH    0.035433    (+)\n","CU    0.035218    (-)\n","GL    0.033890    (-)\n","GE    0.033592    (-)\n","FR    0.032036    (+)\n","CB    0.031658    (-)\n","FC    0.029469    (-)\n","FE    0.028789    (+)\n","CL    0.028186    (+)\n","EH    0.027530    (-)\n","FS    0.024726    (-)\n","CR    0.024130    (+)\n","AH    0.024009    (+)\n","DV    0.022048    (+)\n","GI    0.021140    (-)\n","EG    0.018990    (+)\n","EL    0.018738    (+)\n","BZ    0.018207    (+)\n","AM    0.017763    (+)\n","BR    0.016081    (-)\n","AY    0.015531    (-)\n","AF    0.015198    (+)\n","EU    0.014660    (-)\n","DL    0.013549    (-)\n","CS    0.011567    (-)\n","BN    0.010685    (-)\n","GF    0.008133    (-)\n","CF    0.005244    (-)\n","CC    0.004555    (-)\n","BP    0.003458    (+)\n","BD    0.002547    (+)\n","DF    0.001736    (-)\n","DE    0.001701    (+)\n"]}],"source":["def getFeaturesImportance(modelObjs, nFeatures):\n","    importantFeatures = {}\n","    # for u in targetVars:\n","    columns = x_tTransf[0].columns\n","    # if isWithPCA:\n","    #     columns = x_tTransf[0].columns\n","    features_importance = None\n","    signals = None\n","    if type(modelObjs).__name__ == 'MyLinearRegressor':\n","        try: modelObj = modelObjs.model\n","        except: modelObj = modelObjs\n","        coefs = modelObj.coef_[0]\n","        features_importance = abs(coefs)\n","        nPredictors = len(features_importance)\n","        signals = ['(~)']*nPredictors\n","        for i in range(nPredictors):\n","            if coefs[i] < 0: \n","                signals[i] = '(-)'\n","            elif coefs[i] > 0:\n","                signals[i] = '(+)'\n","            else:\n","                signals[i] = '(without)'\n","    else:\n","        features_importance = modelObj.feature_importances_ \n","        nPredictors = len(features_importance)\n","        signals = ['(+)']*nPredictors\n","    fi = pd.DataFrame(data={'importance': features_importance, 'signal': signals},\n","            index=columns)\n","    fi = fi.sort_values('importance', ascending=False)#.plot(kind='barh', title='Feature Importance')\n","    if nFeatures is None:\n","        nFeatures = nPredictors\n","    print('|| importantFeatures:  \\n', fi.head(nFeatures))\n","    importantFeatures = []\n","    for case in fi.index[:nFeatures]:\n","        importantFeatures.append(case)\n","    # print(res)\n","    importantFeatures = list(dict.fromkeys(importantFeatures))\n","    # print('|| importantFeatures: ', u, importantFeatures)    \n","    return importantFeatures\n","\n","yLinearImportantFeatures = None\n","if isToRunInitialModels['MyLinearRegressor']:\n","    yLinearImportantFeatures = getFeaturesImportance(modelObjs = getFormalismDictionary(yModels, 'yMyLinear'), \n","                                                    nFeatures = None)\n"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.035577Z","iopub.status.busy":"2023-05-05T21:26:03.034731Z","iopub.status.idle":"2023-05-05T21:26:03.056490Z","shell.execute_reply":"2023-05-05T21:26:03.054847Z","shell.execute_reply.started":"2023-05-05T21:26:03.035538Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['EJ',\n"," 'DU',\n"," 'FD',\n"," 'CH',\n"," 'FI',\n"," 'AB',\n"," 'DI',\n"," 'BQ',\n"," 'EP',\n"," 'DN',\n"," 'DY',\n"," 'CW',\n"," 'FL',\n"," 'AX',\n"," 'EE',\n"," 'AZ',\n"," 'CD',\n"," 'GB',\n"," 'EB',\n"," 'DA',\n"," 'BC',\n"," 'AR',\n"," 'DH',\n"," 'GH',\n"," 'CU',\n"," 'GL',\n"," 'GE',\n"," 'FR',\n"," 'CB',\n"," 'FC',\n"," 'FE',\n"," 'CL',\n"," 'EH',\n"," 'FS',\n"," 'CR',\n"," 'AH',\n"," 'DV',\n"," 'GI',\n"," 'EG',\n"," 'EL',\n"," 'BZ',\n"," 'AM',\n"," 'BR',\n"," 'AY',\n"," 'AF',\n"," 'EU',\n"," 'DL',\n"," 'CS',\n"," 'BN',\n"," 'GF',\n"," 'CF',\n"," 'CC',\n"," 'BP',\n"," 'BD',\n"," 'DF',\n"," 'DE']"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["yLinearImportantFeatures"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Error (Boosting) models"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/plain":["{0:      yMyLinear  yMyLogistic    yMySVC   yMyLGBM  yMyDecisionTree   \n"," 1     0.000000    -0.000029 -0.024498 -0.118632         0.000000  \\\n"," 11    0.000000    -0.002886 -0.098927 -0.068095        -0.305556   \n"," 13    0.301340     0.061189  0.084033  0.171858         0.694444   \n"," 14    0.000000    -0.000315 -0.075178 -0.151792         0.000000   \n"," 16    0.000000    -0.017276 -0.090807 -0.026984         0.000000   \n"," ..         ...          ...       ...       ...              ...   \n"," 581   0.000000    -0.078606 -0.105986 -0.393570        -0.305556   \n"," 597   0.000000    -0.000672 -0.015099 -0.011506         0.000000   \n"," 608   0.231405     0.162125  0.040419  0.497003         0.363636   \n"," 609   0.000000    -0.008105 -0.041366 -0.097864         0.000000   \n"," 616   0.000000    -0.001070 -0.047146 -0.037034         0.000000   \n"," \n","      yMyRandomForest  yMyXGB  \n"," 1          -0.129254    -0.5  \n"," 11         -0.295384    -0.5  \n"," 13          0.618236     0.5  \n"," 14         -0.223691    -0.5  \n"," 16         -0.142018    -0.5  \n"," ..               ...     ...  \n"," 581        -0.256604    -0.5  \n"," 597        -0.086949    -0.5  \n"," 608         0.542253     0.5  \n"," 609        -0.118544    -0.5  \n"," 616        -0.161636    -0.5  \n"," \n"," [154 rows x 7 columns],\n"," 1:      yMyLinear  yMyLogistic    yMySVC   yMyLGBM  yMyDecisionTree   \n"," 0     0.374744     0.001041  0.288683  0.273043         0.363636  \\\n"," 1     0.000000    -0.000029 -0.024498 -0.118632         0.000000   \n"," 6     0.000000    -0.000027 -0.057505 -0.010547         0.000000   \n"," 7     0.000000    -0.000156 -0.019171 -0.104368        -0.636364   \n"," 11    0.000000    -0.002886 -0.098927 -0.068095        -0.305556   \n"," ..         ...          ...       ...       ...              ...   \n"," 609   0.000000    -0.008105 -0.041366 -0.097864         0.000000   \n"," 611   0.000000    -0.000003 -0.003660 -0.009079         0.000000   \n"," 612  -0.121859    -0.020559 -0.101963 -0.039339         0.000000   \n"," 614   0.000000    -0.012987 -0.023796 -0.043683         0.000000   \n"," 616   0.000000    -0.001070 -0.047146 -0.037034         0.000000   \n"," \n","      yMyRandomForest  yMyXGB  \n"," 0           0.608399     0.5  \n"," 1          -0.129254    -0.5  \n"," 6          -0.194839    -0.5  \n"," 7          -0.189518    -0.5  \n"," 11         -0.295384    -0.5  \n"," ..               ...     ...  \n"," 609        -0.118544    -0.5  \n"," 611        -0.073758    -0.5  \n"," 612        -0.128605    -0.5  \n"," 614        -0.092856    -0.5  \n"," 616        -0.161636    -0.5  \n"," \n"," [308 rows x 7 columns],\n"," 2: Empty DataFrame\n"," Columns: []\n"," Index: [0, 1, 2, 4, 6, 7, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 49, 50, 51, 53, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, ...]\n"," \n"," [463 rows x 0 columns],\n"," 3:      yMyLinear  yMyLogistic    yMySVC   yMyLGBM  yMyDecisionTree   \n"," 3    -0.179001    -0.345013 -0.284721 -0.476789        -0.636364  \\\n"," 5     0.000000    -0.002291 -0.068431 -0.050109         0.000000   \n"," 8     0.000000    -0.000476 -0.017932 -0.017509         0.000000   \n"," 12    0.000000    -0.023155 -0.070633 -0.020990         0.000000   \n"," 17    0.000000    -0.007397 -0.062780 -0.033350         0.000000   \n"," ..         ...          ...       ...       ...              ...   \n"," 599   0.000000    -0.000038 -0.052061 -0.218712        -0.305556   \n"," 602  -0.237656    -0.197431 -0.272673 -0.052714         0.000000   \n"," 610   0.000000    -0.003771 -0.283579 -0.343421        -0.305556   \n"," 613   0.000000    -0.001216 -0.280999 -0.061128         0.000000   \n"," 615  -0.021459    -0.019801 -0.115184 -0.050794         0.000000   \n"," \n","      yMyRandomForest  yMyXGB  \n"," 3          -0.205668    -0.5  \n"," 5          -0.102235    -0.5  \n"," 8          -0.120120    -0.5  \n"," 12         -0.162849    -0.5  \n"," 17         -0.138155    -0.5  \n"," ..               ...     ...  \n"," 599        -0.147116    -0.5  \n"," 602        -0.117539    -0.5  \n"," 610        -0.369028    -0.5  \n"," 613        -0.217638    -0.5  \n"," 615        -0.142099    -0.5  \n"," \n"," [154 rows x 7 columns]}"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["e_yPredictions"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.058761Z","iopub.status.busy":"2023-05-05T21:26:03.058348Z","iopub.status.idle":"2023-05-05T21:26:03.070682Z","shell.execute_reply":"2023-05-05T21:26:03.069422Z","shell.execute_reply.started":"2023-05-05T21:26:03.058727Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['yMyLinear', 'yMyLogistic', 'yMySVC', 'yMyLGBM', 'yMyDecisionTree',\n","       'yMyRandomForest', 'yMyXGB'],\n","      dtype='object')"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["e_yPredictions[0].columns"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.073228Z","iopub.status.busy":"2023-05-05T21:26:03.072042Z","iopub.status.idle":"2023-05-05T21:26:03.085740Z","shell.execute_reply":"2023-05-05T21:26:03.084275Z","shell.execute_reply.started":"2023-05-05T21:26:03.073183Z"},"trusted":true},"outputs":[],"source":["#computing the train and validation residuals\n","# for u in targetVars:\n","e_t = {}; e_v = {}\n","for yModel in yModels:\n","    e_t[yModel] = e_yPredictions[1][yModel]#getModelResiduals(u, 'df_t', yModel) #yModels[yModel], x_tTransf, y_t)    \n","    e_v[yModel] = e_yPredictions[3][yModel]#getModelResiduals(u, 'df_v', yModel) #yModels[yModel], x_vTransf, y_v)    \n"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.088293Z","iopub.status.busy":"2023-05-05T21:26:03.087591Z","iopub.status.idle":"2023-05-05T21:26:03.105360Z","shell.execute_reply":"2023-05-05T21:26:03.103847Z","shell.execute_reply.started":"2023-05-05T21:26:03.088249Z"},"trusted":true},"outputs":[],"source":["# getErrorModels(...): function for performing the residuals-based boosting\n","# import tensorflow as tf\n","# import copy\n","\n","\n","def getErrorModels(modelObjs, parsDists=None, parsGrid=None, nFeatures=None, toPrintFeaturesImportance=True):\n","    eModels = {}\n","    importantFeatures = {}  # yModelsDic={}\n","# for u in targetVars:\n","    formalism = type(modelObjs).__name__\n","    print('****** Error model.fit', formalism, u, ' ******')\n","    # eModels = {}\n","    isTfFormalism = True if (\n","        formalism == 'MyTfMLPRegressor' or formalism == 'MyTfRNNRegressor') else False\n","    # isMyBoostFormalism = True if (formalism == 'MyXGBRegressor' or formalism == 'MyLGBMRegressor') else False\n","    for yModel in e_t:\n","        # print('****** yModel', yModel, u, ' ******')\n","        # print(e_t[yModel])\n","        model = modelObjs\n","        modelName = getModelName(yModel, formalism)  # , u)\n","        x = x_tTransf[1]\n","        y = e_t[yModel]\n","        if parsGrid is not None:\n","            model = keras.wrappers.scikit_learn.KerasRegressor(\n","                model) if isTfFormalism else model\n","            eModels[yModel] = getOptimalModel(\n","                model, parsGrid, x, y, False, method='GridSearchCV', modelName=modelName)\n","        elif parsDists is not None:\n","            model = keras.wrappers.scikit_learn.KerasRegressor(\n","                model) if isTfFormalism else model\n","            eModels[yModel] = getOptimalModel(\n","                model, parsDists, x, y, False, method='BayesSearchCV', modelName=modelName)\n","        else:\n","            # if isTfFormalism or isMyBoostFormalism:\n","            model.fit(x, y, modelName)\n","            # else:\n","            #     model.fit(x, y)\n","            eModels[yModel] = model\n","        # importantFeatures = {}\n","        if toPrintFeaturesImportance:\n","            importantFeatures[yModel] = getFeaturesImportance(\n","                modelObjs=eModels[yModel], nFeatures=nFeatures)\n","    nCases = len(e_t)  # [targetVars[0]])\n","    i = 0\n","    for yModel in e_t:  # [targetVars[0]]:\n","        i += 1\n","        yModelDic = getFormalismDictionary(yModels, yModel)\n","        e_yModelDic = getFormalismDictionary(eModels, yModel)\n","        # print(yModelDic)\n","        printResults = True if i == nCases else False\n","        computePerformanceMeasures(yModel=yModelDic, phase=1, x_t=x_tTransf,\n","                                   y_t=y_t, eModel=e_yModelDic, printResults=printResults)\n","    return {'eModels': eModels, 'importantFeatures': importantFeatures}"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.107559Z","iopub.status.busy":"2023-05-05T21:26:03.107071Z","iopub.status.idle":"2023-05-05T21:26:03.125496Z","shell.execute_reply":"2023-05-05T21:26:03.124259Z","shell.execute_reply.started":"2023-05-05T21:26:03.107510Z"},"trusted":true},"outputs":[],"source":["#computeErrorModels for executing the getErrorModels for the desired formalism\n","def computeErrorModels(modelObj, parsDists, grids):\n","        eModelsObjs = {}\n","        # global u\n","        modelObj_ = modelObj if type(modelObj).__name__ != 'dict' else modelObj\n","        formalism = type(modelObj_).__name__\n","        eModelsObjs = errorModelsObjs[formalism] if (parsDists is None and grids is None) else modelObj_\n","        getErrorModels(eModelsObjs, parsDists, grids, nFeatures=50, toPrintFeaturesImportance=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Residuals-towards Decision Tree"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.127627Z","iopub.status.busy":"2023-05-05T21:26:03.126980Z","iopub.status.idle":"2023-05-05T21:26:03.139672Z","shell.execute_reply":"2023-05-05T21:26:03.138544Z","shell.execute_reply.started":"2023-05-05T21:26:03.127588Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["****** Error model.fit MyDecisionTreeRegressor Class  ******\n","==**** load_model yMyLinear_eMyDecisionTree ****==\n",">>> elapsed time: 0.0060002803802490234 seconds!\n","==**** load_model yMyLogistic_eMyDecisionTree ****==\n",">>> elapsed time: 0.0063321590423583984 seconds!\n","==**** load_model yMySVC_eMyDecisionTree ****==\n",">>> elapsed time: 0.005587100982666016 seconds!\n","==**** load_model yMyLGBM_eMyDecisionTree ****==\n",">>> elapsed time: 0.004975795745849609 seconds!\n","==**** load_model yMyDecisionTree_eMyDecisionTree ****==\n",">>> elapsed time: 0.0039904117584228516 seconds!\n","==**** load_model yMyRandomForest_eMyDecisionTree ****==\n",">>> elapsed time: 0.005005598068237305 seconds!\n","==**** load_model yMyXGB_eMyDecisionTree ****==\n",">>> elapsed time: 0.006002187728881836 seconds!\n"," *********** Best models via SMAPE in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bestModel</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyLogistic</td>\n","      <td>0.108</td>\n","      <td>0.55</td>\n","      <td>0.442</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     bestModel  logLoss_t  logLoss_v  logLoss_dif_vt\n","0  yMyLogistic      0.108       0.55           0.442"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" *********** Rank via logLoss in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>yMyLogistic</td>\n","      <td>0.108</td>\n","      <td>0.550</td>\n","      <td>0.442</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yMyLGBM</td>\n","      <td>0.273</td>\n","      <td>0.655</td>\n","      <td>0.382</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yMySVC</td>\n","      <td>0.404</td>\n","      <td>0.685</td>\n","      <td>0.281</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>yMyXGB</td>\n","      <td>0.693</td>\n","      <td>0.693</td>\n","      <td>0.000</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>yMyXGB_eMyDecisionTree</td>\n","      <td>0.884</td>\n","      <td>0.746</td>\n","      <td>-0.138</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>yMyRandomForest</td>\n","      <td>0.777</td>\n","      <td>0.910</td>\n","      <td>0.133</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>yMyLogistic_eMyDecisionTree</td>\n","      <td>0.882</td>\n","      <td>1.399</td>\n","      <td>0.517</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>yMySVC_eMyDecisionTree</td>\n","      <td>1.528</td>\n","      <td>1.452</td>\n","      <td>-0.076</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>yMyLinear_eMyDecisionTree</td>\n","      <td>1.690</td>\n","      <td>2.533</td>\n","      <td>0.843</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>yMyDecisionTree</td>\n","      <td>0.594</td>\n","      <td>2.544</td>\n","      <td>1.950</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyLinear</td>\n","      <td>0.508</td>\n","      <td>2.571</td>\n","      <td>2.063</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>yMyLGBM_eMyDecisionTree</td>\n","      <td>3.071</td>\n","      <td>3.425</td>\n","      <td>0.354</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>yMyRandomForest_eMyDecisionTree</td>\n","      <td>6.016</td>\n","      <td>4.578</td>\n","      <td>-1.438</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>yMyDecisionTree_eMyDecisionTree</td>\n","      <td>5.888</td>\n","      <td>5.347</td>\n","      <td>-0.541</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              model  logLoss_t  logLoss_v  logLoss_dif_vt\n","1                       yMyLogistic      0.108      0.550           0.442\n","3                           yMyLGBM      0.273      0.655           0.382\n","2                            yMySVC      0.404      0.685           0.281\n","6                            yMyXGB      0.693      0.693           0.000\n","13           yMyXGB_eMyDecisionTree      0.884      0.746          -0.138\n","5                   yMyRandomForest      0.777      0.910           0.133\n","8       yMyLogistic_eMyDecisionTree      0.882      1.399           0.517\n","9            yMySVC_eMyDecisionTree      1.528      1.452          -0.076\n","7         yMyLinear_eMyDecisionTree      1.690      2.533           0.843\n","4                   yMyDecisionTree      0.594      2.544           1.950\n","0                         yMyLinear      0.508      2.571           2.063\n","10          yMyLGBM_eMyDecisionTree      3.071      3.425           0.354\n","12  yMyRandomForest_eMyDecisionTree      6.016      4.578          -1.438\n","11  yMyDecisionTree_eMyDecisionTree      5.888      5.347          -0.541"]},"metadata":{},"output_type":"display_data"}],"source":["#modelling and evaluating\n","# from sklearn.tree import MyDecisionTreeRegressor\n","if isToRunErrorModels['MyDecisionTreeRegressor']:\n","    grids = {}; parsDists = {}; \n","    # for u in targetVars:\n","    parsDists = None if not isWithOptimization else {\n","        'splitter': [\"best\", \"random\"],  # categorical parameter\n","        'max_depth': (1, 10),  # integer valued parameter\n","        'min_samples_split': (2, 500),\n","        'min_samples_leaf': (1, 50),\n","        'max_features': (1, x_tTransf[0].shape[1]),\n","        # log-uniform: understand as search over p = exp(x) by varying x\n","        'ccp_alpha': (1e-10, 1e+1, 'log-uniform')\n","    }\n","    grids = None if not isWithOptimization else { \n","                'min_samples_leaf': [2, 5, 50, 80, 100],\n","                'min_samples_split': [2, 50, 500, 1000],\n","    }\n","    computeErrorModels(MyDecisionTreeRegressor(), parsDists, grids)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Residuals-towards Light GBM Regression"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.141686Z","iopub.status.busy":"2023-05-05T21:26:03.141110Z","iopub.status.idle":"2023-05-05T21:26:03.159860Z","shell.execute_reply":"2023-05-05T21:26:03.158239Z","shell.execute_reply.started":"2023-05-05T21:26:03.141650Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["****** Error model.fit MyLGBMRegressor Class  ******\n"]},{"name":"stdout","output_type":"stream","text":["==**** load_model yMyLinear_eMyLGBM ****==\n",">>> elapsed time: 42.61136317253113 seconds!\n","==**** load_model yMyLogistic_eMyLGBM ****==\n",">>> elapsed time: 43.05819773674011 seconds!\n","==**** load_model yMySVC_eMyLGBM ****==\n",">>> elapsed time: 68.36393570899963 seconds!\n","==**** load_model yMyLGBM_eMyLGBM ****==\n",">>> elapsed time: 102.81850123405457 seconds!\n","==**** load_model yMyDecisionTree_eMyLGBM ****==\n",">>> elapsed time: 8.969510793685913 seconds!\n","==**** load_model yMyRandomForest_eMyLGBM ****==\n",">>> elapsed time: 8.173982858657837 seconds!\n","==**** fit yMyXGB_eMyLGBM ****==\n"]},{"ename":"AttributeError","evalue":"'Booster' object has no attribute 'fit'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 360\u001b[0m, in \u001b[0;36mMyLGBM.loadModel\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 360\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mBooster(model_file\u001b[39m=\u001b[39;49mpath)\n\u001b[0;32m    361\u001b[0m \u001b[39mexcept\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\praf6\\miniconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py:2639\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_void_p()\n\u001b[1;32m-> 2639\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterCreateFromModelfile(\n\u001b[0;32m   2640\u001b[0m     c_str(\u001b[39mstr\u001b[39;49m(model_file)),\n\u001b[0;32m   2641\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(out_num_iterations),\n\u001b[0;32m   2642\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle)))\n\u001b[0;32m   2643\u001b[0m out_num_class \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int(\u001b[39m0\u001b[39m)\n","File \u001b[1;32mc:\\Users\\praf6\\miniconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n","\u001b[1;31mLightGBMError\u001b[0m: Could not open C:/Users/praf6/OneDrive - Universidade Federal do Cariri - UFCA/Drive/UFCA/Ensino/CRAN R_aulas/kaggleFiles/results/ageRelatedConditions/Models/withoutPCA/withoutOptimization/yMyXGB_eMyLGBM.txt","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 390\u001b[0m, in \u001b[0;36mMyLGBM.fit\u001b[1;34m(self, X, y, modelName)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloadModel(path)\n\u001b[0;32m    391\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m==**** load_model\u001b[39m\u001b[39m'\u001b[39m, modelNm, \u001b[39m'\u001b[39m\u001b[39m****==\u001b[39m\u001b[39m'\u001b[39m)\n","Cell \u001b[1;32mIn[7], line 365\u001b[0m, in \u001b[0;36mMyLGBM.loadModel\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    364\u001b[0m     path2 \u001b[39m=\u001b[39m foldersVerification(RESULTS_ROOT)\u001b[39m+\u001b[39mfileNm\n\u001b[1;32m--> 365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mBooster(model_file\u001b[39m=\u001b[39;49mpath2)\n\u001b[0;32m    366\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n","File \u001b[1;32mc:\\Users\\praf6\\miniconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py:2639\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_void_p()\n\u001b[1;32m-> 2639\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterCreateFromModelfile(\n\u001b[0;32m   2640\u001b[0m     c_str(\u001b[39mstr\u001b[39;49m(model_file)),\n\u001b[0;32m   2641\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(out_num_iterations),\n\u001b[0;32m   2642\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle)))\n\u001b[0;32m   2643\u001b[0m out_num_class \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int(\u001b[39m0\u001b[39m)\n","File \u001b[1;32mc:\\Users\\praf6\\miniconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n","\u001b[1;31mLightGBMError\u001b[0m: Could not open C:/Users/praf6/OneDrive - Universidade Federal do Cariri - UFCA/Drive/UFCA/Ensino/CRAN R_aulas/kaggleFiles/results/ageRelatedConditions/Models/withoutPCA/withoutOptimization/yMyXGB_eMyLGBM.txt","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[82], line 14\u001b[0m\n\u001b[0;32m      7\u001b[0m     parsDists \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mnum_leaves\u001b[39m\u001b[39m'\u001b[39m: (\u001b[39m2\u001b[39m, \u001b[39m300\u001b[39m),\n\u001b[0;32m      8\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: (\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m),\n\u001b[0;32m      9\u001b[0m         \u001b[39m# 'learning_rate':(.1, 1, 'uniform'),\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: (\u001b[39m2\u001b[39m, \u001b[39m300\u001b[39m)} \u001b[39mif\u001b[39;00m isWithOptimization \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     gridLg \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isWithOptimization \u001b[39melse\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m50\u001b[39m],\n\u001b[0;32m     12\u001b[0m         \u001b[39m# 'learning_rate':(.1, 2, 'uniform'),\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m100\u001b[39m]}\n\u001b[1;32m---> 14\u001b[0m computeErrorModels(MyLGBMRegressor(), parsDists, gridLg), \u001b[39m#parsDists, \u001b[39;00m\n\u001b[0;32m     15\u001b[0m                                     \u001b[39m#    n_estimators=5, max_depth=10),  # )\u001b[39;00m\n","Cell \u001b[1;32mIn[78], line 8\u001b[0m, in \u001b[0;36mcomputeErrorModels\u001b[1;34m(modelObj, parsDists, grids)\u001b[0m\n\u001b[0;32m      6\u001b[0m formalism \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(modelObj_)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m      7\u001b[0m eModelsObjs \u001b[39m=\u001b[39m errorModelsObjs[formalism] \u001b[39mif\u001b[39;00m (parsDists \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m grids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39melse\u001b[39;00m modelObj_\n\u001b[1;32m----> 8\u001b[0m getErrorModels(eModelsObjs, parsDists, grids, nFeatures\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, toPrintFeaturesImportance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n","Cell \u001b[1;32mIn[77], line 35\u001b[0m, in \u001b[0;36mgetErrorModels\u001b[1;34m(modelObjs, parsDists, parsGrid, nFeatures, toPrintFeaturesImportance)\u001b[0m\n\u001b[0;32m     31\u001b[0m     eModels[yModel] \u001b[39m=\u001b[39m getOptimalModel(\n\u001b[0;32m     32\u001b[0m         model, parsDists, x, y, \u001b[39mFalse\u001b[39;00m, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBayesSearchCV\u001b[39m\u001b[39m'\u001b[39m, modelName\u001b[39m=\u001b[39mmodelName)\n\u001b[0;32m     33\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[39m# if isTfFormalism or isMyBoostFormalism:\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     model\u001b[39m.\u001b[39;49mfit(x, y, modelName)\n\u001b[0;32m     36\u001b[0m     \u001b[39m# else:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[39m#     model.fit(x, y)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     eModels[yModel] \u001b[39m=\u001b[39m model\n","Cell \u001b[1;32mIn[7], line 397\u001b[0m, in \u001b[0;36mMyLGBM.fit\u001b[1;34m(self, X, y, modelName)\u001b[0m\n\u001b[0;32m    394\u001b[0m     X_train, X_validation, y_train, y_validation \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m    395\u001b[0m         X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    396\u001b[0m     eval_set \u001b[39m=\u001b[39m [(X_validation, y_validation)]\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(X_train, y_train, eval_metric\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric, eval_set\u001b[39m=\u001b[39meval_set, early_stopping_rounds\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[0;32m    398\u001b[0m                    verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    399\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msaveModel(path)\n\u001b[0;32m    400\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m>>> elapsed time:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mstr\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start), \u001b[39m'\u001b[39m\u001b[39mseconds!\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'fit'"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["# https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n","# !pip install lightgbm\n","# import lightgbm as lgb\n","if isToRunErrorModels['MyLGBMRegressor']:\n","    gridLg = {}; parsDists = {}\n","    for u in targetVars:\n","        parsDists = {'num_leaves': (2, 300),\n","            'max_depth': (1, 50),\n","            # 'learning_rate':(.1, 1, 'uniform'),\n","            'n_estimators': (2, 300)} if isWithOptimization else None\n","        gridLg = None if not isWithOptimization else {'max_depth': [-1, 1, 10, 50],\n","            # 'learning_rate':(.1, 2, 'uniform'),\n","            'n_estimators': [2, 5, 50, 100]}\n","    computeErrorModels(MyLGBMRegressor(), parsDists, gridLg), #parsDists, \n","                                        #    n_estimators=5, max_depth=10),  # )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Residuals-towards Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.163009Z","iopub.status.busy":"2023-05-05T21:26:03.161879Z","iopub.status.idle":"2023-05-05T21:26:03.175860Z","shell.execute_reply":"2023-05-05T21:26:03.174269Z","shell.execute_reply.started":"2023-05-05T21:26:03.162966Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["****** Error model.fit MyRandomForestRegressor Class  ******\n","==**** load_model yMyLinear_eMyRandomForest ****==\n",">>> elapsed time: 0.05060076713562012 seconds!\n","==**** load_model yMyLogistic_eMyRandomForest ****==\n",">>> elapsed time: 0.0388033390045166 seconds!\n","==**** load_model yMySVC_eMyRandomForest ****==\n",">>> elapsed time: 0.03935956954956055 seconds!\n","==**** load_model yMyLGBM_eMyRandomForest ****==\n",">>> elapsed time: 0.04076361656188965 seconds!\n","==**** load_model yMyDecisionTree_eMyRandomForest ****==\n",">>> elapsed time: 0.04217338562011719 seconds!\n","==**** load_model yMyRandomForest_eMyRandomForest ****==\n",">>> elapsed time: 0.04135298728942871 seconds!\n","==**** load_model yMyXGB_eMyRandomForest ****==\n",">>> elapsed time: 0.03870725631713867 seconds!\n","==**** load_model yMyMLP_eMyRandomForest ****==\n",">>> elapsed time: 0.03980708122253418 seconds!\n","==**** load_model yMyTfMLP_eMyRandomForest ****==\n",">>> elapsed time: 0.0405881404876709 seconds!\n","==**** load_model yMyTfRNN_eMyRandomForest ****==\n",">>> elapsed time: 0.04062008857727051 seconds!\n"," *********** Best models via SMAPE in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bestModel</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyLogistic</td>\n","      <td>0.108</td>\n","      <td>0.55</td>\n","      <td>0.442</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     bestModel  logLoss_t  logLoss_v  logLoss_dif_vt\n","0  yMyLogistic      0.108       0.55           0.442"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" *********** Rank via logLoss in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>38</th>\n","      <td>yMyTfMLP_eMyRandomForest</td>\n","      <td>0.300</td>\n","      <td>0.438</td>\n","      <td>0.138</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>yMyLogistic_eMyLGBM</td>\n","      <td>0.207</td>\n","      <td>0.455</td>\n","      <td>0.248</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>yMyTfMLP_eMyDecisionTree</td>\n","      <td>0.651</td>\n","      <td>0.459</td>\n","      <td>-0.192</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>yMyTfMLP_eMyLGBM</td>\n","      <td>0.437</td>\n","      <td>0.485</td>\n","      <td>0.048</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>yMySVC_eMyLGBM</td>\n","      <td>0.353</td>\n","      <td>0.519</td>\n","      <td>0.166</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>yMyMLP_eMyRandomForest</td>\n","      <td>0.424</td>\n","      <td>0.538</td>\n","      <td>0.114</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>yMyLogistic</td>\n","      <td>0.108</td>\n","      <td>0.550</td>\n","      <td>0.442</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>yMyTfRNN_eMyRandomForest</td>\n","      <td>0.465</td>\n","      <td>0.592</td>\n","      <td>0.127</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>yMyTfMLP</td>\n","      <td>0.571</td>\n","      <td>0.649</td>\n","      <td>0.078</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yMyLGBM</td>\n","      <td>0.273</td>\n","      <td>0.655</td>\n","      <td>0.382</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>yMyXGB</td>\n","      <td>0.111</td>\n","      <td>0.668</td>\n","      <td>0.557</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yMySVC</td>\n","      <td>0.404</td>\n","      <td>0.685</td>\n","      <td>0.281</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>yMyRandomForest_eMyLGBM</td>\n","      <td>0.624</td>\n","      <td>0.695</td>\n","      <td>0.071</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>yMyTfRNN_eMyDecisionTree</td>\n","      <td>0.883</td>\n","      <td>0.746</td>\n","      <td>-0.137</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>yMyRandomForest</td>\n","      <td>0.777</td>\n","      <td>0.910</td>\n","      <td>0.133</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>yMyMLP_eMyLGBM</td>\n","      <td>0.896</td>\n","      <td>0.931</td>\n","      <td>0.035</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>yMyTfRNN_eMyLGBM</td>\n","      <td>0.921</td>\n","      <td>0.952</td>\n","      <td>0.031</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>yMyLGBM_eMyRandomForest</td>\n","      <td>0.207</td>\n","      <td>1.255</td>\n","      <td>1.048</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>yMyTfRNN</td>\n","      <td>1.224</td>\n","      <td>1.256</td>\n","      <td>0.032</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>yMyMLP</td>\n","      <td>1.125</td>\n","      <td>1.264</td>\n","      <td>0.139</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>yMySVC_eMyDecisionTree</td>\n","      <td>0.835</td>\n","      <td>1.296</td>\n","      <td>0.461</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>yMySVC_eMyRandomForest</td>\n","      <td>0.765</td>\n","      <td>1.296</td>\n","      <td>0.531</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>yMyLGBM_eMyDecisionTree</td>\n","      <td>2.405</td>\n","      <td>1.319</td>\n","      <td>-1.086</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>yMyLogistic_eMyRandomForest</td>\n","      <td>0.680</td>\n","      <td>1.344</td>\n","      <td>0.664</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>yMyLogistic_eMyDecisionTree</td>\n","      <td>0.736</td>\n","      <td>1.350</td>\n","      <td>0.614</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>yMyLinear_eMyRandomForest</td>\n","      <td>0.735</td>\n","      <td>1.356</td>\n","      <td>0.621</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>yMyRandomForest_eMyRandomForest</td>\n","      <td>0.300</td>\n","      <td>1.362</td>\n","      <td>1.062</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>yMyLinear_eMyDecisionTree</td>\n","      <td>0.837</td>\n","      <td>1.373</td>\n","      <td>0.536</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>yMyLGBM_eMyLGBM</td>\n","      <td>0.351</td>\n","      <td>1.422</td>\n","      <td>1.071</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>yMyRandomForest_eMyDecisionTree</td>\n","      <td>1.530</td>\n","      <td>1.434</td>\n","      <td>-0.096</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>yMyXGB_eMyLGBM</td>\n","      <td>0.772</td>\n","      <td>1.439</td>\n","      <td>0.667</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>yMyDecisionTree_eMyRandomForest</td>\n","      <td>0.566</td>\n","      <td>1.452</td>\n","      <td>0.886</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>yMyMLP_eMyDecisionTree</td>\n","      <td>2.754</td>\n","      <td>1.615</td>\n","      <td>-1.139</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>yMyDecisionTree_eMyDecisionTree</td>\n","      <td>1.338</td>\n","      <td>1.620</td>\n","      <td>0.282</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>yMyXGB_eMyRandomForest</td>\n","      <td>0.276</td>\n","      <td>2.295</td>\n","      <td>2.019</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>yMyXGB_eMyDecisionTree</td>\n","      <td>0.911</td>\n","      <td>2.333</td>\n","      <td>1.422</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>yMyDecisionTree_eMyLGBM</td>\n","      <td>1.003</td>\n","      <td>2.388</td>\n","      <td>1.385</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>yMyLinear_eMyLGBM</td>\n","      <td>0.408</td>\n","      <td>2.411</td>\n","      <td>2.003</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>yMyDecisionTree</td>\n","      <td>0.594</td>\n","      <td>2.544</td>\n","      <td>1.950</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyLinear</td>\n","      <td>0.508</td>\n","      <td>2.571</td>\n","      <td>2.063</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              model  logLoss_t  logLoss_v  logLoss_dif_vt\n","38         yMyTfMLP_eMyRandomForest      0.300      0.438           0.138\n","21              yMyLogistic_eMyLGBM      0.207      0.455           0.248\n","18         yMyTfMLP_eMyDecisionTree      0.651      0.459          -0.192\n","28                 yMyTfMLP_eMyLGBM      0.437      0.485           0.048\n","22                   yMySVC_eMyLGBM      0.353      0.519           0.166\n","37           yMyMLP_eMyRandomForest      0.424      0.538           0.114\n","1                       yMyLogistic      0.108      0.550           0.442\n","39         yMyTfRNN_eMyRandomForest      0.465      0.592           0.127\n","8                          yMyTfMLP      0.571      0.649           0.078\n","3                           yMyLGBM      0.273      0.655           0.382\n","6                            yMyXGB      0.111      0.668           0.557\n","2                            yMySVC      0.404      0.685           0.281\n","25          yMyRandomForest_eMyLGBM      0.624      0.695           0.071\n","19         yMyTfRNN_eMyDecisionTree      0.883      0.746          -0.137\n","5                   yMyRandomForest      0.777      0.910           0.133\n","27                   yMyMLP_eMyLGBM      0.896      0.931           0.035\n","29                 yMyTfRNN_eMyLGBM      0.921      0.952           0.031\n","33          yMyLGBM_eMyRandomForest      0.207      1.255           1.048\n","9                          yMyTfRNN      1.224      1.256           0.032\n","7                            yMyMLP      1.125      1.264           0.139\n","12           yMySVC_eMyDecisionTree      0.835      1.296           0.461\n","32           yMySVC_eMyRandomForest      0.765      1.296           0.531\n","13          yMyLGBM_eMyDecisionTree      2.405      1.319          -1.086\n","31      yMyLogistic_eMyRandomForest      0.680      1.344           0.664\n","11      yMyLogistic_eMyDecisionTree      0.736      1.350           0.614\n","30        yMyLinear_eMyRandomForest      0.735      1.356           0.621\n","35  yMyRandomForest_eMyRandomForest      0.300      1.362           1.062\n","10        yMyLinear_eMyDecisionTree      0.837      1.373           0.536\n","23                  yMyLGBM_eMyLGBM      0.351      1.422           1.071\n","15  yMyRandomForest_eMyDecisionTree      1.530      1.434          -0.096\n","26                   yMyXGB_eMyLGBM      0.772      1.439           0.667\n","34  yMyDecisionTree_eMyRandomForest      0.566      1.452           0.886\n","17           yMyMLP_eMyDecisionTree      2.754      1.615          -1.139\n","14  yMyDecisionTree_eMyDecisionTree      1.338      1.620           0.282\n","36           yMyXGB_eMyRandomForest      0.276      2.295           2.019\n","16           yMyXGB_eMyDecisionTree      0.911      2.333           1.422\n","24          yMyDecisionTree_eMyLGBM      1.003      2.388           1.385\n","20                yMyLinear_eMyLGBM      0.408      2.411           2.003\n","4                   yMyDecisionTree      0.594      2.544           1.950\n","0                         yMyLinear      0.508      2.571           2.063"]},"metadata":{},"output_type":"display_data"}],"source":["# from sklearn.ensemble import MyRandomForestRegressor \n","if isToRunErrorModels['MyRandomForestRegressor']:\n","    gridForest = {}; parsDists = {}\n","    # for u in targetVars:\n","    parsDists = {\n","                    'max_depth': (1, 200),  # integer valued parameter\n","                'min_samples_split': (.01, 1, 'uniform'),\n","                'min_samples_leaf': (1, 60),\n","                'n_estimators': (2, 600),\n","                    'max_features': (.1, .9, 'uniform'),\n","                # log-uniform: understand as search over p = exp(x) by varying x\n","                'ccp_alpha': (1e-10, 1e+1, 'log-uniform')\n","                } if isWithOptimization else None\n","    gridForest = None if not isWithOptimization else {'n_estimators':[10, 100, 200],\n","                'min_samples_split': [2, 50, 200, 500]}\n","    computeErrorModels(MyRandomForestRegressor(), parsDists, gridForest)# #parsDists, \n","                                                #    min_samples_split = 100, n_estimators = 100), "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Residuals-towards XGBoost Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.178403Z","iopub.status.busy":"2023-05-05T21:26:03.177717Z","iopub.status.idle":"2023-05-05T21:26:03.195869Z","shell.execute_reply":"2023-05-05T21:26:03.194187Z","shell.execute_reply.started":"2023-05-05T21:26:03.178306Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["****** Error model.fit MyXGBRegressor Class  ******\n","==**** load_model yMyLinear_eMyXGB ****==\n",">>> elapsed time: 0.0029916763305664062 seconds!\n","==**** load_model yMyLogistic_eMyXGB ****==\n",">>> elapsed time: 0.002002239227294922 seconds!\n","==**** load_model yMySVC_eMyXGB ****==\n",">>> elapsed time: 0.0009982585906982422 seconds!\n","==**** load_model yMyLGBM_eMyXGB ****==\n",">>> elapsed time: 0.0 seconds!\n","==**** load_model yMyDecisionTree_eMyXGB ****==\n",">>> elapsed time: 0.0010116100311279297 seconds!\n","==**** load_model yMyRandomForest_eMyXGB ****==\n",">>> elapsed time: 0.0009865760803222656 seconds!\n","==**** load_model yMyXGB_eMyXGB ****==\n",">>> elapsed time: 0.001001119613647461 seconds!\n","==**** load_model yMyMLP_eMyXGB ****==\n",">>> elapsed time: 0.0009999275207519531 seconds!\n","==**** load_model yMyTfMLP_eMyXGB ****==\n",">>> elapsed time: 0.0 seconds!\n","==**** load_model yMyTfRNN_eMyXGB ****==\n",">>> elapsed time: 0.001013040542602539 seconds!\n"," *********** Best models via SMAPE in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bestModel</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         bestModel  logLoss_t  logLoss_v  logLoss_dif_vt\n","0  yMyTfMLP_eMyXGB      0.036      0.299           0.263"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" *********** Rank via logLoss in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>48</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>yMyRandomForest_eMyXGB</td>\n","      <td>0.040</td>\n","      <td>0.368</td>\n","      <td>0.328</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>yMyMLP_eMyXGB</td>\n","      <td>0.100</td>\n","      <td>0.373</td>\n","      <td>0.273</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>yMyTfRNN_eMyXGB</td>\n","      <td>0.076</td>\n","      <td>0.398</td>\n","      <td>0.322</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>yMyTfMLP_eMyRandomForest</td>\n","      <td>0.300</td>\n","      <td>0.438</td>\n","      <td>0.138</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>yMyLogistic_eMyLGBM</td>\n","      <td>0.207</td>\n","      <td>0.455</td>\n","      <td>0.248</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>yMyTfMLP_eMyDecisionTree</td>\n","      <td>0.651</td>\n","      <td>0.459</td>\n","      <td>-0.192</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>yMyTfMLP_eMyLGBM</td>\n","      <td>0.437</td>\n","      <td>0.485</td>\n","      <td>0.048</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>yMySVC_eMyLGBM</td>\n","      <td>0.353</td>\n","      <td>0.519</td>\n","      <td>0.166</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>yMyMLP_eMyRandomForest</td>\n","      <td>0.424</td>\n","      <td>0.538</td>\n","      <td>0.114</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>yMyLogistic</td>\n","      <td>0.108</td>\n","      <td>0.550</td>\n","      <td>0.442</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>yMyTfRNN_eMyRandomForest</td>\n","      <td>0.465</td>\n","      <td>0.592</td>\n","      <td>0.127</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>yMyTfMLP</td>\n","      <td>0.571</td>\n","      <td>0.649</td>\n","      <td>0.078</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yMyLGBM</td>\n","      <td>0.273</td>\n","      <td>0.655</td>\n","      <td>0.382</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>yMyXGB</td>\n","      <td>0.111</td>\n","      <td>0.668</td>\n","      <td>0.557</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yMySVC</td>\n","      <td>0.404</td>\n","      <td>0.685</td>\n","      <td>0.281</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>yMyRandomForest_eMyLGBM</td>\n","      <td>0.624</td>\n","      <td>0.695</td>\n","      <td>0.071</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>yMyTfRNN_eMyDecisionTree</td>\n","      <td>0.883</td>\n","      <td>0.746</td>\n","      <td>-0.137</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>yMyRandomForest</td>\n","      <td>0.777</td>\n","      <td>0.910</td>\n","      <td>0.133</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>yMyMLP_eMyLGBM</td>\n","      <td>0.896</td>\n","      <td>0.931</td>\n","      <td>0.035</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>yMyTfRNN_eMyLGBM</td>\n","      <td>0.921</td>\n","      <td>0.952</td>\n","      <td>0.031</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>yMySVC_eMyXGB</td>\n","      <td>0.019</td>\n","      <td>1.216</td>\n","      <td>1.197</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>yMyLGBM_eMyXGB</td>\n","      <td>0.045</td>\n","      <td>1.240</td>\n","      <td>1.195</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>yMyLGBM_eMyRandomForest</td>\n","      <td>0.207</td>\n","      <td>1.255</td>\n","      <td>1.048</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>yMyTfRNN</td>\n","      <td>1.224</td>\n","      <td>1.256</td>\n","      <td>0.032</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>yMyMLP</td>\n","      <td>1.125</td>\n","      <td>1.264</td>\n","      <td>0.139</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>yMyDecisionTree_eMyXGB</td>\n","      <td>0.061</td>\n","      <td>1.295</td>\n","      <td>1.234</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>yMySVC_eMyDecisionTree</td>\n","      <td>0.835</td>\n","      <td>1.296</td>\n","      <td>0.461</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>yMySVC_eMyRandomForest</td>\n","      <td>0.765</td>\n","      <td>1.296</td>\n","      <td>0.531</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>yMyLGBM_eMyDecisionTree</td>\n","      <td>2.405</td>\n","      <td>1.319</td>\n","      <td>-1.086</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>yMyLogistic_eMyXGB</td>\n","      <td>0.042</td>\n","      <td>1.328</td>\n","      <td>1.286</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>yMyLogistic_eMyRandomForest</td>\n","      <td>0.680</td>\n","      <td>1.344</td>\n","      <td>0.664</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>yMyLogistic_eMyDecisionTree</td>\n","      <td>0.736</td>\n","      <td>1.350</td>\n","      <td>0.614</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>yMyLinear_eMyRandomForest</td>\n","      <td>0.735</td>\n","      <td>1.356</td>\n","      <td>0.621</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>yMyRandomForest_eMyRandomForest</td>\n","      <td>0.300</td>\n","      <td>1.362</td>\n","      <td>1.062</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>yMyLinear_eMyDecisionTree</td>\n","      <td>0.837</td>\n","      <td>1.373</td>\n","      <td>0.536</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>yMyLGBM_eMyLGBM</td>\n","      <td>0.351</td>\n","      <td>1.422</td>\n","      <td>1.071</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>yMyRandomForest_eMyDecisionTree</td>\n","      <td>1.530</td>\n","      <td>1.434</td>\n","      <td>-0.096</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>yMyXGB_eMyLGBM</td>\n","      <td>0.772</td>\n","      <td>1.439</td>\n","      <td>0.667</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>yMyDecisionTree_eMyRandomForest</td>\n","      <td>0.566</td>\n","      <td>1.452</td>\n","      <td>0.886</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>yMyMLP_eMyDecisionTree</td>\n","      <td>2.754</td>\n","      <td>1.615</td>\n","      <td>-1.139</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>yMyDecisionTree_eMyDecisionTree</td>\n","      <td>1.338</td>\n","      <td>1.620</td>\n","      <td>0.282</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>yMyLinear_eMyXGB</td>\n","      <td>0.022</td>\n","      <td>2.216</td>\n","      <td>2.194</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>yMyXGB_eMyXGB</td>\n","      <td>0.048</td>\n","      <td>2.227</td>\n","      <td>2.179</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>yMyXGB_eMyRandomForest</td>\n","      <td>0.276</td>\n","      <td>2.295</td>\n","      <td>2.019</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>yMyXGB_eMyDecisionTree</td>\n","      <td>0.911</td>\n","      <td>2.333</td>\n","      <td>1.422</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>yMyDecisionTree_eMyLGBM</td>\n","      <td>1.003</td>\n","      <td>2.388</td>\n","      <td>1.385</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>yMyLinear_eMyLGBM</td>\n","      <td>0.408</td>\n","      <td>2.411</td>\n","      <td>2.003</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>yMyDecisionTree</td>\n","      <td>0.594</td>\n","      <td>2.544</td>\n","      <td>1.950</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyLinear</td>\n","      <td>0.508</td>\n","      <td>2.571</td>\n","      <td>2.063</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              model  logLoss_t  logLoss_v  logLoss_dif_vt\n","48                  yMyTfMLP_eMyXGB      0.036      0.299           0.263\n","45           yMyRandomForest_eMyXGB      0.040      0.368           0.328\n","47                    yMyMLP_eMyXGB      0.100      0.373           0.273\n","49                  yMyTfRNN_eMyXGB      0.076      0.398           0.322\n","38         yMyTfMLP_eMyRandomForest      0.300      0.438           0.138\n","21              yMyLogistic_eMyLGBM      0.207      0.455           0.248\n","18         yMyTfMLP_eMyDecisionTree      0.651      0.459          -0.192\n","28                 yMyTfMLP_eMyLGBM      0.437      0.485           0.048\n","22                   yMySVC_eMyLGBM      0.353      0.519           0.166\n","37           yMyMLP_eMyRandomForest      0.424      0.538           0.114\n","1                       yMyLogistic      0.108      0.550           0.442\n","39         yMyTfRNN_eMyRandomForest      0.465      0.592           0.127\n","8                          yMyTfMLP      0.571      0.649           0.078\n","3                           yMyLGBM      0.273      0.655           0.382\n","6                            yMyXGB      0.111      0.668           0.557\n","2                            yMySVC      0.404      0.685           0.281\n","25          yMyRandomForest_eMyLGBM      0.624      0.695           0.071\n","19         yMyTfRNN_eMyDecisionTree      0.883      0.746          -0.137\n","5                   yMyRandomForest      0.777      0.910           0.133\n","27                   yMyMLP_eMyLGBM      0.896      0.931           0.035\n","29                 yMyTfRNN_eMyLGBM      0.921      0.952           0.031\n","42                    yMySVC_eMyXGB      0.019      1.216           1.197\n","43                   yMyLGBM_eMyXGB      0.045      1.240           1.195\n","33          yMyLGBM_eMyRandomForest      0.207      1.255           1.048\n","9                          yMyTfRNN      1.224      1.256           0.032\n","7                            yMyMLP      1.125      1.264           0.139\n","44           yMyDecisionTree_eMyXGB      0.061      1.295           1.234\n","12           yMySVC_eMyDecisionTree      0.835      1.296           0.461\n","32           yMySVC_eMyRandomForest      0.765      1.296           0.531\n","13          yMyLGBM_eMyDecisionTree      2.405      1.319          -1.086\n","41               yMyLogistic_eMyXGB      0.042      1.328           1.286\n","31      yMyLogistic_eMyRandomForest      0.680      1.344           0.664\n","11      yMyLogistic_eMyDecisionTree      0.736      1.350           0.614\n","30        yMyLinear_eMyRandomForest      0.735      1.356           0.621\n","35  yMyRandomForest_eMyRandomForest      0.300      1.362           1.062\n","10        yMyLinear_eMyDecisionTree      0.837      1.373           0.536\n","23                  yMyLGBM_eMyLGBM      0.351      1.422           1.071\n","15  yMyRandomForest_eMyDecisionTree      1.530      1.434          -0.096\n","26                   yMyXGB_eMyLGBM      0.772      1.439           0.667\n","34  yMyDecisionTree_eMyRandomForest      0.566      1.452           0.886\n","17           yMyMLP_eMyDecisionTree      2.754      1.615          -1.139\n","14  yMyDecisionTree_eMyDecisionTree      1.338      1.620           0.282\n","40                 yMyLinear_eMyXGB      0.022      2.216           2.194\n","46                    yMyXGB_eMyXGB      0.048      2.227           2.179\n","36           yMyXGB_eMyRandomForest      0.276      2.295           2.019\n","16           yMyXGB_eMyDecisionTree      0.911      2.333           1.422\n","24          yMyDecisionTree_eMyLGBM      1.003      2.388           1.385\n","20                yMyLinear_eMyLGBM      0.408      2.411           2.003\n","4                   yMyDecisionTree      0.594      2.544           1.950\n","0                         yMyLinear      0.508      2.571           2.063"]},"metadata":{},"output_type":"display_data"}],"source":["# !pip install xgboost\n","# import xgboost as xg\n","if isToRunErrorModels['MyXGBRegressor']:\n","    gridXg = {}; parsDists = {}\n","    # for u in targetVars:    \n","    parsDists = {#'splitter': [\"best\", \"random\"],  # categorical parameter\n","            # 'max_depth': (1, 50),  # integer valued parameter\n","            # 'n_estimators': (2, 100),\n","            'eta': (.01, 1, 'log-uniform'), \n","            'gamma': (0, 1, 'uniform'),\n","            } if isWithOptimization else None\n","    gridXg = None if not isWithOptimization else {\n","        'max_depth': [1, 5, 6, 10],  \n","        #   'n_estimators': (3, 10, 20)\n","        'eta': [.1, 0.3, .6],\n","        'gamma': [0, 1, 2],\n","    }\n","    computeErrorModels(MyXGBRegressor(), parsDists, gridXg)#, #parsDists, #None, \n","                                # n_estimators = 3, max_depth = 5), "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["'8.13.2'"]},"execution_count":604,"metadata":{},"output_type":"execute_result"}],"source":["import IPython\n","IPython.__version__"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Residuals-towards Support Vector Regression - SVR"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.198076Z","iopub.status.busy":"2023-05-05T21:26:03.197648Z","iopub.status.idle":"2023-05-05T21:26:03.211782Z","shell.execute_reply":"2023-05-05T21:26:03.209934Z","shell.execute_reply.started":"2023-05-05T21:26:03.198013Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["****** Error model.fit MySVR Class  ******\n","==**** load_model yMyLinear_eMySVR ****==\n",">>> elapsed time: 0.002656221389770508 seconds!\n","==**** load_model yMyLogistic_eMySVR ****==\n",">>> elapsed time: 0.002004861831665039 seconds!\n","==**** load_model yMySVC_eMySVR ****==\n",">>> elapsed time: 0.002008199691772461 seconds!\n","==**** load_model yMyLGBM_eMySVR ****==\n",">>> elapsed time: 0.002321958541870117 seconds!\n","==**** load_model yMyDecisionTree_eMySVR ****==\n",">>> elapsed time: 0.0028040409088134766 seconds!\n","==**** load_model yMyRandomForest_eMySVR ****==\n",">>> elapsed time: 0.0019991397857666016 seconds!\n","==**** load_model yMyXGB_eMySVR ****==\n",">>> elapsed time: 0.0020711421966552734 seconds!\n","==**** load_model yMyMLP_eMySVR ****==\n",">>> elapsed time: 0.0025565624237060547 seconds!\n","==**** load_model yMyTfMLP_eMySVR ****==\n",">>> elapsed time: 0.0015811920166015625 seconds!\n","==**** load_model yMyTfRNN_eMySVR ****==\n",">>> elapsed time: 0.0026209354400634766 seconds!\n"," *********** Best models via SMAPE in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bestModel</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         bestModel  logLoss_t  logLoss_v  logLoss_dif_vt\n","0  yMyTfMLP_eMyXGB      0.036      0.299           0.263"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" *********** Rank via logLoss in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>48</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>yMyLGBM_eMySVR</td>\n","      <td>0.018</td>\n","      <td>0.363</td>\n","      <td>0.345</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>yMyRandomForest_eMyXGB</td>\n","      <td>0.040</td>\n","      <td>0.368</td>\n","      <td>0.328</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>yMyMLP_eMyXGB</td>\n","      <td>0.100</td>\n","      <td>0.373</td>\n","      <td>0.273</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>yMyDecisionTree_eMySVR</td>\n","      <td>0.027</td>\n","      <td>0.379</td>\n","      <td>0.352</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>yMyTfRNN_eMyXGB</td>\n","      <td>0.076</td>\n","      <td>0.398</td>\n","      <td>0.322</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>yMyTfMLP_eMyRandomForest</td>\n","      <td>0.300</td>\n","      <td>0.438</td>\n","      <td>0.138</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>yMyRandomForest_eMySVR</td>\n","      <td>0.018</td>\n","      <td>0.441</td>\n","      <td>0.423</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>yMyLogistic_eMyLGBM</td>\n","      <td>0.207</td>\n","      <td>0.455</td>\n","      <td>0.248</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>yMyTfMLP_eMyDecisionTree</td>\n","      <td>0.651</td>\n","      <td>0.459</td>\n","      <td>-0.192</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>yMyTfMLP_eMyLGBM</td>\n","      <td>0.437</td>\n","      <td>0.485</td>\n","      <td>0.048</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>yMyTfMLP_eMySVR</td>\n","      <td>0.045</td>\n","      <td>0.494</td>\n","      <td>0.449</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>yMyMLP_eMySVR</td>\n","      <td>0.070</td>\n","      <td>0.502</td>\n","      <td>0.432</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>yMySVC_eMyLGBM</td>\n","      <td>0.353</td>\n","      <td>0.519</td>\n","      <td>0.166</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>yMyMLP_eMyRandomForest</td>\n","      <td>0.424</td>\n","      <td>0.538</td>\n","      <td>0.114</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>yMyTfRNN_eMySVR</td>\n","      <td>0.079</td>\n","      <td>0.544</td>\n","      <td>0.465</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>yMyLogistic</td>\n","      <td>0.108</td>\n","      <td>0.550</td>\n","      <td>0.442</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>yMyTfRNN_eMyRandomForest</td>\n","      <td>0.465</td>\n","      <td>0.592</td>\n","      <td>0.127</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>yMyTfMLP</td>\n","      <td>0.571</td>\n","      <td>0.649</td>\n","      <td>0.078</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yMyLGBM</td>\n","      <td>0.273</td>\n","      <td>0.655</td>\n","      <td>0.382</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>yMyXGB</td>\n","      <td>0.111</td>\n","      <td>0.668</td>\n","      <td>0.557</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yMySVC</td>\n","      <td>0.404</td>\n","      <td>0.685</td>\n","      <td>0.281</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>yMyRandomForest_eMyLGBM</td>\n","      <td>0.624</td>\n","      <td>0.695</td>\n","      <td>0.071</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>yMyTfRNN_eMyDecisionTree</td>\n","      <td>0.883</td>\n","      <td>0.746</td>\n","      <td>-0.137</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>yMyRandomForest</td>\n","      <td>0.777</td>\n","      <td>0.910</td>\n","      <td>0.133</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>yMyMLP_eMyLGBM</td>\n","      <td>0.896</td>\n","      <td>0.931</td>\n","      <td>0.035</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>yMyTfRNN_eMyLGBM</td>\n","      <td>0.921</td>\n","      <td>0.952</td>\n","      <td>0.031</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>yMySVC_eMyXGB</td>\n","      <td>0.019</td>\n","      <td>1.216</td>\n","      <td>1.197</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>yMyLGBM_eMyXGB</td>\n","      <td>0.045</td>\n","      <td>1.240</td>\n","      <td>1.195</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>yMyLGBM_eMyRandomForest</td>\n","      <td>0.207</td>\n","      <td>1.255</td>\n","      <td>1.048</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>yMyTfRNN</td>\n","      <td>1.224</td>\n","      <td>1.256</td>\n","      <td>0.032</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>yMyMLP</td>\n","      <td>1.125</td>\n","      <td>1.264</td>\n","      <td>0.139</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>yMyXGB_eMySVR</td>\n","      <td>0.020</td>\n","      <td>1.281</td>\n","      <td>1.261</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>yMyDecisionTree_eMyXGB</td>\n","      <td>0.061</td>\n","      <td>1.295</td>\n","      <td>1.234</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>yMySVC_eMyDecisionTree</td>\n","      <td>0.835</td>\n","      <td>1.296</td>\n","      <td>0.461</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>yMySVC_eMyRandomForest</td>\n","      <td>0.765</td>\n","      <td>1.296</td>\n","      <td>0.531</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>yMyLGBM_eMyDecisionTree</td>\n","      <td>2.405</td>\n","      <td>1.319</td>\n","      <td>-1.086</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>yMyLogistic_eMyXGB</td>\n","      <td>0.042</td>\n","      <td>1.328</td>\n","      <td>1.286</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>yMyLogistic_eMyRandomForest</td>\n","      <td>0.680</td>\n","      <td>1.344</td>\n","      <td>0.664</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>yMyLogistic_eMyDecisionTree</td>\n","      <td>0.736</td>\n","      <td>1.350</td>\n","      <td>0.614</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>yMyLinear_eMyRandomForest</td>\n","      <td>0.735</td>\n","      <td>1.356</td>\n","      <td>0.621</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>yMyRandomForest_eMyRandomForest</td>\n","      <td>0.300</td>\n","      <td>1.362</td>\n","      <td>1.062</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>yMyLinear_eMyDecisionTree</td>\n","      <td>0.837</td>\n","      <td>1.373</td>\n","      <td>0.536</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>yMyLGBM_eMyLGBM</td>\n","      <td>0.351</td>\n","      <td>1.422</td>\n","      <td>1.071</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>yMyRandomForest_eMyDecisionTree</td>\n","      <td>1.530</td>\n","      <td>1.434</td>\n","      <td>-0.096</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>yMyXGB_eMyLGBM</td>\n","      <td>0.772</td>\n","      <td>1.439</td>\n","      <td>0.667</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>yMyDecisionTree_eMyRandomForest</td>\n","      <td>0.566</td>\n","      <td>1.452</td>\n","      <td>0.886</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>yMySVC_eMySVR</td>\n","      <td>0.030</td>\n","      <td>1.467</td>\n","      <td>1.437</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>yMyMLP_eMyDecisionTree</td>\n","      <td>2.754</td>\n","      <td>1.615</td>\n","      <td>-1.139</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>yMyDecisionTree_eMyDecisionTree</td>\n","      <td>1.338</td>\n","      <td>1.620</td>\n","      <td>0.282</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>yMyLinear_eMyXGB</td>\n","      <td>0.022</td>\n","      <td>2.216</td>\n","      <td>2.194</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>yMyXGB_eMyXGB</td>\n","      <td>0.048</td>\n","      <td>2.227</td>\n","      <td>2.179</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>yMyXGB_eMyRandomForest</td>\n","      <td>0.276</td>\n","      <td>2.295</td>\n","      <td>2.019</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>yMyXGB_eMyDecisionTree</td>\n","      <td>0.911</td>\n","      <td>2.333</td>\n","      <td>1.422</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>yMyLogistic_eMySVR</td>\n","      <td>0.021</td>\n","      <td>2.366</td>\n","      <td>2.345</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>yMyLinear_eMySVR</td>\n","      <td>0.020</td>\n","      <td>2.367</td>\n","      <td>2.347</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>yMyDecisionTree_eMyLGBM</td>\n","      <td>1.003</td>\n","      <td>2.388</td>\n","      <td>1.385</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>yMyLinear_eMyLGBM</td>\n","      <td>0.408</td>\n","      <td>2.411</td>\n","      <td>2.003</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>yMyDecisionTree</td>\n","      <td>0.594</td>\n","      <td>2.544</td>\n","      <td>1.950</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyLinear</td>\n","      <td>0.508</td>\n","      <td>2.571</td>\n","      <td>2.063</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              model  logLoss_t  logLoss_v  logLoss_dif_vt\n","48                  yMyTfMLP_eMyXGB      0.036      0.299           0.263\n","53                   yMyLGBM_eMySVR      0.018      0.363           0.345\n","45           yMyRandomForest_eMyXGB      0.040      0.368           0.328\n","47                    yMyMLP_eMyXGB      0.100      0.373           0.273\n","54           yMyDecisionTree_eMySVR      0.027      0.379           0.352\n","49                  yMyTfRNN_eMyXGB      0.076      0.398           0.322\n","38         yMyTfMLP_eMyRandomForest      0.300      0.438           0.138\n","55           yMyRandomForest_eMySVR      0.018      0.441           0.423\n","21              yMyLogistic_eMyLGBM      0.207      0.455           0.248\n","18         yMyTfMLP_eMyDecisionTree      0.651      0.459          -0.192\n","28                 yMyTfMLP_eMyLGBM      0.437      0.485           0.048\n","58                  yMyTfMLP_eMySVR      0.045      0.494           0.449\n","57                    yMyMLP_eMySVR      0.070      0.502           0.432\n","22                   yMySVC_eMyLGBM      0.353      0.519           0.166\n","37           yMyMLP_eMyRandomForest      0.424      0.538           0.114\n","59                  yMyTfRNN_eMySVR      0.079      0.544           0.465\n","1                       yMyLogistic      0.108      0.550           0.442\n","39         yMyTfRNN_eMyRandomForest      0.465      0.592           0.127\n","8                          yMyTfMLP      0.571      0.649           0.078\n","3                           yMyLGBM      0.273      0.655           0.382\n","6                            yMyXGB      0.111      0.668           0.557\n","2                            yMySVC      0.404      0.685           0.281\n","25          yMyRandomForest_eMyLGBM      0.624      0.695           0.071\n","19         yMyTfRNN_eMyDecisionTree      0.883      0.746          -0.137\n","5                   yMyRandomForest      0.777      0.910           0.133\n","27                   yMyMLP_eMyLGBM      0.896      0.931           0.035\n","29                 yMyTfRNN_eMyLGBM      0.921      0.952           0.031\n","42                    yMySVC_eMyXGB      0.019      1.216           1.197\n","43                   yMyLGBM_eMyXGB      0.045      1.240           1.195\n","33          yMyLGBM_eMyRandomForest      0.207      1.255           1.048\n","9                          yMyTfRNN      1.224      1.256           0.032\n","7                            yMyMLP      1.125      1.264           0.139\n","56                    yMyXGB_eMySVR      0.020      1.281           1.261\n","44           yMyDecisionTree_eMyXGB      0.061      1.295           1.234\n","12           yMySVC_eMyDecisionTree      0.835      1.296           0.461\n","32           yMySVC_eMyRandomForest      0.765      1.296           0.531\n","13          yMyLGBM_eMyDecisionTree      2.405      1.319          -1.086\n","41               yMyLogistic_eMyXGB      0.042      1.328           1.286\n","31      yMyLogistic_eMyRandomForest      0.680      1.344           0.664\n","11      yMyLogistic_eMyDecisionTree      0.736      1.350           0.614\n","30        yMyLinear_eMyRandomForest      0.735      1.356           0.621\n","35  yMyRandomForest_eMyRandomForest      0.300      1.362           1.062\n","10        yMyLinear_eMyDecisionTree      0.837      1.373           0.536\n","23                  yMyLGBM_eMyLGBM      0.351      1.422           1.071\n","15  yMyRandomForest_eMyDecisionTree      1.530      1.434          -0.096\n","26                   yMyXGB_eMyLGBM      0.772      1.439           0.667\n","34  yMyDecisionTree_eMyRandomForest      0.566      1.452           0.886\n","52                    yMySVC_eMySVR      0.030      1.467           1.437\n","17           yMyMLP_eMyDecisionTree      2.754      1.615          -1.139\n","14  yMyDecisionTree_eMyDecisionTree      1.338      1.620           0.282\n","40                 yMyLinear_eMyXGB      0.022      2.216           2.194\n","46                    yMyXGB_eMyXGB      0.048      2.227           2.179\n","36           yMyXGB_eMyRandomForest      0.276      2.295           2.019\n","16           yMyXGB_eMyDecisionTree      0.911      2.333           1.422\n","51               yMyLogistic_eMySVR      0.021      2.366           2.345\n","50                 yMyLinear_eMySVR      0.020      2.367           2.347\n","24          yMyDecisionTree_eMyLGBM      1.003      2.388           1.385\n","20                yMyLinear_eMyLGBM      0.408      2.411           2.003\n","4                   yMyDecisionTree      0.594      2.544           1.950\n","0                         yMyLinear      0.508      2.571           2.063"]},"metadata":{},"output_type":"display_data"}],"source":["# from sklearn.svm import SVC\n","if isToRunErrorModels['MySVR']:\n","    gridSVR = {}; parsDists = {}\n","    # for u in targetVars:\n","    parsDists = parsDistsSVC if isWithOptimization else None\n","    gridSVR = None if not isWithOptimization else {'kernel': ['poly', 'rbf', 'sigmoid'],#'linear', \n","        'C':[.001, .05, 1, 1.5], \n","        'epsilon': [.01, .1, .2]}\n","    computeErrorModels(MySVR(), parsDists, gridSVR)#parsDists, SVC(, max_iter=2000)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Residuals-towards Artificial Neural Network - ANN"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.214844Z","iopub.status.busy":"2023-05-05T21:26:03.213662Z","iopub.status.idle":"2023-05-05T21:26:03.231786Z","shell.execute_reply":"2023-05-05T21:26:03.230518Z","shell.execute_reply.started":"2023-05-05T21:26:03.214787Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["****** Error model.fit MyMLPRegressor Class  ******\n","==**** load_model yMyLinear_eMyMLP ****==\n",">>> elapsed time: 0.007639169692993164 seconds!\n","==**** load_model yMyLogistic_eMyMLP ****==\n",">>> elapsed time: 0.00716090202331543 seconds!\n","==**** load_model yMySVC_eMyMLP ****==\n",">>> elapsed time: 0.0060040950775146484 seconds!\n","==**** load_model yMyLGBM_eMyMLP ****==\n",">>> elapsed time: 0.005000114440917969 seconds!\n","==**** load_model yMyDecisionTree_eMyMLP ****==\n",">>> elapsed time: 0.006749629974365234 seconds!\n","==**** load_model yMyRandomForest_eMyMLP ****==\n",">>> elapsed time: 0.0069980621337890625 seconds!\n","==**** load_model yMyXGB_eMyMLP ****==\n",">>> elapsed time: 0.0050241947174072266 seconds!\n","==**** load_model yMyMLP_eMyMLP ****==\n",">>> elapsed time: 0.007309675216674805 seconds!\n","==**** load_model yMyTfMLP_eMyMLP ****==\n",">>> elapsed time: 0.005875110626220703 seconds!\n","==**** load_model yMyTfRNN_eMyMLP ****==\n",">>> elapsed time: 0.007206916809082031 seconds!\n"," *********** Best models via SMAPE in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bestModel</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         bestModel  logLoss_t  logLoss_v  logLoss_dif_vt\n","0  yMyTfMLP_eMyXGB      0.036      0.299           0.263"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" *********** Rank via logLoss in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>48</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>yMyLGBM_eMySVR</td>\n","      <td>0.018</td>\n","      <td>0.363</td>\n","      <td>0.345</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>yMyRandomForest_eMyXGB</td>\n","      <td>0.040</td>\n","      <td>0.368</td>\n","      <td>0.328</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>yMyMLP_eMyXGB</td>\n","      <td>0.100</td>\n","      <td>0.373</td>\n","      <td>0.273</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>yMyDecisionTree_eMySVR</td>\n","      <td>0.027</td>\n","      <td>0.379</td>\n","      <td>0.352</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>yMyLinear_eMyMLP</td>\n","      <td>0.089</td>\n","      <td>2.472</td>\n","      <td>2.383</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>yMyDecisionTree</td>\n","      <td>0.594</td>\n","      <td>2.544</td>\n","      <td>1.950</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyLinear</td>\n","      <td>0.508</td>\n","      <td>2.571</td>\n","      <td>2.063</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>yMyLogistic_eMyMLP</td>\n","      <td>0.043</td>\n","      <td>3.359</td>\n","      <td>3.316</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>yMySVC_eMyMLP</td>\n","      <td>0.084</td>\n","      <td>4.320</td>\n","      <td>4.236</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>70 rows × 4 columns</p>\n","</div>"],"text/plain":["                     model  logLoss_t  logLoss_v  logLoss_dif_vt\n","48         yMyTfMLP_eMyXGB      0.036      0.299           0.263\n","53          yMyLGBM_eMySVR      0.018      0.363           0.345\n","45  yMyRandomForest_eMyXGB      0.040      0.368           0.328\n","47           yMyMLP_eMyXGB      0.100      0.373           0.273\n","54  yMyDecisionTree_eMySVR      0.027      0.379           0.352\n","..                     ...        ...        ...             ...\n","60        yMyLinear_eMyMLP      0.089      2.472           2.383\n","4          yMyDecisionTree      0.594      2.544           1.950\n","0                yMyLinear      0.508      2.571           2.063\n","61      yMyLogistic_eMyMLP      0.043      3.359           3.316\n","62           yMySVC_eMyMLP      0.084      4.320           4.236\n","\n","[70 rows x 4 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# #https://towardsdatascience.com/deep-neural-multilayer-perceptron-mlp-with-scikit-learn-2698e77155e\n","\n","if isToRunErrorModels['MyMLPRegressor']:\n","    gridMLP = {}; parsDists = {}\n","    # for u in targetVars:\n","    parsDists = None if not isWithOptimization else {'activation': ['relu', 'identity', 'logistic', 'tanh'],  # categorical parameter,\n","            'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n","            #  'hidden_layer_sizes':[(2,2), (5,2), (5,3,2)],\n","            'max_iter':(100, 500), \n","            'alpha': (1e-5, 2e-1, 'log-uniform'),  # integer valued parameter\n","            'tol': (1e-4, 1e-1, 'log-uniform'),\n","            }\n","    gridMLP = None if not isWithOptimization else {'activation': ['relu', 'identity', 'logistic', 'tanh'],  # categorical parameter,\n","        # 'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n","        #  'hidden_layer_sizes':[(2,2), (5,2), (5,3,2)],\n","        # 'max_iter':(100, 500), \n","        # 'alpha': (1e-5, 2e-1, 'log-uniform')  # integer valued parameter\n","        # 'tol': (1e-4, 1e-1, 'log-uniform')\n","        # hidden_layer_sizes = [(1), (10), (50), (10, 10)],\n","    }\n","    computeErrorModels(MyMLPRegressor(), parsDists, gridMLP) #parsDists, \n","                            # hidden_layer_sizes=(10, 5, 2), activation=\"relu\", max_iter=2000), \n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Keras-TensorFlow ANN"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.234067Z","iopub.status.busy":"2023-05-05T21:26:03.233211Z","iopub.status.idle":"2023-05-05T21:26:03.245593Z","shell.execute_reply":"2023-05-05T21:26:03.244118Z","shell.execute_reply.started":"2023-05-05T21:26:03.233988Z"},"trusted":true},"outputs":[],"source":["# # #https://www.tensorflow.org/install\n","# # # Requires the latest pip\n","# # # !-m pip install --upgrade pip\n","# # # Current stable release for CPU and GPU\n","# # # !pip install tensorflow\n","# # #Testing if tensorflow is installed\n","# # import tensorflow as tf \n","# from tensorflow import keras \n","# # print('tf.__version__: ', tf.__version__)\n","# # print('__version__: ', keras.__version__)\n","# # print('x_train.shape: ', x_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.268688Z","iopub.status.busy":"2023-05-05T21:26:03.268178Z","iopub.status.idle":"2023-05-05T21:26:03.284610Z","shell.execute_reply":"2023-05-05T21:26:03.282434Z","shell.execute_reply.started":"2023-05-05T21:26:03.268638Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["****** Error model.fit MyTfMLPRegressor Class  ******\n","==**** load_model yMyLinear_eMyTfMLP ****==\n",">>> elapsed time: 0.1311202049255371 seconds!\n","==**** load_model yMyLogistic_eMyTfMLP ****==\n",">>> elapsed time: 0.1304183006286621 seconds!\n","==**** load_model yMySVC_eMyTfMLP ****==\n",">>> elapsed time: 0.1334228515625 seconds!\n","==**** load_model yMyLGBM_eMyTfMLP ****==\n",">>> elapsed time: 0.1309833526611328 seconds!\n","==**** load_model yMyDecisionTree_eMyTfMLP ****==\n",">>> elapsed time: 0.13383698463439941 seconds!\n","==**** load_model yMyRandomForest_eMyTfMLP ****==\n",">>> elapsed time: 0.13096833229064941 seconds!\n","==**** load_model yMyXGB_eMyTfMLP ****==\n",">>> elapsed time: 0.1298825740814209 seconds!\n","==**** load_model yMyMLP_eMyTfMLP ****==\n",">>> elapsed time: 0.1286022663116455 seconds!\n","==**** load_model yMyTfMLP_eMyTfMLP ****==\n",">>> elapsed time: 0.12640166282653809 seconds!\n","==**** load_model yMyTfRNN_eMyTfMLP ****==\n",">>> elapsed time: 0.13271284103393555 seconds!\n"," *********** Best models via SMAPE in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bestModel</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         bestModel  logLoss_t  logLoss_v  logLoss_dif_vt\n","0  yMyTfMLP_eMyXGB      0.036      0.299           0.263"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" *********** Rank via logLoss in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>48</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>yMyLGBM_eMySVR</td>\n","      <td>0.018</td>\n","      <td>0.363</td>\n","      <td>0.345</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>yMyRandomForest_eMyXGB</td>\n","      <td>0.040</td>\n","      <td>0.368</td>\n","      <td>0.328</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>yMyMLP_eMyXGB</td>\n","      <td>0.100</td>\n","      <td>0.373</td>\n","      <td>0.273</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>yMyDecisionTree_eMySVR</td>\n","      <td>0.027</td>\n","      <td>0.379</td>\n","      <td>0.352</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>yMyLinear_eMyTfMLP</td>\n","      <td>1.244</td>\n","      <td>2.778</td>\n","      <td>1.534</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>yMySVC_eMyTfMLP</td>\n","      <td>1.101</td>\n","      <td>2.778</td>\n","      <td>1.677</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>yMyLogistic_eMyMLP</td>\n","      <td>0.043</td>\n","      <td>3.359</td>\n","      <td>3.316</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>yMyMLP_eMyTfMLP</td>\n","      <td>2.628</td>\n","      <td>3.434</td>\n","      <td>0.806</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>yMySVC_eMyMLP</td>\n","      <td>0.084</td>\n","      <td>4.320</td>\n","      <td>4.236</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>80 rows × 4 columns</p>\n","</div>"],"text/plain":["                     model  logLoss_t  logLoss_v  logLoss_dif_vt\n","48         yMyTfMLP_eMyXGB      0.036      0.299           0.263\n","53          yMyLGBM_eMySVR      0.018      0.363           0.345\n","45  yMyRandomForest_eMyXGB      0.040      0.368           0.328\n","47           yMyMLP_eMyXGB      0.100      0.373           0.273\n","54  yMyDecisionTree_eMySVR      0.027      0.379           0.352\n","..                     ...        ...        ...             ...\n","70      yMyLinear_eMyTfMLP      1.244      2.778           1.534\n","72         yMySVC_eMyTfMLP      1.101      2.778           1.677\n","61      yMyLogistic_eMyMLP      0.043      3.359           3.316\n","77         yMyMLP_eMyTfMLP      2.628      3.434           0.806\n","62           yMySVC_eMyMLP      0.084      4.320           4.236\n","\n","[80 rows x 4 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["if isToRunErrorModels['MyTfMLPRegressor']:\n","    # early_stopping_cb = keras.callbacks.EarlyStopping(\n","    #     monitor='val_loss', patience=5, restore_best_weights=True)\n","    gridTfAnn = {}; parsDists = {}; \n","    # for u in targetVars:\n","    parsDists = None if not isWithOptimization else {#'nHiddenLayers': (0, 15),\n","                #'hidden_layer_sizes': (1, 20),\n","                'learningRate': (1e-3, .2, 'uniform'),\n","                'inpute_layer_dropout_rate': (0, .4, 'uniform')\n","                }\n","    gridTfAnn = None if not isWithOptimization else {'inpute_layer_dropout_rate': [0, .1, .4],\n","            #  'nHiddenLayers': [0, 1, 10, 20],\n","            #  'nNeurons': [1, 2, 20], \n","                'learningRate': [1e-3, .01, .2],\n","                }\n","    # modelObj = keras.wrappers.scikit_learn.KerasRegressor(MyTfMLPRegressor)\n","    computeErrorModels(MyTfMLPRegressor(u, 'errorModel'), parsDists, gridTfAnn)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.286917Z","iopub.status.busy":"2023-05-05T21:26:03.285816Z","iopub.status.idle":"2023-05-05T21:26:03.306871Z","shell.execute_reply":"2023-05-05T21:26:03.305189Z","shell.execute_reply.started":"2023-05-05T21:26:03.286862Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Layer hidden_layer_0 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer hidden_layer_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer hidden_layer_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","****** Error model.fit MyTfRNNRegressor Class  ******\n","==**** load_model yMyLinear_eMyTfRNN ****==\n",">>> elapsed time: 2.257549285888672 seconds!\n","==**** load_model yMyLogistic_eMyTfRNN ****==\n",">>> elapsed time: 2.2460310459136963 seconds!\n","==**** load_model yMySVC_eMyTfRNN ****==\n",">>> elapsed time: 2.3277080059051514 seconds!\n","==**** load_model yMyLGBM_eMyTfRNN ****==\n",">>> elapsed time: 2.143719434738159 seconds!\n","==**** load_model yMyDecisionTree_eMyTfRNN ****==\n",">>> elapsed time: 2.150620222091675 seconds!\n","==**** load_model yMyRandomForest_eMyTfRNN ****==\n",">>> elapsed time: 2.146812677383423 seconds!\n","==**** load_model yMyXGB_eMyTfRNN ****==\n",">>> elapsed time: 2.1738598346710205 seconds!\n","==**** load_model yMyMLP_eMyTfRNN ****==\n",">>> elapsed time: 2.5567033290863037 seconds!\n","==**** load_model yMyTfMLP_eMyTfRNN ****==\n",">>> elapsed time: 2.1195406913757324 seconds!\n","==**** load_model yMyTfRNN_eMyTfRNN ****==\n",">>> elapsed time: 2.102085590362549 seconds!\n"," *********** Best models via SMAPE in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bestModel</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         bestModel  logLoss_t  logLoss_v  logLoss_dif_vt\n","0  yMyTfMLP_eMyXGB      0.036      0.299           0.263"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" *********** Rank via logLoss in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>48</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>yMyLGBM_eMySVR</td>\n","      <td>0.018</td>\n","      <td>0.363</td>\n","      <td>0.345</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>yMyRandomForest_eMyXGB</td>\n","      <td>0.040</td>\n","      <td>0.368</td>\n","      <td>0.328</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>yMyMLP_eMyXGB</td>\n","      <td>0.100</td>\n","      <td>0.373</td>\n","      <td>0.273</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>yMyDecisionTree_eMySVR</td>\n","      <td>0.027</td>\n","      <td>0.379</td>\n","      <td>0.352</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>yMyLinear_eMyTfRNN</td>\n","      <td>1.150</td>\n","      <td>2.782</td>\n","      <td>1.632</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>yMyLogistic_eMyMLP</td>\n","      <td>0.043</td>\n","      <td>3.359</td>\n","      <td>3.316</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>yMyMLP_eMyTfMLP</td>\n","      <td>2.628</td>\n","      <td>3.434</td>\n","      <td>0.806</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>yMySVC_eMyTfRNN</td>\n","      <td>1.071</td>\n","      <td>3.678</td>\n","      <td>2.607</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>yMySVC_eMyMLP</td>\n","      <td>0.084</td>\n","      <td>4.320</td>\n","      <td>4.236</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>90 rows × 4 columns</p>\n","</div>"],"text/plain":["                     model  logLoss_t  logLoss_v  logLoss_dif_vt\n","48         yMyTfMLP_eMyXGB      0.036      0.299           0.263\n","53          yMyLGBM_eMySVR      0.018      0.363           0.345\n","45  yMyRandomForest_eMyXGB      0.040      0.368           0.328\n","47           yMyMLP_eMyXGB      0.100      0.373           0.273\n","54  yMyDecisionTree_eMySVR      0.027      0.379           0.352\n","..                     ...        ...        ...             ...\n","80      yMyLinear_eMyTfRNN      1.150      2.782           1.632\n","61      yMyLogistic_eMyMLP      0.043      3.359           3.316\n","77         yMyMLP_eMyTfMLP      2.628      3.434           0.806\n","82         yMySVC_eMyTfRNN      1.071      3.678           2.607\n","62           yMySVC_eMyMLP      0.084      4.320           4.236\n","\n","[90 rows x 4 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["if isToRunErrorModels['MyTfRNNRegressor']:\n","    # early_stopping_cb = keras.callbacks.EarlyStopping(\n","    #     monitor='val_loss', patience=5, restore_best_weights=True)\n","    grid = {}; parsDists = {}; \n","    # for u in targetVars:\n","    parsDists = None if not isWithOptimization else {#'nHiddenLayers': (0, 15),\n","                #'hidden_layer_sizes': (1, 20),\n","                'learningRate': (1e-3, .2, 'uniform'),\n","                'inpute_layer_dropout_rate': (0, .4, 'uniform')\n","                }\n","    grid = None if not isWithOptimization else {\n","        'inpute_layer_dropout_rate': [0, .1, .4],\n","            #  'nHiddenLayers': [0, 1, 10, 20],\n","            #  'nNeurons': [1, 2, 20], \n","                'learningRate': [1e-3, .01, .2],\n","                }\n","    # modelObj = keras.wrappers.scikit_learn.KerasRegressor(MyTfMLPRegressor)\n","    computeErrorModels(MyTfRNNRegressor(u, 'errorModel'), parsDists, grid)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Combiners (Stacking)\n","https://scikit-learn.org/stable/auto_examples/ensemble/plot_stack_predictors.html#sphx-glr-auto-examples-ensemble-plot-stack-predictors-py"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Linear combiners"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.310396Z","iopub.status.busy":"2023-05-05T21:26:03.309426Z","iopub.status.idle":"2023-05-05T21:26:03.326762Z","shell.execute_reply":"2023-05-05T21:26:03.324370Z","shell.execute_reply.started":"2023-05-05T21:26:03.310336Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['Class', 'yMyLinear', 'yMyLogistic', 'yMySVC', 'yMyLGBM',\n","       'yMyDecisionTree', 'yMyRandomForest', 'yMyXGB', 'yMyMLP', 'yMyTfMLP',\n","       'yMyTfRNN', 'yMyLinear_eMyDecisionTree', 'yMyLogistic_eMyDecisionTree',\n","       'yMySVC_eMyDecisionTree', 'yMyLGBM_eMyDecisionTree',\n","       'yMyDecisionTree_eMyDecisionTree', 'yMyRandomForest_eMyDecisionTree',\n","       'yMyXGB_eMyDecisionTree', 'yMyMLP_eMyDecisionTree',\n","       'yMyTfMLP_eMyDecisionTree', 'yMyTfRNN_eMyDecisionTree',\n","       'yMyLinear_eMyLGBM', 'yMyLogistic_eMyLGBM', 'yMySVC_eMyLGBM',\n","       'yMyLGBM_eMyLGBM', 'yMyDecisionTree_eMyLGBM', 'yMyRandomForest_eMyLGBM',\n","       'yMyXGB_eMyLGBM', 'yMyMLP_eMyLGBM', 'yMyTfMLP_eMyLGBM',\n","       'yMyTfRNN_eMyLGBM', 'yMyLinear_eMyRandomForest',\n","       'yMyLogistic_eMyRandomForest', 'yMySVC_eMyRandomForest',\n","       'yMyLGBM_eMyRandomForest', 'yMyDecisionTree_eMyRandomForest',\n","       'yMyRandomForest_eMyRandomForest', 'yMyXGB_eMyRandomForest',\n","       'yMyMLP_eMyRandomForest', 'yMyTfMLP_eMyRandomForest',\n","       'yMyTfRNN_eMyRandomForest', 'yMyLinear_eMyXGB', 'yMyLogistic_eMyXGB',\n","       'yMySVC_eMyXGB', 'yMyLGBM_eMyXGB', 'yMyDecisionTree_eMyXGB',\n","       'yMyRandomForest_eMyXGB', 'yMyXGB_eMyXGB', 'yMyMLP_eMyXGB',\n","       'yMyTfMLP_eMyXGB', 'yMyTfRNN_eMyXGB', 'yMyLinear_eMySVR',\n","       'yMyLogistic_eMySVR', 'yMySVC_eMySVR', 'yMyLGBM_eMySVR',\n","       'yMyDecisionTree_eMySVR', 'yMyRandomForest_eMySVR', 'yMyXGB_eMySVR',\n","       'yMyMLP_eMySVR', 'yMyTfMLP_eMySVR', 'yMyTfRNN_eMySVR',\n","       'yMyLinear_eMyMLP', 'yMyLogistic_eMyMLP', 'yMySVC_eMyMLP',\n","       'yMyLGBM_eMyMLP', 'yMyDecisionTree_eMyMLP', 'yMyRandomForest_eMyMLP',\n","       'yMyXGB_eMyMLP', 'yMyMLP_eMyMLP', 'yMyTfMLP_eMyMLP', 'yMyTfRNN_eMyMLP',\n","       'yMyLinear_eMyTfMLP', 'yMyLogistic_eMyTfMLP', 'yMySVC_eMyTfMLP',\n","       'yMyLGBM_eMyTfMLP', 'yMyDecisionTree_eMyTfMLP',\n","       'yMyRandomForest_eMyTfMLP', 'yMyXGB_eMyTfMLP', 'yMyMLP_eMyTfMLP',\n","       'yMyTfMLP_eMyTfMLP', 'yMyTfRNN_eMyTfMLP', 'yMyLinear_eMyTfRNN',\n","       'yMyLogistic_eMyTfRNN', 'yMySVC_eMyTfRNN', 'yMyLGBM_eMyTfRNN',\n","       'yMyDecisionTree_eMyTfRNN', 'yMyRandomForest_eMyTfRNN',\n","       'yMyXGB_eMyTfRNN', 'yMyMLP_eMyTfRNN', 'yMyTfMLP_eMyTfRNN',\n","       'yMyTfRNN_eMyTfRNN'],\n","      dtype='object')"]},"execution_count":610,"metadata":{},"output_type":"execute_result"}],"source":["yPredictions[1].columns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.341444Z","iopub.status.busy":"2023-05-05T21:26:03.340670Z","iopub.status.idle":"2023-05-05T21:26:03.350111Z","shell.execute_reply":"2023-05-05T21:26:03.348421Z","shell.execute_reply.started":"2023-05-05T21:26:03.341403Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["******* # original ySingleModelsNms: 91\n","******* # elected ySingleModelsNms: 31\n","******* elected ySingleModelsNms: ['yMyMLP_eMyDecisionTree', 'yMyLGBM_eMyDecisionTree', 'yMyTfMLP_eMyDecisionTree', 'yMyTfRNN_eMyDecisionTree', 'yMyRandomForest_eMyDecisionTree', 'yMyTfRNN_eMyTfMLP', 'yMyTfRNN_eMyLGBM', 'yMyTfRNN', 'yMyMLP_eMyLGBM', 'yMyTfMLP_eMyLGBM', 'yMyRandomForest_eMyLGBM', 'yMyTfMLP', 'yMyRandomForest_eMyTfMLP', 'yMyMLP_eMyRandomForest', 'yMyTfMLP_eMyTfMLP', 'yMyTfRNN_eMyRandomForest', 'yMyRandomForest', 'yMyTfMLP_eMyRandomForest', 'yMyMLP', 'yMySVC_eMyLGBM', 'yMyTfMLP_eMyTfRNN', 'yMyTfRNN_eMyTfRNN', 'yMyRandomForest_eMyTfRNN', 'yMyLogistic_eMyLGBM', 'yMyTfMLP_eMyXGB', 'yMyMLP_eMyXGB', 'yMySVC', 'yMyDecisionTree_eMyDecisionTree', 'yMyDecisionTree_eMyMLP', 'yMyTfRNN_eMyXGB', 'yMyRandomForest_eMyXGB']\n"]},{"data":{"text/plain":["'****** all single models performance ******'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>59</th>\n","      <td>yMyMLP_eMyDecisionTree</td>\n","      <td>2.754</td>\n","      <td>1.615</td>\n","      <td>-1.139</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>yMyLGBM_eMyDecisionTree</td>\n","      <td>2.405</td>\n","      <td>1.319</td>\n","      <td>-1.086</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>yMyTfMLP_eMyDecisionTree</td>\n","      <td>0.651</td>\n","      <td>0.459</td>\n","      <td>-0.192</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>yMyTfRNN_eMyDecisionTree</td>\n","      <td>0.883</td>\n","      <td>0.746</td>\n","      <td>-0.137</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>yMyRandomForest_eMyDecisionTree</td>\n","      <td>1.530</td>\n","      <td>1.434</td>\n","      <td>-0.096</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>yMyLinear_eMySVR</td>\n","      <td>0.020</td>\n","      <td>2.367</td>\n","      <td>2.347</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>yMyLinear_eMyMLP</td>\n","      <td>0.089</td>\n","      <td>2.472</td>\n","      <td>2.383</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>yMySVC_eMyTfRNN</td>\n","      <td>1.071</td>\n","      <td>3.678</td>\n","      <td>2.607</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>yMyLogistic_eMyMLP</td>\n","      <td>0.043</td>\n","      <td>3.359</td>\n","      <td>3.316</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>yMySVC_eMyMLP</td>\n","      <td>0.084</td>\n","      <td>4.320</td>\n","      <td>4.236</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>90 rows × 4 columns</p>\n","</div>"],"text/plain":["                              model  logLoss_t  logLoss_v  logLoss_dif_vt\n","59           yMyMLP_eMyDecisionTree      2.754      1.615          -1.139\n","45          yMyLGBM_eMyDecisionTree      2.405      1.319          -1.086\n","11         yMyTfMLP_eMyDecisionTree      0.651      0.459          -0.192\n","26         yMyTfRNN_eMyDecisionTree      0.883      0.746          -0.137\n","54  yMyRandomForest_eMyDecisionTree      1.530      1.434          -0.096\n","..                              ...        ...        ...             ...\n","71                 yMyLinear_eMySVR      0.020      2.367           2.347\n","75                 yMyLinear_eMyMLP      0.089      2.472           2.383\n","88                  yMySVC_eMyTfRNN      1.071      3.678           2.607\n","86               yMyLogistic_eMyMLP      0.043      3.359           3.316\n","89                    yMySVC_eMyMLP      0.084      4.320           4.236\n","\n","[90 rows x 4 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["def getSingleModelsNms(isToPrint = False):\n","    # ySingleModelsNms = {}\n","    # u = targetVars[0]\n","    # ySingleModelsNms = list(yPredictions[1].columns)\n","    # ySingleModelsNms.remove(u)\n","    modelsPerformance = pd.read_csv(PERFORMANCE_ROOT+'modelsPerformance.csv', sep='\\t')\n","    modelsPerformance.sort_values(by=['logLoss_dif_vt', 'logLoss_v', 'logLoss_t'], \n","                                  ascending=True, inplace=True)\n","    nModels = modelsPerformance.shape[0]\n","    index = np.min([nModels-1, 2])\n","    treshold = np.max([CombMVMaxLogLoss_dif_vt, modelsPerformance.logLoss_dif_vt[index]])\n","    ySingleModelsNms = modelsPerformance.model[modelsPerformance.logLoss_dif_vt <= treshold].to_list()\n","    if isToPrint:\n","        print('******* # original ySingleModelsNms:',  nModels+1)\n","        print('******* # elected ySingleModelsNms:',  len(ySingleModelsNms))\n","        print('******* elected ySingleModelsNms:',  ySingleModelsNms)\n","        display('****** all single models performance ******', modelsPerformance)\n","    return ySingleModelsNms\n","\n","ySingleModelsNms = getSingleModelsNms(isToPrint=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.352786Z","iopub.status.busy":"2023-05-05T21:26:03.351797Z","iopub.status.idle":"2023-05-05T21:26:03.374828Z","shell.execute_reply":"2023-05-05T21:26:03.373101Z","shell.execute_reply.started":"2023-05-05T21:26:03.352743Z"},"trusted":true},"outputs":[],"source":["def getSingleModelsPreds(x, targetVar, useLogScale = False):\n","    # u = targetVar\n","    ySingleModelsPreds = pd.DataFrame(index=x.index)\n","    for modelNm in ySingleModelsNms:\n","        modelsObjs = singleModelsObjs[modelNm]#+'_'+u]\n","        y_tPred = getPrediction(yModel = modelsObjs['yModel'], x = x, \n","                                      eModel=modelsObjs['eModel'])\n","        ySingleModelsPreds[modelNm] = y_tPred# if useLogScale else getPrediction(targetVar = u, y_Predictions = y_tPred)\n","        # ySingleModelsPreds[modelNm] = y_tPred\n","    return ySingleModelsPreds\n","class CombRNN:\n","    def __init__(self):\n","        self.targetVar = None\n","        self.w = {}\n","    def fit(self, X, y=None, targetVar=\"\"):\n","        self.targetVar = targetVar\n","        ySingleModelsPreds = getSingleModelsPreds(X, self.targetVar, useLogScale = True)\n","        self.model = MyTfRNNRegressor(self.targetVar, 'combinerModel', \n","                hidden_layer_sizes = [5, 3, 2],#[100, 50, 40, 30, 20, 10, 5, 3, 2] \n","                hidden_layer_dropout_rates = [0], \n","                learningRate = 1e-3, inpute_layer_dropout_rate = 0)  \n","        modelNm = getModelName(yModel='yComb'+type(self.model).__name__.replace('Regressor', ''), \n","                               targetVar=self.targetVar)     \n","        self.model.fit(X = ySingleModelsPreds, y=y,modelName= modelNm) \n","        return self\n","    def predict(self, X):\n","        ySingleModelsPreds = getSingleModelsPreds(X, self.targetVar, useLogScale = True)\n","        y_Predictions = self.model.predict(ySingleModelsPreds)\n","        # ret = getPrediction(targetVar = self.targetVar, y_Predictions = y_Predictions)\n","        return y_Predictions\n","class CombMV:\n","    def __init__(self):\n","        self.targetVar = None\n","        self.w = {}\n","        # self.ySingleModelsPreds = None\n","    def fit(self, X, y=None, targetVar=\"\"):\n","        self.targetVar = targetVar\n","        # if self.ySingleModelsPreds is None:\n","        ySingleModelsPreds = getSingleModelsPreds(X, self.targetVar, useLogScale = True)\n","        residuals = ySingleModelsPreds.sub(y.values, axis = 0).mul(-1) #y - Preds\n","        cov =  np.cov(m=residuals, rowvar=False)\n","        invCov = None\n","        try:\n","            invCov = np.linalg.inv(cov)\n","        except:\n","            print('******', self.targetVar, 'trouble with cMV (LinAlgError: Singular matrix)')\n","            invCov = np.linalg.pinv(cov)\n","            # print('np.dot(invCov, cov) \\n', np.dot(invCov, cov))\n","\n","        # display(invCov_t)\n","        # print('len(invCov_t):', len(invCov_t))\n","        total = invCov.sum()\n","        for i in range(len(invCov)):\n","            self.w[ySingleModelsNms[i]] = invCov[i].sum()/total\n","        print('*********** cMV weigths', self.targetVar, ':', self.w)\n","        # cMV_dic = 'cMV'\n","        # e_yModelDic = None\n","        return self\n","    def predict(self, X):\n","        ySingleModelsPreds = getSingleModelsPreds(X, self.targetVar, useLogScale = True)\n","        y_Predictions = ySingleModelsPreds.mul(self.w).sum(axis=1)\n","        # ret = getPrediction(targetVar = self.targetVar, y_Predictions = y_Predictions)\n","        return y_Predictions\n","class CombSA:\n","    def __init__(self):\n","        self.targetVar = None\n","        self.w = {}\n","        # self.ySingleModelsPreds = ySingleModelsPreds\n","    def fit(self, X, y=None, targetVar=\"\"):\n","        self.targetVar = targetVar\n","        return self\n","    def predict(self, X):\n","        ySingleModelsPreds = getSingleModelsPreds(X, self.targetVar, useLogScale = True)\n","        y_Predictions = ySingleModelsPreds.mean(axis=1)\n","        # ret = getPrediction(targetVar = self.targetVar, y_Predictions = y_Predictions)\n","        return y_Predictions\n","class CombMd:\n","    def __init__(self):\n","        self.targetVar = None\n","        self.w = {}\n","        # self.ySingleModelsPreds = ySingleModelsPreds\n","    def fit(self, X, y=None, targetVar=\"\"):\n","        self.targetVar = targetVar\n","        return self\n","    def predict(self, X):\n","        ySingleModelsPreds = getSingleModelsPreds(X, self.targetVar, useLogScale = True)\n","        y_Predictions = ySingleModelsPreds.median(axis=1)\n","        # ret = getPrediction(targetVar = self.targetVar, y_Predictions = y_Predictions)\n","        return y_Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.397766Z","iopub.status.busy":"2023-05-05T21:26:03.396474Z","iopub.status.idle":"2023-05-05T21:26:03.411234Z","shell.execute_reply":"2023-05-05T21:26:03.409907Z","shell.execute_reply.started":"2023-05-05T21:26:03.397718Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["*******  CombSA\n","*******  CombMd\n","*******  CombMV\n","****** Class trouble with cMV (LinAlgError: Singular matrix)\n","*********** cMV weigths Class : {'yMyMLP_eMyDecisionTree': -0.6553661262487002, 'yMyLGBM_eMyDecisionTree': 0.032206798646959356, 'yMyTfMLP_eMyDecisionTree': -0.7645057247053058, 'yMyTfRNN_eMyDecisionTree': 2.2256572593084947, 'yMyRandomForest_eMyDecisionTree': -0.4691075512652371, 'yMyTfRNN_eMyTfMLP': -0.12466010917059982, 'yMyTfRNN_eMyLGBM': -2.2312209915591548, 'yMyTfRNN': -0.12466010917145717, 'yMyMLP_eMyLGBM': 2.6293416357907775, 'yMyTfMLP_eMyLGBM': -0.4838404107245578, 'yMyRandomForest_eMyLGBM': 0.16208285838754058, 'yMyTfMLP': 0.22553108278069142, 'yMyRandomForest_eMyTfMLP': 1.0529993322091298, 'yMyMLP_eMyRandomForest': -0.5774927530293815, 'yMyTfMLP_eMyTfMLP': 0.22553139665243035, 'yMyTfRNN_eMyRandomForest': -0.6162903248246248, 'yMyRandomForest': -0.2945607626253154, 'yMyTfMLP_eMyRandomForest': 1.0576792784711913, 'yMyMLP': -1.2491571516393483, 'yMySVC_eMyLGBM': 0.30964380841786004, 'yMyTfMLP_eMyTfRNN': -0.18158345610614657, 'yMyTfRNN_eMyTfRNN': 1.2062028178135418, 'yMyRandomForest_eMyTfRNN': -1.07103369452046, 'yMyLogistic_eMyLGBM': 0.15794959145260598, 'yMyTfMLP_eMyXGB': -0.439017466468789, 'yMyMLP_eMyXGB': -0.7253385881418185, 'yMySVC': 0.18472002843629798, 'yMyDecisionTree_eMyDecisionTree': -0.47474612151295587, 'yMyDecisionTree_eMyMLP': 0.37056263035128423, 'yMyTfRNN_eMyXGB': 0.6233592254351706, 'yMyRandomForest_eMyXGB': 1.0191135975553227}\n","*******  CombRNN\n","==**** load_model yCombMyTfRNN ****==\n",">>> elapsed time: 0.7270596027374268 seconds!\n"," *********** Best models via SMAPE in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bestModel</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         bestModel  logLoss_t  logLoss_v  logLoss_dif_vt\n","0  yMyTfMLP_eMyXGB      0.036      0.299           0.263"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" *********** Rank via logLoss in the validation set *********** \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>48</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>yCombRNN</td>\n","      <td>0.378</td>\n","      <td>0.336</td>\n","      <td>-0.042</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>yMyLGBM_eMySVR</td>\n","      <td>0.018</td>\n","      <td>0.363</td>\n","      <td>0.345</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>yMyRandomForest_eMyXGB</td>\n","      <td>0.040</td>\n","      <td>0.368</td>\n","      <td>0.328</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>yMyMLP_eMyXGB</td>\n","      <td>0.100</td>\n","      <td>0.373</td>\n","      <td>0.273</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>yMyLinear_eMyTfRNN</td>\n","      <td>1.150</td>\n","      <td>2.782</td>\n","      <td>1.632</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>yMyLogistic_eMyMLP</td>\n","      <td>0.043</td>\n","      <td>3.359</td>\n","      <td>3.316</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>yMyMLP_eMyTfMLP</td>\n","      <td>2.628</td>\n","      <td>3.434</td>\n","      <td>0.806</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>yMySVC_eMyTfRNN</td>\n","      <td>1.071</td>\n","      <td>3.678</td>\n","      <td>2.607</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>yMySVC_eMyMLP</td>\n","      <td>0.084</td>\n","      <td>4.320</td>\n","      <td>4.236</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>94 rows × 4 columns</p>\n","</div>"],"text/plain":["                     model  logLoss_t  logLoss_v  logLoss_dif_vt\n","48         yMyTfMLP_eMyXGB      0.036      0.299           0.263\n","93                yCombRNN      0.378      0.336          -0.042\n","53          yMyLGBM_eMySVR      0.018      0.363           0.345\n","45  yMyRandomForest_eMyXGB      0.040      0.368           0.328\n","47           yMyMLP_eMyXGB      0.100      0.373           0.273\n","..                     ...        ...        ...             ...\n","80      yMyLinear_eMyTfRNN      1.150      2.782           1.632\n","61      yMyLogistic_eMyMLP      0.043      3.359           3.316\n","77         yMyMLP_eMyTfMLP      2.628      3.434           0.806\n","82         yMySVC_eMyTfRNN      1.071      3.678           2.607\n","62           yMySVC_eMyMLP      0.084      4.320           4.236\n","\n","[94 rows x 4 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["import copy\n","def computeCombinerPrediction(combObj, printResults = False):\n","    objDic = {}; e_yModelDic = {}; #cSA_dic = {}; cMd_dic = {}\n","    # for u in targetVars:\n","    # print('************* *************')\n","    cObj = copy.deepcopy(combObj)# if type(combObj).__name__ != 'MyTfRNNRegressor' else \n","    # cObj.targetVar = u\n","    e_yModelDic = None\n","    x = x_tTransf[2]\n","    y = y_t[2]\n","    cObj.fit(x, y, u); \n","    objDic = cObj\n","    computePerformanceMeasures(yModel = objDic, phase = 2, x_t = x_tTransf, \n","                            y_t = y_t, eModel=e_yModelDic, printResults = printResults)\n","\n","combList = []\n","if isToRunCombinerModels['cSA']:\n","    combList.append(CombSA())\n","if isToRunCombinerModels['cMd']:\n","    combList.append(CombMd())\n","if isToRunCombinerModels['cMV']:\n","    combList.append(CombMV())\n","if isToRunCombinerModels['cRNN']:\n","    combList.append(CombRNN())\n","\n","count = 0\n","nCombs = len(combList)\n","for comb in combList:\n","    count += 1\n","    printResults = False if count < nCombs else True\n","    print('******* ', type(comb).__name__)\n","    computeCombinerPrediction(comb, printResults)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### non-linear combiners"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Full results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.413246Z","iopub.status.busy":"2023-05-05T21:26:03.412784Z","iopub.status.idle":"2023-05-05T21:26:03.480342Z","shell.execute_reply":"2023-05-05T21:26:03.478830Z","shell.execute_reply.started":"2023-05-05T21:26:03.413210Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>yCombRNN</td>\n","      <td>0.378</td>\n","      <td>0.336</td>\n","      <td>-0.042</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yMyLGBM_eMySVR</td>\n","      <td>0.018</td>\n","      <td>0.363</td>\n","      <td>0.345</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yMyRandomForest_eMyXGB</td>\n","      <td>0.040</td>\n","      <td>0.368</td>\n","      <td>0.328</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>yMyMLP_eMyXGB</td>\n","      <td>0.100</td>\n","      <td>0.373</td>\n","      <td>0.273</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>yMyLinear_eMyTfRNN</td>\n","      <td>1.150</td>\n","      <td>2.782</td>\n","      <td>1.632</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>yMyLogistic_eMyMLP</td>\n","      <td>0.043</td>\n","      <td>3.359</td>\n","      <td>3.316</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>yMyMLP_eMyTfMLP</td>\n","      <td>2.628</td>\n","      <td>3.434</td>\n","      <td>0.806</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>yMySVC_eMyTfRNN</td>\n","      <td>1.071</td>\n","      <td>3.678</td>\n","      <td>2.607</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>yMySVC_eMyMLP</td>\n","      <td>0.084</td>\n","      <td>4.320</td>\n","      <td>4.236</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>94 rows × 4 columns</p>\n","</div>"],"text/plain":["                     model  logLoss_t  logLoss_v  logLoss_dif_vt\n","0          yMyTfMLP_eMyXGB      0.036      0.299           0.263\n","1                 yCombRNN      0.378      0.336          -0.042\n","2           yMyLGBM_eMySVR      0.018      0.363           0.345\n","3   yMyRandomForest_eMyXGB      0.040      0.368           0.328\n","4            yMyMLP_eMyXGB      0.100      0.373           0.273\n","..                     ...        ...        ...             ...\n","89      yMyLinear_eMyTfRNN      1.150      2.782           1.632\n","90      yMyLogistic_eMyMLP      0.043      3.359           3.316\n","91         yMyMLP_eMyTfMLP      2.628      3.434           0.806\n","92         yMySVC_eMyTfRNN      1.071      3.678           2.607\n","93           yMySVC_eMyMLP      0.084      4.320           4.236\n","\n","[94 rows x 4 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# print('****** all models *****')\n","modelsPerformanceFN = 'modelsPerformance.csv'\n","modelsPerformance = pd.read_csv(PERFORMANCE_ROOT+modelsPerformanceFN, sep='\\t')\n","\n","# display(modelsPerformance)\n","# for u in targetVars:\n","display(modelsPerformance.sort_values(by=['logLoss_v',\t'logLoss_dif_vt', 'logLoss_t'], ascending=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.482302Z","iopub.status.busy":"2023-05-05T21:26:03.481785Z","iopub.status.idle":"2023-05-05T21:26:03.499083Z","shell.execute_reply":"2023-05-05T21:26:03.498148Z","shell.execute_reply.started":"2023-05-05T21:26:03.482262Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bestModel</th>\n","      <th>logLoss_t</th>\n","      <th>logLoss_v</th>\n","      <th>logLoss_dif_vt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yMyTfMLP_eMyXGB</td>\n","      <td>0.036</td>\n","      <td>0.299</td>\n","      <td>0.263</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         bestModel  logLoss_t  logLoss_v  logLoss_dif_vt\n","0  yMyTfMLP_eMyXGB      0.036      0.299           0.263"]},"metadata":{},"output_type":"display_data"}],"source":["#print('***** best models *****')\n","bestModelsPerformanceFN = 'bestModelsPerformance.csv'\n","bestModelsPerformance = pd.read_csv(PERFORMANCE_ROOT+bestModelsPerformanceFN, sep='\\t')\n","display(bestModelsPerformance)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Kaggle Competition Submission Files"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:03.501851Z","iopub.status.busy":"2023-05-05T21:26:03.500757Z","iopub.status.idle":"2023-05-05T21:26:04.145509Z","shell.execute_reply":"2023-05-05T21:26:04.144108Z","shell.execute_reply.started":"2023-05-05T21:26:03.501796Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["===>>> SUBMISSION FILE SUCCESSFULLY CREATED!!! <<<===\n"]}],"source":["#geting the model predictions file\n","#Starting from https://www.kaggle.com/code/renataghisloti/linearregression-simple-70-smape\n","def getSubmissionPredictionsFile(isToPrint = False):#'xTransfXg'):#'xTransfLinear):\n","    '''All predictors are `visit_month` dependent'''\n","    #defining the data per UPDRS\n","    data = pd.read_csv(DATA_ROOT+'test.csv')#getTestQtDf(test_proteins=proteinsData, test_peptides=pepitidesData, test_general=generalData)\n","    performPrimeTransformations(data)\n","    data['EJ'] = np.where(data['EJ'] == 'A', 0, 1)\n","    cols = x_tTransf[0].columns\n","    data_Transf = pd.DataFrame(fullPipeline.transform(data[quantiVars]), \n","                               columns=cols, \n","                               index = data.index)\n","    # data = data.sort_values(by=['visit_month', 'Id'], ascending=True)\n","    ids = data.Id\n","    class_1_Probs = getPrediction(yModel = best_yModels['yModelObj'],# yLinear, \n","                            x = data_Transf, \n","                            eModel=best_yModels['eModelObj'])\n","    class_0_Probs = pd.Series([1]*len(class_1_Probs), \n","                              index=class_1_Probs.index).subtract(class_1_Probs)\n","    result = pd.DataFrame({'Id':ids,\n","                           'class_0': class_0_Probs,\n","                           'class_1':class_1_Probs})\n","    result.to_csv(RESULTS_ROOT+'submission.csv',index=False)\n","    \n","    if isToPrint:\n","        print('************ test data ************')\n","        display(data)\n","        print('************ transformed data ************')\n","        display(data_Transf)\n","        print('************ submission file ************')\n","        display(result)\n","    print('===>>> SUBMISSION FILE SUCCESSFULLY CREATED!!! <<<===')\n","    return result\n","# Run once to check results\n","result = getSubmissionPredictionsFile(isToPrint = False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T21:26:05.135299Z","iopub.status.busy":"2023-05-05T21:26:05.134914Z","iopub.status.idle":"2023-05-05T21:26:05.144516Z","shell.execute_reply":"2023-05-05T21:26:05.142733Z","shell.execute_reply.started":"2023-05-05T21:26:05.135266Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["My current relative rank in the competiion: top  33.0 %\n"]}],"source":["#My relative rank in the competiion\n","nTeams = 727  \n","myRank = 243\n","dateWhenIGotMyBestScore = '2023-05-17'\n","MyBestAcore = 57.4\n","copetionBestScoreAt_dateWhenIGotMyBestScore = 56.3\n","print('My current relative rank in the competiion: top ', 100*round(myRank/nTeams, 2), '%')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
